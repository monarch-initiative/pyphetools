{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pyphetools","text":"<p>pyphetools is a Python package for creating GA4GH phenopackets from tabular data such as databases or supplemental files found in the medical literature.</p> <p>This documentation contains information about</p> <ul> <li>How to use the Excel template to code clinical data</li> <li>Information for developers</li> <li>A description of the pyphetools API</li> </ul> <p>See the following pages for more information:</p> <ul> <li>GitHub: Source code is available at the pyphetools GitHub repository.</li> <li>PyPI: pyphetools has been released as a Python package as. See its PyPI project page.</li> <li>Feedback: The best place to leave feedback, ask questions, and report bugs is the Pyphetools Issue Tracker.</li> </ul>"},{"location":"api/creation/","title":"Creation module","text":"<p>This module contains code for creating phenopackets from tabular data.</p> <ul> <li>AgeColumnMapper</li> </ul>"},{"location":"api/overview/","title":"API Documentation","text":"<p>pyphetools has three modules.</p> <ul> <li>creation</li> <li>validation</li> <li>visualization</li> </ul>"},{"location":"api/validation/","title":"Validation module","text":"<p>This module contains code for validating phenopackets created by pyphetools. These functions are provided for convenience. We recommend using phenopacket-tools to validate phenopackets.</p>"},{"location":"api/validation/#pyphetools.validation.CohortValidator","title":"<code>CohortValidator</code>","text":"Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>class CohortValidator:\n\n    def __init__(self, cohort:List[Individual], ontology:hpotk.MinimalOntology, min_hpo:int,  allelic_requirement:AllelicRequirement=None) -&gt; None:\n        self._cohort = cohort\n        self._ontology = ontology\n        self._validated_individual_list = []\n        for indi in cohort:\n            vindi = ValidatedIndividual(individual=indi)\n            vindi.validate(ontology=ontology, min_hpo=min_hpo, allelic_requirement=allelic_requirement)\n            self._validated_individual_list.append(vindi)\n        if len(cohort) != len(self._validated_individual_list):\n            # should never happen\n            raise ValueError(f\"Invalid validation: size of cohort ={len(cohort)} but size of validated individual = {len(self._validated_individual_list)}\")\n        self._error_free_individuals = [vi.get_individual_with_clean_terms() for vi in self._validated_individual_list if not vi.has_unfixed_error()]\n        self._v_individuals_with_unfixable_errors = [vi for vi in self._validated_individual_list if vi.has_unfixed_error()]\n\n    def get_validated_individual_list(self):\n        \"\"\"\n        :returns: list of all individuals with QC Validation results\n        :rtype: List[ValidatedIndividual]\n        \"\"\"\n        return self._validated_individual_list\n\n\n    def get_error_free_individual_list(self) -&gt; List[Individual]:\n        \"\"\"\n        Returns a list of individuals from which the erroneous and redundant termas have been removed and from which individuals with errors (e.g., not enough HPO terms) have been removed.\n        :returns: List of individuals with no errors\n        :rtype: List[Individual]\n        \"\"\"\n        return self._error_free_individuals\n\n    def get_validated_individuals_with_unfixable_errors(self):\n        \"\"\"\n        Returns a list of individuals with errors that cannot be automatically fixed.\n        :returns: List of individuals with unfixable errors\n        :rtype: List[ValidatedIndivudal]\n        \"\"\"\n        return self._v_individuals_with_unfixable_errors\n\n\n    def n_removed_individuals(self):\n        return len(self._validated_individual_list) - len(self._error_free_individuals)\n\n    def n_individuals(self):\n        return len(self._validated_individual_list)\n\n    def n_error_free_individuals(self):\n        return len(self._error_free_individuals)\n\n    def get_ontology(self):\n        return self._ontology\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.CohortValidator.get_error_free_individual_list","title":"<code>get_error_free_individual_list()</code>","text":"<p>Returns a list of individuals from which the erroneous and redundant termas have been removed and from which individuals with errors (e.g., not enough HPO terms) have been removed.</p> <p>Returns:</p> Type Description <code>List[Individual]</code> <p>List of individuals with no errors</p> Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>def get_error_free_individual_list(self) -&gt; List[Individual]:\n    \"\"\"\n    Returns a list of individuals from which the erroneous and redundant termas have been removed and from which individuals with errors (e.g., not enough HPO terms) have been removed.\n    :returns: List of individuals with no errors\n    :rtype: List[Individual]\n    \"\"\"\n    return self._error_free_individuals\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.CohortValidator.get_validated_individual_list","title":"<code>get_validated_individual_list()</code>","text":"<p>Returns:</p> Type Description <code>List[ValidatedIndividual]</code> <p>list of all individuals with QC Validation results</p> Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>def get_validated_individual_list(self):\n    \"\"\"\n    :returns: list of all individuals with QC Validation results\n    :rtype: List[ValidatedIndividual]\n    \"\"\"\n    return self._validated_individual_list\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.CohortValidator.get_validated_individuals_with_unfixable_errors","title":"<code>get_validated_individuals_with_unfixable_errors()</code>","text":"<p>Returns a list of individuals with errors that cannot be automatically fixed.</p> <p>Returns:</p> Type Description <code>List[ValidatedIndivudal]</code> <p>List of individuals with unfixable errors</p> Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>def get_validated_individuals_with_unfixable_errors(self):\n    \"\"\"\n    Returns a list of individuals with errors that cannot be automatically fixed.\n    :returns: List of individuals with unfixable errors\n    :rtype: List[ValidatedIndivudal]\n    \"\"\"\n    return self._v_individuals_with_unfixable_errors\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ContentValidator","title":"<code>ContentValidator</code>","text":"<p>               Bases: <code>PhenopacketValidator</code></p> <p>Validate a list of phenopackets as to whether they have a minunum number of phenotypic features and alleles</p> <p>The following example shows how to use this class to assess whether each phenopacket in the directory called \"phenopackets\" contains at least one variant and at least three HPO terms.</p> <pre><code>from pyphetools.visualization import PhenopacketIngestor\nfrom pyphetools.validation import ContentValidator\ningestor = PhenopacketIngestor(indir=\"phenopackets\")\nppkt_d = ingestor.get_phenopacket_dictionary()\nppkt_list = list(ppkt_d.values())\nvalidator = ContentValidator(min_var=1, min_hpo=3)\nerrors = validator.validate_phenopacket_list(ppkt_list)\nprint(f\"{len(errors)} errors were identified\")\n</code></pre> <p>Note that this class does not test for all errors. Use phenopacket-tools to check for redundant or conflicting annotations.</p> <p>Parameters:</p> Name Type Description Default <code>min_hpo</code> <code>int</code> <p>minimum number of phenotypic features (HP terms) for this phenopacket to be considered valid</p> required <code>allelic_requirement</code> <code>AllelicRequirement</code> <p>used to check number of alleles and variants</p> <code>None</code> Source code in <code>pyphetools/validation/content_validator.py</code> <pre><code>class ContentValidator(PhenopacketValidator):\n    \"\"\"\n    Validate a list of phenopackets as to whether they have a minunum number of phenotypic features and alleles\n\n    The following example shows how to use this class to assess whether each phenopacket in the directory called \"phenopackets\" contains at least one variant and at least three HPO terms.\n\n        from pyphetools.visualization import PhenopacketIngestor\n        from pyphetools.validation import ContentValidator\n        ingestor = PhenopacketIngestor(indir=\"phenopackets\")\n        ppkt_d = ingestor.get_phenopacket_dictionary()\n        ppkt_list = list(ppkt_d.values())\n        validator = ContentValidator(min_var=1, min_hpo=3)\n        errors = validator.validate_phenopacket_list(ppkt_list)\n        print(f\"{len(errors)} errors were identified\")\n\n    Note that this class does not test for all errors. Use phenopacket-tools to check for redundant or conflicting\n    annotations.\n\n    :param min_hpo: minimum number of phenotypic features (HP terms) for this phenopacket to be considered valid\n    :type min_hpo: int\n    :param allelic_requirement: used to check number of alleles and variants\n    :type allelic_requirement: AllelicRequirement\n    \"\"\"\n    def __init__(self, min_hpo: int, allelic_requirement: AllelicRequirement = None, minimum_disease_count:int=1) -&gt; None:\n        super().__init__()\n        self._min_hpo = min_hpo\n        self._allelic_requirement = allelic_requirement\n        self._minimum_disease_count = minimum_disease_count\n\n\n    def validate_individual(self, individual:Individual) -&gt; List[ValidationResult]:\n        \"\"\"\n        check a single Individual as to whether there are sufficient HPO terms and alleles/variants\n        :returns: a potential empty list of validations\n        :rtype: List[ValidationResult]\n        \"\"\"\n        n_pf = len(individual.hpo_terms)\n        n_var = 0\n        n_alleles = 0\n        pp_id = individual.get_phenopacket_id()\n        for variant_interpretation in individual.interpretation_list:\n            n_var += 1\n            if variant_interpretation.variation_descriptor is not None:\n                vdesc =  variant_interpretation.variation_descriptor\n                if vdesc.allelic_state is not None:\n                    gtype = vdesc.allelic_state\n                    if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                        n_alleles += 1\n                    elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                        n_alleles += 2\n                    elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                        n_alleles += 1\n        disease_count =  individual.disease_count()\n        return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n\n\n\n    def validate_phenopacket(self, phenopacket) -&gt; List[ValidationResult]:\n        \"\"\"\n        check a single phenopacket as to whether there are sufficient HPO terms and alleles/variants\n        :returns: a potential empty list of validations\n        :rtype: List[ValidationResult]\n        \"\"\"\n        if isinstance(phenopacket, str):\n            # the user passed a file\n            if not os.path.isfile(phenopacket):\n                raise FileNotFoundError(f\"Could not find phenopacket file at '{phenopacket}'\")\n            with open(phenopacket) as f:\n                data = f.read()\n                jsondata = json.loads(data)\n                phpacket = Parse(json.dumps(jsondata), phenopackets.Phenopacket())\n        elif isinstance(phenopacket, phenopackets.Phenopacket):\n            phpacket = phenopacket\n        else:\n            raise ValueError(f\"phenopacket argument must be file path or GA4GH Phenopacket \\\n                object but was {type(phenopacket)}\")\n        pp_id = phpacket.id\n        n_pf = len(phpacket.phenotypic_features)\n        if phpacket.interpretations is None:\n            n_var = 0\n            n_alleles = 0\n        else:\n            n_var = 0\n            n_alleles = 0\n            for interpretation in phpacket.interpretations:\n                if interpretation.diagnosis is not None:\n                    dx = interpretation.diagnosis\n                    for genomic_interpretation in dx.genomic_interpretations:\n                        n_var += 1\n                        vint = genomic_interpretation.variant_interpretation\n                        if vint.variation_descriptor is not None:\n                            vdesc =   vint.variation_descriptor\n                            if vdesc.allelic_state is not None:\n                                gtype = vdesc.allelic_state\n                                if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                                    n_alleles += 1\n                                elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                                    n_alleles += 2\n                                elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                                    n_alleles += 1\n        disease_count = len(phenopacket.diseases)\n        return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n\n\n\n    def _validate(self, pp_id:str, n_hpo:int, disease_count:int, n_var:int=None, n_alleles:int=None):\n        \"\"\"\n        private method called by validate_individual or validate_phenopacket.\n        :param pp_id: phenopacket identifier\n        :type pp_id: str\n        :param n_hpo: Number of HPO terms\n        :type n_hpo: int\n        :param n_var: Number of variants found\n        :type n_var: Optional[int]\n        :param n_alleles: Number of alleles found\n        :type n_alleles: Optional[int]\n        \"\"\"\n        validation_results = []\n        if n_hpo &lt; self._min_hpo:\n            validation_results.append(ValidationResultBuilder(phenopacket_id=pp_id).insufficient_hpos(min_hpo=self._min_hpo, n_hpo=n_hpo).build())\n        if disease_count &lt; self._minimum_disease_count:\n            val_result = ValidationResultBuilder(phenopacket_id=pp_id).insufficient_disease_count(disease_count, self._minimum_disease_count).build()\n            validation_results.append(val_result)\n        if self._allelic_requirement is None:\n            return validation_results\n        if self._allelic_requirement == AllelicRequirement.MONO_ALLELIC:\n            if n_var != 1:\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_variant_count(self._allelic_requirement, n_var).build()\n                validation_results.append(val_result)\n            if n_alleles != 1:\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_allele_count(self._allelic_requirement, n_alleles).build()\n                validation_results.append(val_result)\n        elif self._allelic_requirement == AllelicRequirement.BI_ALLELIC:\n            if n_var &lt; 1 or n_var &gt; 2:\n                msg = f\"Expected one or two variant for biallelic but got {n_var} variants\"\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_variant_count(self._allelic_requirement, n_var).build()\n                validation_results.append(val_result)\n            if n_alleles != 2:\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_allele_count(self._allelic_requirement, n_alleles).build()\n                validation_results.append(val_result)\n        return validation_results\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ContentValidator.validate_individual","title":"<code>validate_individual(individual)</code>","text":"<p>check a single Individual as to whether there are sufficient HPO terms and alleles/variants</p> <p>Returns:</p> Type Description <code>List[ValidationResult]</code> <p>a potential empty list of validations</p> Source code in <code>pyphetools/validation/content_validator.py</code> <pre><code>def validate_individual(self, individual:Individual) -&gt; List[ValidationResult]:\n    \"\"\"\n    check a single Individual as to whether there are sufficient HPO terms and alleles/variants\n    :returns: a potential empty list of validations\n    :rtype: List[ValidationResult]\n    \"\"\"\n    n_pf = len(individual.hpo_terms)\n    n_var = 0\n    n_alleles = 0\n    pp_id = individual.get_phenopacket_id()\n    for variant_interpretation in individual.interpretation_list:\n        n_var += 1\n        if variant_interpretation.variation_descriptor is not None:\n            vdesc =  variant_interpretation.variation_descriptor\n            if vdesc.allelic_state is not None:\n                gtype = vdesc.allelic_state\n                if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                    n_alleles += 1\n                elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                    n_alleles += 2\n                elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                    n_alleles += 1\n    disease_count =  individual.disease_count()\n    return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ContentValidator.validate_phenopacket","title":"<code>validate_phenopacket(phenopacket)</code>","text":"<p>check a single phenopacket as to whether there are sufficient HPO terms and alleles/variants</p> <p>Returns:</p> Type Description <code>List[ValidationResult]</code> <p>a potential empty list of validations</p> Source code in <code>pyphetools/validation/content_validator.py</code> <pre><code>def validate_phenopacket(self, phenopacket) -&gt; List[ValidationResult]:\n    \"\"\"\n    check a single phenopacket as to whether there are sufficient HPO terms and alleles/variants\n    :returns: a potential empty list of validations\n    :rtype: List[ValidationResult]\n    \"\"\"\n    if isinstance(phenopacket, str):\n        # the user passed a file\n        if not os.path.isfile(phenopacket):\n            raise FileNotFoundError(f\"Could not find phenopacket file at '{phenopacket}'\")\n        with open(phenopacket) as f:\n            data = f.read()\n            jsondata = json.loads(data)\n            phpacket = Parse(json.dumps(jsondata), phenopackets.Phenopacket())\n    elif isinstance(phenopacket, phenopackets.Phenopacket):\n        phpacket = phenopacket\n    else:\n        raise ValueError(f\"phenopacket argument must be file path or GA4GH Phenopacket \\\n            object but was {type(phenopacket)}\")\n    pp_id = phpacket.id\n    n_pf = len(phpacket.phenotypic_features)\n    if phpacket.interpretations is None:\n        n_var = 0\n        n_alleles = 0\n    else:\n        n_var = 0\n        n_alleles = 0\n        for interpretation in phpacket.interpretations:\n            if interpretation.diagnosis is not None:\n                dx = interpretation.diagnosis\n                for genomic_interpretation in dx.genomic_interpretations:\n                    n_var += 1\n                    vint = genomic_interpretation.variant_interpretation\n                    if vint.variation_descriptor is not None:\n                        vdesc =   vint.variation_descriptor\n                        if vdesc.allelic_state is not None:\n                            gtype = vdesc.allelic_state\n                            if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                                n_alleles += 1\n                            elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                                n_alleles += 2\n                            elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                                n_alleles += 1\n    disease_count = len(phenopacket.diseases)\n    return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.OntologyQC","title":"<code>OntologyQC</code>","text":"<p>This class performs three kind of checks/cleansing of ontology data 1. negated superclass and observed subclass (this is an error in the original data) 2. observed superclass and observed subclass (this is a redundancy but arguably not an error) 3. Same term is excluded and observed (this is an unfixable error in the original data)</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>class OntologyQC:\n    \"\"\"\n    This class performs three kind of checks/cleansing of ontology data\n    1. negated superclass and observed subclass (this is an error in the original data)\n    2. observed superclass and observed subclass (this is a redundancy but arguably not an error)\n    3. Same term is excluded and observed (this is an unfixable error in the original data)\n\n    \"\"\"\n\n    def __init__(self,\n                 ontology:hpotk.MinimalOntology,\n                 individual:Individual,\n                 fix_conflicts=True,\n                 fix_redundancies=True):\n        self._ontology = ontology\n        self._individual = individual\n        self._phenopacket_id = individual.get_phenopacket_id()\n        self._fix_conflict_flag = fix_conflicts\n        self._fix_redundancy_flag = fix_redundancies\n        self._errors = []\n        self._clean_hpo_terms = self._clean_terms()\n\n\n    def _fix_conflicts(self,\n                       observed_hpo_terms:List[HpTerm],\n                       excluded_hpo_terms) -&gt; List[HpTerm]:\n        \"\"\"\n        This class detects excluded superclasses that have observed subclasses -- a conflict.\n\n        For instance, if an individual is annotated to the terms (1) excluded: Seizure [HP:0001250] and (2)\n        observed - Clonic Seizure [HP:0020221], this is a conflict, because a person with clonic seizure also\n        can be said to have seizure. Here, we assume that the excluded annotation is an error that we\n        want to remove automatically and issue a warning. Thus, in this example, we would remove the\n        annotation excluded: Seizure [HP:0001250], and in general the excluded superclass is removed\n        if this kind of conflict is detected\n\n        :param observed_hpo_terms: list of HPO terms (observed), can be empty\n        :type observed_hpo_terms: List[HpTerm]\n        :param excluded_hpo_terms: list of HPO terms (excluded), can be empty\n        :type excluded_hpo_terms: List[HpTerm]\n        :returns: the potentially cleansed list of excluded terms (the observed terms are never changed by this method\n        :rtype: List[HpTerm]\n        \"\"\"\n        if len(excluded_hpo_terms) == 0:\n            # i.e., there can be no conflict\n            return excluded_hpo_terms\n        all_excluded_term_ids = {term.id for term in excluded_hpo_terms}\n        conflicting_term_id_set = set()\n        for term in observed_hpo_terms:\n            for tid in all_excluded_term_ids:\n                if term.id == tid:\n                    # same term observed and excluded\n                    # we cannot automatically fix this error\n                    # this will be reported and the user will need to check the input data\n                    error = ValidationResultBuilder(phenopacket_id=self._phenopacket_id).observed_and_excluded_term(term=term).build()\n                    self._errors.append(error)\n                elif self._ontology.graph.is_ancestor_of(tid, term.id):\n                    conflicting_term_id_set.add(tid)\n                    conflicting_term = self._ontology.get_term(term_id=tid)\n                    cterm = HpTerm.from_hpo_tk_term(conflicting_term)\n                    error = ValidationResultBuilder(phenopacket_id=self._phenopacket_id).conflict(term=term, conflicting_term=cterm).build()\n                    self._errors.append(error)\n        if len(conflicting_term_id_set) &gt; 0:\n            excluded_hpo_terms = [term for term in excluded_hpo_terms if term.id not in conflicting_term_id_set]\n        return excluded_hpo_terms\n\n\n\n\n    def _fix_redundancies(self,\n                          hpo_terms:List[HpTerm]) -&gt; List[HpTerm]:\n        \"\"\"\n        Remove redundant terms from a list of HPO terms.\n\n        As a side effect, add a ValidationResult for each removed redundant term\n        :param hpo_terms: original term list that might contain redundancies\n        :type hpo_terms: List[HpTerm]\n        :returns: list of HPO terms without redundancies\n        :rtype hpo_terms: List[HpTerm]\n        \"\"\"\n        all_terms = set(hpo_terms)\n        # check for duplicates\n        if len(all_terms) != len(hpo_terms):\n            duplicates = [item for item, count in Counter(hpo_terms).items() if count &gt; 1]\n            for dup in duplicates:\n                error = ValidationResultBuilder(self._phenopacket_id).duplicate_term(redundant_term=dup).build()\n                self._errors.append(error)\n            # The following removes duplicates under the assumption that all components of the HpTerm are equal\n            hpo_terms = set(hpo_terms)\n        # The following code checks for other kinds of redundancies\n        redundant_term_d = {}\n        for term in all_terms:\n            for term2 in all_terms:\n                # The ancestor, e.g. Seizure comes first, the other term, e.g. Clonic seizure, second\n                # in the following function call\n                if self._ontology.graph.is_ancestor_of(term2.id, term.id):\n                    redundant_term_d[term2] = term\n        # When we get here, we have scanned all terms for redundant ancestors\n        non_redundant_terms = [ term for term in hpo_terms if term not in redundant_term_d]\n        if len(redundant_term_d) &gt; 0:\n            for term, descendant in redundant_term_d.items():\n                error = ValidationResultBuilder(self._phenopacket_id).redundant_term(ancestor_term=term, descendent_term=descendant).build()\n                self._errors.append(error)\n        return non_redundant_terms\n\n\n    def _check_term_ids_and_labels(self,\n                                   hpo_terms:List[HpTerm]) -&gt; None:\n        \"\"\"\n        Check whether the term identifiers (e.g., HP:0001234) are present in the ontology as primary ids and whether\n        the label matches the current priumary label; if not, flag the errors in self._errors\n        \"\"\"\n        for term in hpo_terms:\n            hpo_id = term.id\n            if not hpo_id in self._ontology:\n                error = ValidationResultBuilder(self._phenopacket_id).malformed_hpo_id(malformed_term=term).build()\n                self._errors.append(error)\n            else:\n                hpo_term = self._ontology.get_term(term_id=hpo_id)\n                if hpo_term.name != term.label:\n                    valid_term = HpTerm.from_hpo_tk_term(hpo_term)\n                    error = ValidationResultBuilder(self._phenopacket_id).malformed_hpo_label(malformed_label=term.label,\n                                                                                              valid_term=hpo_term).build()\n                    self._errors.append(error)\n\n    def _clean_terms(self) -&gt; List[HpTerm]:\n        \"\"\"\n        :returns: list of HPO terms without redundancies/conflicts\n        :rtype hpo_terms: List[HpTerm]\n        \"\"\"\n        by_age_dictionary = defaultdict(list)\n        # collect all terms without a defined age of onset\n        # We will assume these terms exist at all specific ages of onset, thus we need this to calculate redundancy\n        observed_terms_without_onset = list()\n        excluded_terms_without_onset = list()\n        for term in self._individual.hpo_terms:\n            if not term.measured:\n                self._errors.append(ValidationResultBuilder(self._phenopacket_id).not_measured(term=term).build())\n            else:\n                if term.onset is not None:\n                    by_age_dictionary[term.onset].append(term)\n                else:\n                    if term.observed:\n                        observed_terms_without_onset.append(term)\n                    else:\n                        excluded_terms_without_onset.append(term)\n        self._check_term_ids_and_labels(self._individual.hpo_terms)\n        clean_terms = []\n\n        for onset, term_list in by_age_dictionary.items():\n            observed_hpo_terms = [term for term in term_list if term.observed]\n            excluded_hpo_terms = [term for term in term_list if not term.observed]\n            if self._fix_redundancy_flag:\n                observed_hpo_terms = self._fix_redundancies(observed_hpo_terms)\n                excluded_hpo_terms = self._fix_redundancies(excluded_hpo_terms)\n            if self._fix_conflict_flag:\n                # this method checks and may fix the excluded terms (only)\n                excluded_hpo_terms = self._fix_conflicts(observed_hpo_terms, excluded_hpo_terms)\n            clean_terms.extend(observed_hpo_terms)\n            clean_terms.extend(excluded_hpo_terms)\n        # When we get here, clean terms contains terms with specific onsets and conflicting/redundant terms\n        # have been removed. There may be terms with no specific onset. We only add such terms if they are neither\n        # ancestors or descendants of the specific terms\n        observed_terms_without_onset = self._fix_redundancies(observed_terms_without_onset)\n        excluded_terms_without_onset = self._fix_redundancies(excluded_terms_without_onset)\n        all_term_set = set(clean_terms)\n        for t in observed_terms_without_onset:\n            addT = True\n            for s in all_term_set:\n                # keep the term with the age of onset regardless of whether it is more or less specific\n                if s.id == t.id:\n                    error = ValidationResultBuilder(self._phenopacket_id).duplicate_term(s).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n                if self._ontology.graph.is_ancestor_of(t.id, s.id):\n                    error = ValidationResultBuilder(self._phenopacket_id).redundant_term(t, s).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n                if self._ontology.graph.is_ancestor_of(s.id, t.id):\n                    error = ValidationResultBuilder(self._phenopacket_id).redundant_term(s, t).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n            if addT:\n                clean_terms.append(t)\n                all_term_set.add(t)\n        # now check for problems with excluded terms\n        for t in excluded_terms_without_onset:\n            addT = True\n            for s in all_term_set:\n                # if an excluded term is equal to or ancestor of an observed term this is an error\n                if s.id == t.id:\n                    error = ValidationResultBuilder(self._phenopacket_id).observed_and_excluded_term(term=s).build()\n                    self._errors.append(error)\n                    addT = False\n                elif self._ontology.graph.is_ancestor_of(t.id, s.id):\n                    error = ValidationResultBuilder(self._phenopacket_id).conflict(term=s, conflicting_term=t).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n            if addT:\n                clean_terms.append(t)\n                all_term_set.add(t)\n\n        return clean_terms\n\n    def has_error(self) -&gt; bool:\n        \"\"\"\n        :returns: True iff errors were encountered\n        :rtype: boolean\n        \"\"\"\n        return len(self._errors) &gt; 0\n\n    def get_error_list(self) -&gt; List[ValidationResult]:\n        \"\"\"\n        :returns: a potential empty list of errors\n        :rtype: List[str]\n        \"\"\"\n        return self._errors\n\n    def get_clean_terms(self) -&gt; List[HpTerm]:\n        return self._clean_hpo_terms\n\n\n    def get_error_string(self) -&gt; Optional[str]:\n        \"\"\"\n        create and return a string that summarizes the redundancies and conflicts that were corrected\n\n        :returns: a string summarizing errors or None if there were none\n        :rtype: Optional[str]\n        \"\"\"\n        if not self.has_error():\n            return None\n        redundancies = [e for e in self._errors if e.is_redundant()]\n        conflicts = [e for e in self._errors if e.is_conflict()]\n        e_string = \"\"\n        if len(redundancies) &gt; 0:\n            red_terms = [e.hpo_term_and_id for e in redundancies]\n            e_string = \"The following redundant terms were removed: \" + \", \".join(red_terms) + \". \"\n        if len(conflicts) &gt; 0:\n            conf_terms = [e.hpo_term_and_id for e in conflicts]\n            e_string = e_string + \"The following conflicting excluded terms were removed: \" + \", \".join(conf_terms) + \". \"\n        return e_string\n\n\n    @staticmethod\n    def qc_cohort(individual_list:List[Individual]) -&gt; List[Individual] :\n\n\n        return individual_list\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.OntologyQC.get_error_list","title":"<code>get_error_list()</code>","text":"<p>Returns:</p> Type Description <code>List[str]</code> <p>a potential empty list of errors</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>def get_error_list(self) -&gt; List[ValidationResult]:\n    \"\"\"\n    :returns: a potential empty list of errors\n    :rtype: List[str]\n    \"\"\"\n    return self._errors\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.OntologyQC.get_error_string","title":"<code>get_error_string()</code>","text":"<p>create and return a string that summarizes the redundancies and conflicts that were corrected</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>a string summarizing errors or None if there were none</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>def get_error_string(self) -&gt; Optional[str]:\n    \"\"\"\n    create and return a string that summarizes the redundancies and conflicts that were corrected\n\n    :returns: a string summarizing errors or None if there were none\n    :rtype: Optional[str]\n    \"\"\"\n    if not self.has_error():\n        return None\n    redundancies = [e for e in self._errors if e.is_redundant()]\n    conflicts = [e for e in self._errors if e.is_conflict()]\n    e_string = \"\"\n    if len(redundancies) &gt; 0:\n        red_terms = [e.hpo_term_and_id for e in redundancies]\n        e_string = \"The following redundant terms were removed: \" + \", \".join(red_terms) + \". \"\n    if len(conflicts) &gt; 0:\n        conf_terms = [e.hpo_term_and_id for e in conflicts]\n        e_string = e_string + \"The following conflicting excluded terms were removed: \" + \", \".join(conf_terms) + \". \"\n    return e_string\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.OntologyQC.has_error","title":"<code>has_error()</code>","text":"<p>Returns:</p> Type Description <code>boolean</code> <p>True iff errors were encountered</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>def has_error(self) -&gt; bool:\n    \"\"\"\n    :returns: True iff errors were encountered\n    :rtype: boolean\n    \"\"\"\n    return len(self._errors) &gt; 0\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.PhenopacketValidator","title":"<code>PhenopacketValidator</code>","text":"<p>Abstract super class for classes that validate phenopackets</p> Source code in <code>pyphetools/validation/phenopacket_validator.py</code> <pre><code>class PhenopacketValidator(metaclass=abc.ABCMeta):\n    \"\"\"\n    Abstract super class for classes that validate phenopackets\n    \"\"\"\n    def __init__(self):\n        pass\n\n    @abc.abstractmethod\n    def validate_phenopacket(self, phenopacket):\n        pass\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResult","title":"<code>ValidationResult</code>","text":"<p>A helper class to store the results of validation</p> <p>Parameters:</p> Name Type Description Default <code>phenopacket_id</code> <code>str</code> <p>Identifier of the phenopacket being validated</p> required <code>message</code> <code>str</code> <p>description of the error/warning</p> required <code>errorlevel</code> <code>ErrorLevel</code> <p>whether this result is an error or a warning</p> required <code>category</code> <code>Category</code> <p>type of QcError</p> required <code>term</code> <code>HpTerm</code> <p>HpTerm that caused the error</p> <code>None</code> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>class ValidationResult:\n    \"\"\"\n    A helper class to store the results of validation\n    :param phenopacket_id: Identifier of the phenopacket being validated\n    :type phenopacket_id: str\n    :param message: description of the error/warning\n    :type message: str\n    :param errorlevel: whether this result is an error or a warning\n    :type errorlevel: ErrorLevel\n    :param category: type of QcError\n    :type category: Category\n    :param term: HpTerm that caused the error\n    :type term: HpTerm\n\n    \"\"\"\n    def __init__(self, phenopacket_id:str, message:str, errorlevel:ErrorLevel, category:Category, term:HpTerm=None):\n        self._phenopacket_id = phenopacket_id\n        self._message = message\n        self._error_level = errorlevel\n        self._category = category\n        self._term = term\n\n    @property\n    def id(self):\n        return self._phenopacket_id\n\n    @property\n    def message(self) -&gt; str:\n        \"\"\"\n        :returns: description of the cause of ValidationResult\n        :rtype: str\n        \"\"\"\n        return self._message\n\n    @property\n    def error_level(self)-&gt; str:\n        \"\"\"\n        :returns: the name of the ErrorLevel this ValidationResult is about\n        :rtype: str\n        \"\"\"\n        return self._error_level.name\n\n    @property\n    def term(self) -&gt; Optional[HpTerm]:\n        \"\"\"\n        :returns: A string representation of the HPO term this ValidationResult is about, if applicable, or empty string\n        :rtype: Optional[str]\n        \"\"\"\n        return self._term\n\n    @property\n    def category(self) -&gt; str:\n        \"\"\"\n        :returns: the name of the Category this ValidationResult is about\n        :rtype: str\n        \"\"\"\n        return self._category.name\n\n    def is_error(self) -&gt; bool:\n        return self._error_level == ErrorLevel.ERROR\n\n    def is_warning(self) -&gt; bool:\n        return self._error_level == ErrorLevel.WARNING\n\n    def is_unfixable_error(self) -&gt; bool:\n        \"\"\"Some errors cannot be fixed automatically and require manual attention.\n\n        :returns: True iff this ValidationResult cannot be fixed automatically.\n        :rtype: bool\n        \"\"\"\n        return self._category in {Category.INSUFFICIENT_HPOS,\n                                Category.INCORRECT_ALLELE_COUNT,\n                                Category.INCORRECT_VARIANT_COUNT,\n                                Category.MALFORMED_ID,\n                                Category.MALFORMED_LABEL,\n                                Category.OBSERVED_AND_EXCLUDED\n                                }\n\n    def get_items_as_array(self) -&gt; List[str]:\n        \"\"\"\n        :returns: A list of items (strings) intended for display\n        :rtype: List[str]\n        \"\"\"\n        if self._term is None:\n            term = \"\"\n        elif isinstance(self._term, HpTerm):\n            term = self._term.hpo_term_and_id\n        else:\n            term = f\"{self._term.name} ({self._term.identifier.value})\"\n        return [self.id, self.error_level, self.category, self.message, term]\n\n    def __repr__(self):\n        return f\"{self._error_level}: {self._message}\"\n\n\n    @staticmethod\n    def get_header_fields():\n        return [\"ID\", \"Level\", \"Category\", \"Message\", \"HPO Term\"]\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResult.category","title":"<code>category</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>the name of the Category this ValidationResult is about</p>"},{"location":"api/validation/#pyphetools.validation.ValidationResult.error_level","title":"<code>error_level</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>the name of the ErrorLevel this ValidationResult is about</p>"},{"location":"api/validation/#pyphetools.validation.ValidationResult.message","title":"<code>message</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>description of the cause of ValidationResult</p>"},{"location":"api/validation/#pyphetools.validation.ValidationResult.term","title":"<code>term</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>Optional[str]</code> <p>A string representation of the HPO term this ValidationResult is about, if applicable, or empty string</p>"},{"location":"api/validation/#pyphetools.validation.ValidationResult.get_items_as_array","title":"<code>get_items_as_array()</code>","text":"<p>Returns:</p> Type Description <code>List[str]</code> <p>A list of items (strings) intended for display</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def get_items_as_array(self) -&gt; List[str]:\n    \"\"\"\n    :returns: A list of items (strings) intended for display\n    :rtype: List[str]\n    \"\"\"\n    if self._term is None:\n        term = \"\"\n    elif isinstance(self._term, HpTerm):\n        term = self._term.hpo_term_and_id\n    else:\n        term = f\"{self._term.name} ({self._term.identifier.value})\"\n    return [self.id, self.error_level, self.category, self.message, term]\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResult.is_unfixable_error","title":"<code>is_unfixable_error()</code>","text":"<p>Some errors cannot be fixed automatically and require manual attention.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True iff this ValidationResult cannot be fixed automatically.</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def is_unfixable_error(self) -&gt; bool:\n    \"\"\"Some errors cannot be fixed automatically and require manual attention.\n\n    :returns: True iff this ValidationResult cannot be fixed automatically.\n    :rtype: bool\n    \"\"\"\n    return self._category in {Category.INSUFFICIENT_HPOS,\n                            Category.INCORRECT_ALLELE_COUNT,\n                            Category.INCORRECT_VARIANT_COUNT,\n                            Category.MALFORMED_ID,\n                            Category.MALFORMED_LABEL,\n                            Category.OBSERVED_AND_EXCLUDED\n                            }\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResultBuilder","title":"<code>ValidationResultBuilder</code>","text":"<p>This class is intended for internal use only, and makes constructing ValidatioResult objects a little easier.</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>class ValidationResultBuilder:\n    \"\"\"\n    This class is intended for internal use only, and makes constructing ValidatioResult objects a little easier.\n    \"\"\"\n\n    def __init__(self, phenopacket_id:str):\n        self._phenopacket_id = phenopacket_id\n        self._error_level = ErrorLevel.UNKNOWN\n        self._category = Category.UNKNOWN\n        self._message = \"\"\n        self._term = None\n\n    def duplicate_term(self, redundant_term:HpTerm):\n        \"\"\"The HPO term is annotated as observed and excluded in the same individual. This is an unfixable error.\n\n        :param redundant_term: HPO term that is annotated as observed and excluded\n        :type redundant_term: HpTerm\n        :returns: a reference to self so this command can be used as part of a builder.\n        :rtype: ValidationResultBuilder\n        \"\"\"\n        self._error_level = ErrorLevel.WARNING\n        self._category = Category.DUPLICATE\n        self._message = f\"&lt;b&gt;{redundant_term.label}&lt;/b&gt; is listed multiple times\"\n        self._term = redundant_term\n        return self\n\n    def observed_and_excluded_term(self, term:HpTerm):\n        \"\"\"The HPO term is annotated as observed and excluded in the same individual. This is an unfixable error.\n\n        :param redundant_term: HPO term that is annotated as observed and excluded\n        :type redundant_term: HpTerm\n        :returns: a reference to self so this command can be used as part of a builder.\n        :rtype: ValidationResultBuilder\n        \"\"\"\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.OBSERVED_AND_EXCLUDED\n        self._message = f\"Term {term.label} ({term.id}) was annotated to be both observed and excluded.\"\n        self._term = term\n        return self\n\n    def redundant_term(self, ancestor_term:HpTerm, descendent_term:HpTerm):\n        \"\"\"The HPO term and one of its ancestors are both annotated as observed in the same individual.\n\n        :param ancestor_term: Ancestor HPO term that is annotated as observed\n        :type ancestor_term: HpTerm\n        :param descendent_term: Descendent HPO term that is annotated as observed\n        :type descendent_term: HpTerm\n        :returns: a reference to self so this command can be used as part of a builder.\n        :rtype: ValidationResultBuilder\n        \"\"\"\n        self._error_level = ErrorLevel.WARNING\n        self._category = Category.REDUNDANT\n        self._message = f\"&lt;b&gt;{ancestor_term.label}&lt;/b&gt; is redundant because of &lt;b&gt;{descendent_term.label}&lt;/b&gt;\"\n        self._term = ancestor_term\n        return self\n\n    def conflict(self, term:HpTerm, conflicting_term:HpTerm):\n        message = f\"{term.to_string()} conflicts with the excluded term {conflicting_term.to_string()} \"\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.CONFLICT\n        self._message = message\n        self._term = conflicting_term\n        return self\n\n    def not_measured(self, term:HpTerm):\n        self._error_level = ErrorLevel.INFORMATION\n        self._category = Category.NOT_MEASURED\n        self._term = term\n        self._message = f\"{term.hpo_term_and_id} was listed as not measured and will be omitted\"\n        return self\n\n    def insufficient_hpos(self, min_hpo:int, n_hpo:int):\n        self._message = f\"Minimum HPO terms required {min_hpo} but only {n_hpo} found\"\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.INSUFFICIENT_HPOS\n        return self\n\n    def incorrect_allele_count(self, allelic_requirement:AllelicRequirement, observed_alleles:int):\n        if allelic_requirement == AllelicRequirement.MONO_ALLELIC:\n            self._message = f\"Expected one allele for monoallelic but got {observed_alleles} alleles\"\n        elif allelic_requirement == AllelicRequirement.BI_ALLELIC:\n            self._message  = f\"Expected two alleles for biallelic but got {observed_alleles} alleles\"\n        else:\n            # should never happen\n            raise ValueError(\"attempt to create incorrect_allele_count Error without defined allelic requirement\")\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.INCORRECT_ALLELE_COUNT\n        return self\n\n    def incorrect_variant_count(self,allelic_requirement:AllelicRequirement, n_var:int):\n        if allelic_requirement == AllelicRequirement.MONO_ALLELIC:\n            self._message = f\"Expected one variant for monoallelic but got {n_var} variants\"\n        elif allelic_requirement == AllelicRequirement.BI_ALLELIC:\n            self._message  = f\"Expected one or two variants for biallelic but got {n_var} variants\"\n        else:\n            # should never happen\n            raise ValueError(\"attempt to create incorrect_variant_count Error without defined allelic requirement\")\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.INCORRECT_VARIANT_COUNT\n        return self\n\n    def set_message(self, msg):\n        self._message = msg\n        return self\n\n    def malformed_hpo_id(self, malformed_term:HpTerm):\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.MALFORMED_ID\n        self._message = f\"Malformed term {malformed_term.label} with invalid HPO id {malformed_term.id}\"\n        return self\n\n    def insufficient_disease_count(self, observed_count:int, minimum_count:int):\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.INSUFFICIENT_DISEASE_COUNT\n        self._message = f\"Individual had {observed_count} disease annotation(s) but the mininum required count is {minimum_count}\"\n        return self\n\n    def malformed_hpo_label(self, malformed_label, valid_term:HpTerm):\n        self._error_level = ErrorLevel.ERROR\n        self._category = Category.MALFORMED_LABEL\n        self._message = f\"Invalid label '{malformed_label}' found for {valid_term.name} ({valid_term.identifier.value})\"\n        self._term = valid_term\n        return self\n\n    def set_term(self, term:HpTerm):\n        self._term = term\n        return self\n\n    def build(self) -&gt; ValidationResult:\n        return ValidationResult(phenopacket_id=self._phenopacket_id, message=self._message, errorlevel=self._error_level, category=self._category, term=self._term)\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResultBuilder.duplicate_term","title":"<code>duplicate_term(redundant_term)</code>","text":"<p>The HPO term is annotated as observed and excluded in the same individual. This is an unfixable error.</p> <p>Parameters:</p> Name Type Description Default <code>redundant_term</code> <code>HpTerm</code> <p>HPO term that is annotated as observed and excluded</p> required <p>Returns:</p> Type Description <code>ValidationResultBuilder</code> <p>a reference to self so this command can be used as part of a builder.</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def duplicate_term(self, redundant_term:HpTerm):\n    \"\"\"The HPO term is annotated as observed and excluded in the same individual. This is an unfixable error.\n\n    :param redundant_term: HPO term that is annotated as observed and excluded\n    :type redundant_term: HpTerm\n    :returns: a reference to self so this command can be used as part of a builder.\n    :rtype: ValidationResultBuilder\n    \"\"\"\n    self._error_level = ErrorLevel.WARNING\n    self._category = Category.DUPLICATE\n    self._message = f\"&lt;b&gt;{redundant_term.label}&lt;/b&gt; is listed multiple times\"\n    self._term = redundant_term\n    return self\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResultBuilder.observed_and_excluded_term","title":"<code>observed_and_excluded_term(term)</code>","text":"<p>The HPO term is annotated as observed and excluded in the same individual. This is an unfixable error.</p> <p>Parameters:</p> Name Type Description Default <code>redundant_term</code> <code>HpTerm</code> <p>HPO term that is annotated as observed and excluded</p> required <p>Returns:</p> Type Description <code>ValidationResultBuilder</code> <p>a reference to self so this command can be used as part of a builder.</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def observed_and_excluded_term(self, term:HpTerm):\n    \"\"\"The HPO term is annotated as observed and excluded in the same individual. This is an unfixable error.\n\n    :param redundant_term: HPO term that is annotated as observed and excluded\n    :type redundant_term: HpTerm\n    :returns: a reference to self so this command can be used as part of a builder.\n    :rtype: ValidationResultBuilder\n    \"\"\"\n    self._error_level = ErrorLevel.ERROR\n    self._category = Category.OBSERVED_AND_EXCLUDED\n    self._message = f\"Term {term.label} ({term.id}) was annotated to be both observed and excluded.\"\n    self._term = term\n    return self\n</code></pre>"},{"location":"api/validation/#pyphetools.validation.ValidationResultBuilder.redundant_term","title":"<code>redundant_term(ancestor_term, descendent_term)</code>","text":"<p>The HPO term and one of its ancestors are both annotated as observed in the same individual.</p> <p>Parameters:</p> Name Type Description Default <code>ancestor_term</code> <code>HpTerm</code> <p>Ancestor HPO term that is annotated as observed</p> required <code>descendent_term</code> <code>HpTerm</code> <p>Descendent HPO term that is annotated as observed</p> required <p>Returns:</p> Type Description <code>ValidationResultBuilder</code> <p>a reference to self so this command can be used as part of a builder.</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def redundant_term(self, ancestor_term:HpTerm, descendent_term:HpTerm):\n    \"\"\"The HPO term and one of its ancestors are both annotated as observed in the same individual.\n\n    :param ancestor_term: Ancestor HPO term that is annotated as observed\n    :type ancestor_term: HpTerm\n    :param descendent_term: Descendent HPO term that is annotated as observed\n    :type descendent_term: HpTerm\n    :returns: a reference to self so this command can be used as part of a builder.\n    :rtype: ValidationResultBuilder\n    \"\"\"\n    self._error_level = ErrorLevel.WARNING\n    self._category = Category.REDUNDANT\n    self._message = f\"&lt;b&gt;{ancestor_term.label}&lt;/b&gt; is redundant because of &lt;b&gt;{descendent_term.label}&lt;/b&gt;\"\n    self._term = ancestor_term\n    return self\n</code></pre>"},{"location":"api/visualization/","title":"Creation module","text":"<p>This module contains code for visualizing phenopackets in Jupyter notebooks.</p>"},{"location":"api/creation/case_template_encoder/","title":"CaseTemplateEncoder","text":"<p>Class to encode data from user-provided Excel template.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>template table with clinical data</p> required <code>hpo_cr</code> <code>HpoConceptRecognizer</code> <p>HpoConceptRecognizer for text mining</p> required <code>created_by</code> <code>str</code> <p>biocurator (typically, this should be an ORCID identifier)</p> required Source code in <code>pyphetools/creation/case_template_encoder.py</code> <pre><code>class CaseTemplateEncoder:\n    \"\"\"Class to encode data from user-provided Excel template.\n\n    :param df: template table with clinical data\n    :type df: pd.DataFrame\n    :param hpo_cr: HpoConceptRecognizer for text mining\n    :type hpo_cr: pyphetools.creation.HpoConceptRecognizer\n    :param created_by: biocurator (typically, this should be an ORCID identifier)\n    :type created_by: str\n    \"\"\"\n\n    HPO_VERSION = None\n\n    def __init__(self, df:pd.DataFrame, hpo_cr:HpoConceptRecognizer, created_by:str, hpo_ontology:hpotk.MinimalOntology) -&gt; None:\n        \"\"\"constructor\n        \"\"\"\n        if not isinstance(df, pd.DataFrame):\n            raise ValueError(f\"argument \\\"df\\\" must be pandas DataFrame but was {type(df)}\")\n        self._individuals = []\n        self._errors = []\n        self._ntr_set = set()\n        header_1 = df.columns.values.tolist()\n        header_2 = df.loc[0, :].values.tolist()\n        if len(header_1) != len(header_2):\n            # should never happen unless the template file is corrupted\n            raise ValueError(\"headers are different lengths. Check template file for correctness.\")\n        # check headers are well formed\n        required_h1 = REQUIRED_H1_FIELDS\n        required_h2 = REQUIRED_H2_FIELDS\n        for i in range(len(required_h1)):\n            if header_1[i] != required_h1[i]:\n                raise ValueError(f\"Malformed header 1 field at index {i}. Expected \\\"{required_h1[i]}\\\" but got \\\"{header_1[i]}\\\"\")\n            if header_2[i] != required_h2[i]:\n                raise ValueError(f\"Malformed header 2 field at index {i}. Expected \\\"{required_h2[i]}\\\" but got \\\"{header_2[i]}\\\"\")\n        self._header_fields_1 = header_1\n        self._n_columns = len(header_1)\n        self._index_to_decoder = self._process_header(header_1=header_1, header_2=header_2, hpo_cr=hpo_cr)\n        data_df = df.iloc[1:]\n        self._check_for_duplicate_individual_ids(data_df)\n        self._is_biallelic = \"allele_2\" in header_1\n        self._allele1_d = {}\n        self._allele2_d = {}\n        for _, row in data_df.iterrows():\n            individual = self._parse_individual(row)\n            self._individuals.append(individual)\n            self._allele1_d[individual.id] = row[\"allele_1\"]\n            if self._is_biallelic:\n                self._allele2_d[individual.id] = row[\"allele_2\"]\n        CaseTemplateEncoder.HPO_VERSION = hpo_ontology.version\n        self._created_by = created_by\n        self._metadata_d = {}\n        for i in self._individuals:\n            cite = i.get_citation()\n            metadata = MetaData(created_by=created_by, citation=cite)\n            metadata.default_versions_with_hpo(CaseTemplateEncoder.HPO_VERSION)\n            self._metadata_d[i.id] = metadata\n\n    def  _process_header(self, \n                         header_1:typing.List[str], \n                         header_2:typing.List[str], \n                         hpo_cr:HpoConceptRecognizer) -&gt; typing.Dict[int, CellEncoder]:\n        index_to_decoder_d = {}\n        in_hpo_range = False\n        for i in range(self._n_columns):\n            h1 = header_1[i]\n            h2 = header_2[i]\n            if isinstance(h1, float) or len(h1) == 0:\n                raise ValueError(f\"Error: Empty column header at column {i}\")\n            if h1 == \"HPO\":\n                in_hpo_range = True\n                index_to_decoder_d[i] = NullEncoder()\n                continue\n            if h1 == \"Miscellaneous\":\n                index_to_decoder_d[i] = MiscEncoder(h1=h1, h2=h2, hpo_cr=hpo_cr)\n            elif not in_hpo_range:\n                if h1 in EXPECTED_HEADERS:\n                    index_to_decoder_d[i] = DataEncoder(h1=h1, h2=h2)\n                else:\n                    raise ValueError(f\"Malformed template header at column {i}: \\\"{h1}\\\"\")\n            elif in_hpo_range:\n                ntr =  h2 == \"NTR\"\n                encoder = HpoEncoder(h1=h1, h2=h2, ntr=ntr)\n                if ntr:\n                    self._ntr_set.add(h1)\n                    index_to_decoder_d[i] = encoder\n                elif encoder.needs_attention():\n                    self._errors.append(encoder.get_error())\n                    index_to_decoder_d[i] = NullEncoder()\n                else:\n                    index_to_decoder_d[i] = encoder\n        if not in_hpo_range:\n            raise ValueError(\"Did not find HPO boundary column\")\n        print(f\"Created encoders for {len(index_to_decoder_d)} fields\")\n        if len(self._ntr_set) &gt; 0:\n            print(\"[WARNING] Template contains new term requests (NTR). These columns will be ignored until they are replaced with HPO terms\")\n            for ntr in self._ntr_set:\n                print(\"\\tNTR: \", ntr)\n        if len(self._errors) &gt; 0:\n            for e in self._errors:\n                print(f\"ERROR: {e}\")\n        return index_to_decoder_d\n\n    def _check_for_duplicate_individual_ids(self, \n                                            df:pd.DataFrame) -&gt; None:\n        \"\"\"Check that no two individuals in the dataframe have the same identifier\n        Duplicate identifiers can lead to other errors in the code\n        An identifier is made from the combination of PMID and individual_id and must be unique\n        If there is one or mure duplicates, this function will throw a value error.\n        \"\"\"\n        if not \"individual_id\" in df.columns:\n            raise ValueError(f\"Malformed template headers - could not find column \\\"individual_id\\\"\")\n        if not \"PMID\" in df.columns:\n            raise ValueError(f\"Malformed template headers - could not find column \\\"individual_id\\\"\")\n        seen_ids = set()\n        errors = list()\n        for _, row in df.iterrows():\n            individual_id = row[\"individual_id\"]\n            pmid = row[\"PMID\"]\n            composite_id = f\"{pmid}_{individual_id}\"\n            if composite_id in seen_ids:\n                errors.append(f\"Duplicate identifier: {composite_id}\")\n            else:\n                seen_ids.add(composite_id)\n        if len(errors) &gt; 0:\n            err_str = \"\\n\".join(errors)\n            raise ValueError(err_str)\n        # else, all is OK, no duplicate ids\n\n    def _parse_individual(self, \n                          row:pd.Series) -&gt; Individual:\n        \"\"\"\n        Parse one row of the Data ingest (Excel) template, corresponding to one individual\n        \"\"\"\n        if not isinstance(row, pd.Series):\n            raise ValueError(f\"argument df must be pandas Series but was {type(row)}\")\n        data = row.values.tolist()\n        if len(data) != self._n_columns:\n            # Should never happen\n            raise ValueError(f\"Divergent number of columns: header {self._n_columns} but data row {len(data)}: {data}\")\n        data_items = {}\n        hpo_terms = list()\n        for i in range(self._n_columns):\n            encoder = self._index_to_decoder.get(i)\n            cell_contents = data[i]\n            if encoder is None:\n                print(f\"Encoder for column {i} was None for data \\\"{cell_contents}\\\"\")\n                self._debug_row(i, row)\n                raise ValueError(f\"Encoder for column {i} was None for data \\\"{cell_contents}\\\"\")\n            elif encoder.columntype == CellType.NTR:\n                continue ## cannot be use yet because new term request.\n            encoder_type = encoder.columntype()\n            if encoder_type == CellType.DATA and encoder.name in DATA_ITEMS:\n                data_items[encoder.name] = encoder.encode(cell_contents)\n            elif encoder_type == CellType.HPO:\n                try:\n                    hpoterm = encoder.encode(cell_contents)\n                    if hpoterm is not None:\n                        hpo_terms.append(hpoterm)\n                except Exception as hpo_parse_exception:\n                    errr = f\"Could not parse contents of HPO column {encoder.name}: {cell_contents} because of {str(hpo_parse_exception)}\"\n                    print(errr)\n                    raise ValueError(errr)\n            elif encoder_type == CellType.MISC:\n                term_list = encoder.encode(cell_contents=cell_contents)\n                for trm in term_list:\n                    hpo_terms.append(trm)\n        # Check we have all of the items we need\n        for item in data_items.keys():\n            if item not in DATA_ITEMS:\n                raise ValueError(f\"Unrecognized data item: \\\"{item}\\\"\")\n        #Note that allele_2 is optional\n        if len(data_items) &lt; len(DATA_ITEMS) - 1:\n            raise ValueError(f\"Insufficient data items: \\\"{data_items}\\\"\")\n        # If we get here, we can contruct an individual\n        individual_id = data_items.get('individual_id')\n        if individual_id is None or isinstance(individual_id, float) or len(individual_id) == 0:\n            raise ValueError(f\"Empty individual_id field for {row}\")\n        pmid = data_items.get(\"PMID\")\n        title = data_items.get(\"title\")\n        if pmid is None or isinstance(pmid, float) or not pmid.startswith(\"PMID\"):\n            raise ValueError(f\"Could not find PubMed identifier for {individual_id}\")\n        if title is None or isinstance(title, float) or len(title) &lt; 5:\n            raise ValueError(f\"Could not find valid title for {individual_id}\")\n        citation = Citation(pmid=pmid, title=title)\n        sex = data_items.get(\"sex\")\n        if sex == \"M\":\n            sex = Constants.MALE_SYMBOL\n        elif sex == \"F\":\n            sex = Constants.FEMALE_SYMBOL\n        elif sex == \"O\":\n            sex = Constants.OTHER_SEX_SYMBOL\n        elif sex == \"U\":\n            sex = Constants.UNKNOWN_SEX_SYMBOL\n        else:\n            raise ValueError(f\"Unrecognized sex symbol: {sex} for individual \\\"{individual_id}\\\"\")\n        onset_age = data_items.get(AGE_OF_ONSET_FIELDNAME)\n        if onset_age is not None and isinstance(onset_age, str):\n            onset_age = PyPheToolsAge.get_age_pp201(onset_age)\n        else:\n            onset_age = None\n        encounter_age = data_items.get(AGE_AT_LAST_ENCOUNTER_FIELDNAME)\n        if encounter_age is not None and isinstance(encounter_age, str):\n            encounter_age = PyPheToolsAge.get_age_pp201(encounter_age)\n        else:\n            encounter_age = None\n        vitStat = None\n        # deceased is a required field from version 0.9.112 on\n        decsd = data_items.get(\"deceased\")\n        if decsd == \"yes\" and encounter_age is not None:\n            vitStat = VitalStatus(status=VitalStatus.Status.DECEASED, time_of_death=encounter_age)\n        elif decsd == \"no\":\n            vitStat = VitalStatus(status=VitalStatus.Status.ALIVE)\n        else:\n            vitStat = VitalStatus(status=VitalStatus.Status.UNKNOWN_STATUS)\n        disease_id = data_items.get(\"disease_id\")\n        disease_label = data_items.get(\"disease_label\")\n        # common error -- e.g. PMID: 3000312 or OMIM: 600123 (whitespace after colon)\n        for item in [pmid, disease_id]:\n            if \" \" in item:\n                raise ValueError(f\"Found illegal whitespace in {item}. Please remove it and try again\")\n        disease = Disease(disease_id=disease_id, disease_label=disease_label)\n        return Individual(individual_id=individual_id,\n                            citation=citation,\n                            hpo_terms=hpo_terms,\n                            sex=sex,\n                            age_of_onset=onset_age,\n                            age_at_last_encounter=encounter_age,\n                            vital_status=vitStat,\n                            disease=disease)\n\n    def _debug_row(self, target_idx:int, row:pd.Series):\n        row_items = list(row)\n        for j in range(len(row_items)):\n            hdr = self._header_fields_1[j]\n            if j == target_idx:\n                print(f\"[{j}] *** {hdr}={row_items[j]}  ***\")\n            else:\n                print(f\"[{j}] {hdr}={row_items[j]}\")\n\n    def get_individuals(self) -&gt; typing.List[Individual]:\n        return self._individuals\n\n    def get_allele1_d(self)-&gt; typing.Dict[str,str]:\n        return self._allele1_d\n\n    def get_allele2_d(self)-&gt; typing.Dict[str,str]:\n        return self._allele2_d\n\n    def _is_biallelic(self) -&gt; bool:\n        return self._is_biallelic\n\n    def get_metadata_d(self) -&gt; typing.Dict[str,MetaData]:\n        return self._metadata_d\n\n    def get_phenopackets(self) -&gt; typing.List[PPKt.Phenopacket]:\n        ppack_list = []\n        for individual in self._individuals:\n            cite = individual.get_citation()\n            metadata = MetaData(created_by=self._created_by, citation=cite)\n            metadata.default_versions_with_hpo(CaseTemplateEncoder.HPO_VERSION)\n            phenopckt = individual.to_ga4gh_phenopacket(metadata=metadata)\n            ppack_list.append(phenopckt)\n        return ppack_list\n\n\n\n    def _transform_individuals_to_phenopackets(self, \n                                               individual_list:typing.List[Individual]):\n        \"\"\"Create one phenopacket for each of the individuals\n\n        :param individual_list: List of individual objects\n        :type individual_list:List[Individual]\n        :returns: list of corresponding phenopackets\n        :rtype: List[PPKt.Phenopacket]\n        \"\"\"\n        ppkt_list = list()\n        if self._created_by is None:\n            created_by = 'pyphetools'\n        else:\n            created_by = self._created_by\n        for individual in individual_list:\n            cite = individual.get_citation()\n            metadata = MetaData(created_by=created_by, citation=cite)\n            metadata.default_versions_with_hpo(CaseTemplateEncoder.HPO_VERSION)\n            phenopckt = individual.to_ga4gh_phenopacket(metadata=metadata)\n            ppkt_list.append(phenopckt)\n        return ppkt_list\n\n    def output_individuals_as_phenopackets(self, \n                                           individual_list:typing.List[Individual], \n                                           outdir:str=\"phenopackets\") -&gt; None:\n        \"\"\"write a list of Individual objects to file in GA4GH Phenopacket format\n        Note that the individual_list needs to be passed to this object, because we expect that\n        the QC code will have been used to cleanse the data of redundancies etc before output.\n        We use the statefullness to keep track of the created_by argument from the constructor\n\n        :param outdir: Path to output directory. Defaults to \"phenopackets\". Created if not exists.\n        :type outdir: str\n        \"\"\"\n        if os.path.isfile(outdir):\n            raise ValueError(f\"Attempt to create directory with name of existing file {outdir}\")\n        if not os.path.isdir(outdir):\n            os.makedirs(outdir)\n        written = 0\n\n        if self._created_by is None:\n            created_by = 'pyphetools'\n        else:\n            created_by = self._created_by\n        for individual in individual_list:\n            cite = individual.get_citation()\n            metadata = MetaData(created_by=created_by, citation=cite)\n            metadata.default_versions_with_hpo(CaseTemplateEncoder.HPO_VERSION)\n            phenopckt = individual.to_ga4gh_phenopacket(metadata=metadata)\n            json_string = MessageToJson(phenopckt)\n            pmid = cite.pmid\n            if pmid is None:\n                fname = \"phenopacket_\" + individual.id\n            else:\n                pmid = pmid.replace(\" \", \"\").replace(\":\", \"_\")\n                fname = pmid + \"_\" + individual.id\n            fname = re.sub('[^A-Za-z0-9\\_\\-]', '', fname)  # remove any illegal characters from filename\n            fname = fname.replace(\" \", \"_\") + \".json\"\n            outpth = os.path.join(outdir, fname)\n            with open(outpth, \"wt\") as fh:\n                fh.write(json_string)\n                written += 1\n        print(f\"We output {written} GA4GH phenopackets to the directory {outdir}\")\n\n\n    def print_individuals_as_phenopackets(self, \n                                          individual_list:typing.List[Individual]) -&gt; None:\n        \"\"\"Function designed to show all phenopackets in a notebook for Q/C\n        :param individual_list: List of individual objects\n        :type individual_list:List[Individual]\n        \"\"\"\n        ppkt_list = self._transform_individuals_to_phenopackets(individual_list)\n        for ppkt in ppkt_list:\n            json_string = MessageToJson(ppkt)\n            print(\"####\")\n            print(json_string)\n\n\n    def to_summary(self) -&gt; pd.DataFrame:\n        \"\"\"\n\n        The table provides a summary of the table that was parsed from the input file. If there were errors, it\n        provides enough feedback so that the user knows what needs to be fixed\n\n        :returns: an table with status of parse\n        :rtype: pd.DataFrame\n        \"\"\"\n        n_error = 0\n        items = []\n        for e in self._errors:\n            n_error += 1\n            d = {'item': f\"Error {n_error}\", 'value': e}\n            items.append(d)\n        d = {'item': 'created by', 'value':self._created_by}\n        items.append(d)\n        d = {'item':'number of individuals', 'value': str(len(self._individuals))}\n        items.append(d)\n        n_hpo_columns = sum([1 for encoder in self._index_to_decoder.values() if encoder.is_hpo()])\n        d = {'item':'number of HPO columns', 'value': str(n_hpo_columns)}\n        items.append(d)\n        return pd.DataFrame(items)\n</code></pre>"},{"location":"api/creation/case_template_encoder/#pyphetools.creation.CaseTemplateEncoder.__init__","title":"<code>__init__(df, hpo_cr, created_by, hpo_ontology)</code>","text":"<p>constructor</p> Source code in <code>pyphetools/creation/case_template_encoder.py</code> <pre><code>def __init__(self, df:pd.DataFrame, hpo_cr:HpoConceptRecognizer, created_by:str, hpo_ontology:hpotk.MinimalOntology) -&gt; None:\n    \"\"\"constructor\n    \"\"\"\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(f\"argument \\\"df\\\" must be pandas DataFrame but was {type(df)}\")\n    self._individuals = []\n    self._errors = []\n    self._ntr_set = set()\n    header_1 = df.columns.values.tolist()\n    header_2 = df.loc[0, :].values.tolist()\n    if len(header_1) != len(header_2):\n        # should never happen unless the template file is corrupted\n        raise ValueError(\"headers are different lengths. Check template file for correctness.\")\n    # check headers are well formed\n    required_h1 = REQUIRED_H1_FIELDS\n    required_h2 = REQUIRED_H2_FIELDS\n    for i in range(len(required_h1)):\n        if header_1[i] != required_h1[i]:\n            raise ValueError(f\"Malformed header 1 field at index {i}. Expected \\\"{required_h1[i]}\\\" but got \\\"{header_1[i]}\\\"\")\n        if header_2[i] != required_h2[i]:\n            raise ValueError(f\"Malformed header 2 field at index {i}. Expected \\\"{required_h2[i]}\\\" but got \\\"{header_2[i]}\\\"\")\n    self._header_fields_1 = header_1\n    self._n_columns = len(header_1)\n    self._index_to_decoder = self._process_header(header_1=header_1, header_2=header_2, hpo_cr=hpo_cr)\n    data_df = df.iloc[1:]\n    self._check_for_duplicate_individual_ids(data_df)\n    self._is_biallelic = \"allele_2\" in header_1\n    self._allele1_d = {}\n    self._allele2_d = {}\n    for _, row in data_df.iterrows():\n        individual = self._parse_individual(row)\n        self._individuals.append(individual)\n        self._allele1_d[individual.id] = row[\"allele_1\"]\n        if self._is_biallelic:\n            self._allele2_d[individual.id] = row[\"allele_2\"]\n    CaseTemplateEncoder.HPO_VERSION = hpo_ontology.version\n    self._created_by = created_by\n    self._metadata_d = {}\n    for i in self._individuals:\n        cite = i.get_citation()\n        metadata = MetaData(created_by=created_by, citation=cite)\n        metadata.default_versions_with_hpo(CaseTemplateEncoder.HPO_VERSION)\n        self._metadata_d[i.id] = metadata\n</code></pre>"},{"location":"api/creation/case_template_encoder/#pyphetools.creation.CaseTemplateEncoder.output_individuals_as_phenopackets","title":"<code>output_individuals_as_phenopackets(individual_list, outdir='phenopackets')</code>","text":"<p>write a list of Individual objects to file in GA4GH Phenopacket format Note that the individual_list needs to be passed to this object, because we expect that the QC code will have been used to cleanse the data of redundancies etc before output. We use the statefullness to keep track of the created_by argument from the constructor</p> <p>Parameters:</p> Name Type Description Default <code>outdir</code> <code>str</code> <p>Path to output directory. Defaults to \"phenopackets\". Created if not exists.</p> <code>'phenopackets'</code> Source code in <code>pyphetools/creation/case_template_encoder.py</code> <pre><code>def output_individuals_as_phenopackets(self, \n                                       individual_list:typing.List[Individual], \n                                       outdir:str=\"phenopackets\") -&gt; None:\n    \"\"\"write a list of Individual objects to file in GA4GH Phenopacket format\n    Note that the individual_list needs to be passed to this object, because we expect that\n    the QC code will have been used to cleanse the data of redundancies etc before output.\n    We use the statefullness to keep track of the created_by argument from the constructor\n\n    :param outdir: Path to output directory. Defaults to \"phenopackets\". Created if not exists.\n    :type outdir: str\n    \"\"\"\n    if os.path.isfile(outdir):\n        raise ValueError(f\"Attempt to create directory with name of existing file {outdir}\")\n    if not os.path.isdir(outdir):\n        os.makedirs(outdir)\n    written = 0\n\n    if self._created_by is None:\n        created_by = 'pyphetools'\n    else:\n        created_by = self._created_by\n    for individual in individual_list:\n        cite = individual.get_citation()\n        metadata = MetaData(created_by=created_by, citation=cite)\n        metadata.default_versions_with_hpo(CaseTemplateEncoder.HPO_VERSION)\n        phenopckt = individual.to_ga4gh_phenopacket(metadata=metadata)\n        json_string = MessageToJson(phenopckt)\n        pmid = cite.pmid\n        if pmid is None:\n            fname = \"phenopacket_\" + individual.id\n        else:\n            pmid = pmid.replace(\" \", \"\").replace(\":\", \"_\")\n            fname = pmid + \"_\" + individual.id\n        fname = re.sub('[^A-Za-z0-9\\_\\-]', '', fname)  # remove any illegal characters from filename\n        fname = fname.replace(\" \", \"_\") + \".json\"\n        outpth = os.path.join(outdir, fname)\n        with open(outpth, \"wt\") as fh:\n            fh.write(json_string)\n            written += 1\n    print(f\"We output {written} GA4GH phenopackets to the directory {outdir}\")\n</code></pre>"},{"location":"api/creation/case_template_encoder/#pyphetools.creation.CaseTemplateEncoder.print_individuals_as_phenopackets","title":"<code>print_individuals_as_phenopackets(individual_list)</code>","text":"<p>Function designed to show all phenopackets in a notebook for Q/C</p> <p>Parameters:</p> Name Type Description Default <code>individual_list</code> <code>List[Individual]</code> <p>List of individual objects</p> required Source code in <code>pyphetools/creation/case_template_encoder.py</code> <pre><code>def print_individuals_as_phenopackets(self, \n                                      individual_list:typing.List[Individual]) -&gt; None:\n    \"\"\"Function designed to show all phenopackets in a notebook for Q/C\n    :param individual_list: List of individual objects\n    :type individual_list:List[Individual]\n    \"\"\"\n    ppkt_list = self._transform_individuals_to_phenopackets(individual_list)\n    for ppkt in ppkt_list:\n        json_string = MessageToJson(ppkt)\n        print(\"####\")\n        print(json_string)\n</code></pre>"},{"location":"api/creation/case_template_encoder/#pyphetools.creation.CaseTemplateEncoder.to_summary","title":"<code>to_summary()</code>","text":"<p>The table provides a summary of the table that was parsed from the input file. If there were errors, it provides enough feedback so that the user knows what needs to be fixed</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>an table with status of parse</p> Source code in <code>pyphetools/creation/case_template_encoder.py</code> <pre><code>def to_summary(self) -&gt; pd.DataFrame:\n    \"\"\"\n\n    The table provides a summary of the table that was parsed from the input file. If there were errors, it\n    provides enough feedback so that the user knows what needs to be fixed\n\n    :returns: an table with status of parse\n    :rtype: pd.DataFrame\n    \"\"\"\n    n_error = 0\n    items = []\n    for e in self._errors:\n        n_error += 1\n        d = {'item': f\"Error {n_error}\", 'value': e}\n        items.append(d)\n    d = {'item': 'created by', 'value':self._created_by}\n    items.append(d)\n    d = {'item':'number of individuals', 'value': str(len(self._individuals))}\n    items.append(d)\n    n_hpo_columns = sum([1 for encoder in self._index_to_decoder.values() if encoder.is_hpo()])\n    d = {'item':'number of HPO columns', 'value': str(n_hpo_columns)}\n    items.append(d)\n    return pd.DataFrame(items)\n</code></pre>"},{"location":"api/creation/citation/","title":"CohortEncoder","text":"<p>encapsulate information about a citation that we add to the metadata for display</p> Source code in <code>pyphetools/creation/citation.py</code> <pre><code>class Citation:\n    \"\"\"encapsulate information about a citation that we add to the metadata for display\n    \"\"\"\n\n    def __init__(self, pmid:str, title:str) -&gt; None:\n        \"\"\"\n        :param pmid: PubMed identifier for the publication in which this individual was described (e.g. PMID:321..).\n        :type pmid: str\n        :param title: Title of the publication in which this individual was described.\n        :type title: str\n        \"\"\"\n        if pmid is None or isinstance(pmid, float) or not pmid.startswith(\"PMID\"):\n            raise ValueError(f\"Could not find PubMed identifier\")\n        if title is None or isinstance(title, float) or len(title) &lt; 5:\n            raise ValueError(f\"Could not find valid title\")\n        self._pmid = pmid\n        self._title = title\n\n    @property\n    def pmid(self) -&gt; str:\n        return self._pmid\n\n    @property\n    def title(self) -&gt; str:\n        return self._title\n\n    def to_external_reference(self) -&gt; ExternalReference202:\n        \"\"\"\n        :returns: an ExternalReference object representing this PubMed citation\n        :rtype: ExternalReference202\n        \"\"\"\n        pm_number = self._pmid.replace(\"PMID:\", \"\")\n        pm_url = f\"https://pubmed.ncbi.nlm.nih.gov/{pm_number}\" \n        return ExternalReference202(id=self._pmid,\n                                    reference=pm_url,\n                                    description=self._title)\n</code></pre>"},{"location":"api/creation/citation/#pyphetools.creation.Citation.__init__","title":"<code>__init__(pmid, title)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>pmid</code> <code>str</code> <p>PubMed identifier for the publication in which this individual was described (e.g. PMID:321..).</p> required <code>title</code> <code>str</code> <p>Title of the publication in which this individual was described.</p> required Source code in <code>pyphetools/creation/citation.py</code> <pre><code>def __init__(self, pmid:str, title:str) -&gt; None:\n    \"\"\"\n    :param pmid: PubMed identifier for the publication in which this individual was described (e.g. PMID:321..).\n    :type pmid: str\n    :param title: Title of the publication in which this individual was described.\n    :type title: str\n    \"\"\"\n    if pmid is None or isinstance(pmid, float) or not pmid.startswith(\"PMID\"):\n        raise ValueError(f\"Could not find PubMed identifier\")\n    if title is None or isinstance(title, float) or len(title) &lt; 5:\n        raise ValueError(f\"Could not find valid title\")\n    self._pmid = pmid\n    self._title = title\n</code></pre>"},{"location":"api/creation/citation/#pyphetools.creation.Citation.to_external_reference","title":"<code>to_external_reference()</code>","text":"<p>Returns:</p> Type Description <code>ExternalReference202</code> <p>an ExternalReference object representing this PubMed citation</p> Source code in <code>pyphetools/creation/citation.py</code> <pre><code>def to_external_reference(self) -&gt; ExternalReference202:\n    \"\"\"\n    :returns: an ExternalReference object representing this PubMed citation\n    :rtype: ExternalReference202\n    \"\"\"\n    pm_number = self._pmid.replace(\"PMID:\", \"\")\n    pm_url = f\"https://pubmed.ncbi.nlm.nih.gov/{pm_number}\" \n    return ExternalReference202(id=self._pmid,\n                                reference=pm_url,\n                                description=self._title)\n</code></pre>"},{"location":"api/creation/cohort_encoder/","title":"CohortEncoder","text":"<p>               Bases: <code>AbstractEncoder</code></p> <p>Map a table of data to Individual/GA4GH Phenopacket Schema objects</p> <p>Encode a cohort of individuals with clinical data in a table as a collection of GA4GH Phenopackets This classes uses a collection of ColumnMapper objects to map a table using the get_individuals or output_phenopackets methods.</p> <p>The column_mapper_d is a dictionary with key=column names, and value=Mapper objects. These mappers are responsible for mapping HPO terms. The agemapper and the sexmapper are specialized for the respective columns. The variant mapper is useful if there is a single variant column that is all HGVS or structural variants. In some cases, it is preferable to use the variant_dictionary, which has key=string (cell contents) and value=Hgvs or StructuralVariant object.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>tabular data about a cohort</p> required <code>hpo_cr</code> <code>HpoConceptRecognizer</code> <p>HpoConceptRecognizer for text mining</p> required <code>column_mapper_list</code> <code>List[ColumnMapper]</code> <p>list of ColumnMapper objects</p> required <code>individual_column_name</code> <code>str</code> <p>label of column with individual/proband/patient identifier</p> required <code>metadata</code> <code>PPkt.MetaData</code> <p>GA4GH MetaData object</p> required <code>age_of_onset_mapper</code> <code>AgeColumnMapper</code> <p>Mapper for the Age of onset column. Defaults to AgeColumnMapper.not_provided()</p> <code>not_provided()</code> <code>age_at_last_encounter_mapper</code> <code>AgeColumnMapper</code> <p>Mapper for the Age at last clinical encounter column. Defaults to AgeColumnMapper.not_provided()</p> <code>not_provided()</code> <code>sexmapper</code> <code>SexColumnMapper</code> <p>Mapper for the Sex column. Defaults to SexColumnMapper.not_provided().</p> <code>not_provided()</code> <code>variant_mapper</code> <code>VariantColumnMapper</code> <p>column mapper for HGVS-encoded variant column.</p> <code>None</code> Source code in <code>pyphetools/creation/cohort_encoder.py</code> <pre><code>class CohortEncoder(AbstractEncoder):\n    \"\"\"Map a table of data to Individual/GA4GH Phenopacket Schema objects\n\n    Encode a cohort of individuals with clinical data in a table as a collection of GA4GH Phenopackets\n    This classes uses a collection of ColumnMapper objects to map a table using the\n    get_individuals or output_phenopackets methods.\n\n    The column_mapper_d is a dictionary with key=column names, and value=Mapper objects. These mappers are responsible\n    for mapping HPO terms. The agemapper and the sexmapper are specialized for the respective columns. The\n    variant mapper is useful if there is a single variant column that is all HGVS or structural variants. In some\n    cases, it is preferable to use the variant_dictionary, which has key=string (cell contents) and value=Hgvs or\n    StructuralVariant object.\n\n    :param df: tabular data about a cohort\n    :type df: pd.DataFrame\n    :param hpo_cr: HpoConceptRecognizer for text mining\n    :type hpo_cr: pyphetools.creation.HpoConceptRecognizer\n    :param column_mapper_list: list of ColumnMapper objects\n    :type column_mapper_list: List[pyphetools.creation.ColumnMapper]\n    :param individual_column_name: label of column with individual/proband/patient identifier\n    :type individual_column_name: str\n    :param metadata: GA4GH MetaData object\n    :type metadata: PPkt.MetaData\n    :param age_of_onset_mapper:Mapper for the Age of onset column. Defaults to AgeColumnMapper.not_provided()\n    :type age_of_onset_mapper: pyphetools.creation.AgeColumnMapper\n    :param age_at_last_encounter_mapper:Mapper for the Age at last clinical encounter column. Defaults to AgeColumnMapper.not_provided()\n    :type age_at_last_encounter_mapper: pyphetools.creation.AgeColumnMapper\n    :param sexmapper: Mapper for the Sex column. Defaults to SexColumnMapper.not_provided().\n    :type sexmapper: pyphetools.creation.SexColumnMapper\n    :param variant_mapper: column mapper for HGVS-encoded variant column.\n    :type variant_mapper: pyphetools.creation.VariantColumnMapper\n    :raises: ValueError - several of the input arguments are checked.\n    \"\"\"\n\n    def __init__(self,\n                 df: pd.DataFrame,\n                 hpo_cr: HpoConceptRecognizer,\n                 column_mapper_list: typing.List[ColumnMapper],\n                 individual_column_name: str,\n                 metadata,\n                 age_of_onset_mapper: AgeColumnMapper = AgeColumnMapper.not_provided(),\n                 age_at_last_encounter_mapper: AgeColumnMapper = AgeColumnMapper.not_provided(),\n                 sexmapper: SexColumnMapper = SexColumnMapper.not_provided(),\n                 variant_mapper: VariantColumnMapper = None,\n                 delimiter: str = None):\n        \"\"\"Constructor\n        \"\"\"\n        super().__init__(metadata=metadata)\n        if not isinstance(hpo_cr, HpoConceptRecognizer):\n            raise ValueError(\n                \"concept_recognizer argument must be HpoConceptRecognizer but was {type(concept_recognizer)}\")\n        self._hpo_concept_recognizer = hpo_cr\n        if not isinstance(df, pd.DataFrame):\n            raise ValueError(f\"df argument must be pandas data frame but was {type(df)}\")\n        if not isinstance(column_mapper_list, list):\n            raise ValueError(f\"column_mapper_list argument must be a list but was {type(column_mapper_list)}\")\n        if not isinstance(individual_column_name, str):\n            raise ValueError(f\"individual_column_name argument must be a string but was {type(individual_column_name)}\")\n        if variant_mapper is not None and not isinstance(variant_mapper, VariantColumnMapper):\n            raise ValueError(f\"variant_mapper argument must be VariantColumnMapper but was {type(variant_mapper)}\")\n        self._df = df.astype(str)\n        self._column_mapper_list = column_mapper_list\n        self._id_column_name = individual_column_name\n        self._age_of_onset_mapper = age_of_onset_mapper\n        self._age_at_last_encounter_mapper = age_at_last_encounter_mapper\n        self._sex_mapper = sexmapper\n        self._disease = None\n        self._variant_mapper = variant_mapper\n        self._disease_dictionary = None\n        self._delimiter = delimiter\n\n    def preview_dataframe(self):\n        \"\"\"\n        Generate a dataframe with a preview of the parsed contents\n\n        :returns: a DataFrame representing the cohort to check results\n        :rtype: pd.DataFrame\n        \"\"\"\n        df = self._df.reset_index()  # make sure indexes pair with number of rows\n        individuals = []\n        age_column_name = self._age_of_onset_mapper.get_column_name()\n        sex_column_name = self._sex_mapper.get_column_name()\n        for index, row in df.iterrows():\n            individual_id = row[self._id_column_name]\n            if age_column_name == Constants.NOT_PROVIDED:\n                age = Constants.NOT_PROVIDED\n            else:\n                age_cell_contents = row[age_column_name]\n                age = self._age_mapper.map_cell(age_cell_contents)\n            sex_cell_contents = row[sex_column_name]\n            sex = self._sex_mapper.map_cell(sex_cell_contents)\n            hpo_terms = []\n            for column_mapper in self.__column_mapper_list:\n                column_name = column_mapper.get_column_name()\n                cell_contents = row[column_name]\n                # Empty cells are often represented as float non-a-number by Pandas\n                if isinstance(cell_contents, float) and isnan(cell_contents):\n                    continue\n                terms = column_mapper.map_cell(row[column_name])\n                hpo_terms.extend(terms)\n            hpo_string = \"\\n\".join([h.to_string() for h in hpo_terms])\n            d = {'id': individual_id,\n                 'sex': sex,\n                 'age': age,\n                 'phenotypic features': hpo_string}\n            individuals.append(d)\n        df = pd.DataFrame(individuals)\n        return df.set_index('id')\n\n    def set_disease(self, disease: Disease):\n        \"\"\"Set the disease diagnosis for all patients in the cohort\n\n        If all patients in the cohort have the same disease we can set it with this method\n        :param disease: Disease diagnosis for the individuals in this cohort\n        :type disease: Disease\n        \"\"\"\n        self._disease = disease\n        self._disease_dictionary = None\n\n    def set_disease_dictionary(self,\n                               disease_d: typing.Dict[str, Disease]):\n        \"\"\"Set the dictionary of disease ontology terms\n\n        For tables with multiple different diseases, we provide a dictionary that has as key\n        the string used in the original table and as value\n        \"\"\"\n        self._disease_dictionary = disease_d\n        self._disease = None\n\n    def _get_age(row: pd.Series, mapper: AgeColumnMapper):\n        import math\n        column_name = mapper.get_column_name()\n        if column_name == Constants.NOT_PROVIDED:\n            return None\n        age_cell_contents = row[column_name]\n        if isinstance(age_cell_contents, float) and math.isnan(age_cell_contents):\n            return None\n        try:\n            age = mapper.map_cell(age_cell_contents)\n        except Exception as ee:\n            print(f\"Warning: Could not parse age {ee}. Setting age to \\\"not provided\\\"\")\n            age = None\n        return age\n\n    def get_individuals(self) -&gt; typing.List[Individual]:\n        \"\"\"Get a list of all Individual objects in the cohort\n\n        :returns: a list of all Individual objects in the cohort\n        :rtype: List[Individual]\n        \"\"\"\n        # make sure indexes pair with number of rows, if needed\n        if not self._df.index.name in self._df.columns:\n            df = self._df.reset_index()\n        individuals = []\n        sex_column_name = self._sex_mapper.get_column_name()\n        if self._variant_mapper is None:\n            variant_colname = None\n            genotype_colname = None\n        else:\n            variant_colname = self._variant_mapper.get_variant_column_name()\n            genotype_colname = self._variant_mapper.get_genotype_colname()\n        for index, row in df.iterrows():\n            individual_id = row[self._id_column_name]\n            age_of_onset = CohortEncoder._get_age(row, self._age_of_onset_mapper)\n            age_last_encounter = CohortEncoder._get_age(row, self._age_at_last_encounter_mapper)\n            if sex_column_name == Constants.NOT_PROVIDED:\n                sex = self._sex_mapper.map_cell(Constants.NOT_PROVIDED)\n            else:\n                sex_cell_contents = row[sex_column_name]\n                sex = self._sex_mapper.map_cell(sex_cell_contents)\n            hpo_terms = []\n            for column_mapper in self._column_mapper_list:\n                column_name = column_mapper.get_column_name()\n                if column_name not in df.columns:\n                    raise ValueError(f\"Did not find column name '{column_name}' in dataframe -- check spelling!\")\n                cell_contents = row[column_name]\n                # Empty cells are often represented as float non-a-number by Pandas\n                if isinstance(cell_contents, float) and isnan(cell_contents):\n                    continue\n                terms = column_mapper.map_cell(cell_contents)\n                hpo_terms.extend(terms)\n            if variant_colname is not None:\n                variant_cell_contents = row[variant_colname]\n                if genotype_colname is not None:\n                    genotype_cell_contents = row[genotype_colname]\n                else:\n                    genotype_cell_contents = None\n                if self._variant_mapper is not None:\n                    interpretation_list = self._variant_mapper.map_cell(variant_cell_contents, genotype_cell_contents)\n                else:\n                    interpretation_list = []\n            else:\n                interpretation_list = []\n            if self._disease_dictionary is not None and self._disease is None:\n                if individual_id not in self._disease_dictionary:\n                    raise ValueError(f\"Could not find disease link for {individual_id}\")\n                disease = self._disease_dictionary.get(individual_id)\n                indi = Individual(individual_id=individual_id,\n                                  sex=sex,\n                                  age_of_onset=age_of_onset,\n                                  age_at_last_encounter=age_last_encounter,\n                                  hpo_terms=hpo_terms,\n                                  citation=self._metadata.get_citation(),\n                                  interpretation_list=interpretation_list,\n                                  disease=disease)\n            elif self._disease_dictionary is None and self._disease is not None:\n                indi = Individual(individual_id=individual_id,\n                                  sex=sex,\n                                  age_of_onset=age_of_onset,\n                                  age_at_last_encounter=age_last_encounter,\n                                  hpo_terms=hpo_terms,\n                                  citation=self._metadata.get_citation(),\n                                  interpretation_list=interpretation_list,\n                                  disease=self._disease)\n            else:\n                raise ValueError(f\"Could not find disease data for '{individual_id}'\")\n            individuals.append(indi)\n        if self._age_of_onset_mapper.has_error():\n            print(self._age_of_onset_mapper.error_summary())\n        if self._age_at_last_encounter_mapper.has_error():\n            print(self._age_at_last_encounter_mapper.error_summary())\n        if self._sex_mapper.has_error():\n            print(self._sex_mapper.error_summary())\n        return individuals\n</code></pre>"},{"location":"api/creation/cohort_encoder/#pyphetools.creation.CohortEncoder.__init__","title":"<code>__init__(df, hpo_cr, column_mapper_list, individual_column_name, metadata, age_of_onset_mapper=AgeColumnMapper.not_provided(), age_at_last_encounter_mapper=AgeColumnMapper.not_provided(), sexmapper=SexColumnMapper.not_provided(), variant_mapper=None, delimiter=None)</code>","text":"<p>Constructor</p> Source code in <code>pyphetools/creation/cohort_encoder.py</code> <pre><code>def __init__(self,\n             df: pd.DataFrame,\n             hpo_cr: HpoConceptRecognizer,\n             column_mapper_list: typing.List[ColumnMapper],\n             individual_column_name: str,\n             metadata,\n             age_of_onset_mapper: AgeColumnMapper = AgeColumnMapper.not_provided(),\n             age_at_last_encounter_mapper: AgeColumnMapper = AgeColumnMapper.not_provided(),\n             sexmapper: SexColumnMapper = SexColumnMapper.not_provided(),\n             variant_mapper: VariantColumnMapper = None,\n             delimiter: str = None):\n    \"\"\"Constructor\n    \"\"\"\n    super().__init__(metadata=metadata)\n    if not isinstance(hpo_cr, HpoConceptRecognizer):\n        raise ValueError(\n            \"concept_recognizer argument must be HpoConceptRecognizer but was {type(concept_recognizer)}\")\n    self._hpo_concept_recognizer = hpo_cr\n    if not isinstance(df, pd.DataFrame):\n        raise ValueError(f\"df argument must be pandas data frame but was {type(df)}\")\n    if not isinstance(column_mapper_list, list):\n        raise ValueError(f\"column_mapper_list argument must be a list but was {type(column_mapper_list)}\")\n    if not isinstance(individual_column_name, str):\n        raise ValueError(f\"individual_column_name argument must be a string but was {type(individual_column_name)}\")\n    if variant_mapper is not None and not isinstance(variant_mapper, VariantColumnMapper):\n        raise ValueError(f\"variant_mapper argument must be VariantColumnMapper but was {type(variant_mapper)}\")\n    self._df = df.astype(str)\n    self._column_mapper_list = column_mapper_list\n    self._id_column_name = individual_column_name\n    self._age_of_onset_mapper = age_of_onset_mapper\n    self._age_at_last_encounter_mapper = age_at_last_encounter_mapper\n    self._sex_mapper = sexmapper\n    self._disease = None\n    self._variant_mapper = variant_mapper\n    self._disease_dictionary = None\n    self._delimiter = delimiter\n</code></pre>"},{"location":"api/creation/cohort_encoder/#pyphetools.creation.CohortEncoder.get_individuals","title":"<code>get_individuals()</code>","text":"<p>Get a list of all Individual objects in the cohort</p> <p>Returns:</p> Type Description <code>List[Individual]</code> <p>a list of all Individual objects in the cohort</p> Source code in <code>pyphetools/creation/cohort_encoder.py</code> <pre><code>def get_individuals(self) -&gt; typing.List[Individual]:\n    \"\"\"Get a list of all Individual objects in the cohort\n\n    :returns: a list of all Individual objects in the cohort\n    :rtype: List[Individual]\n    \"\"\"\n    # make sure indexes pair with number of rows, if needed\n    if not self._df.index.name in self._df.columns:\n        df = self._df.reset_index()\n    individuals = []\n    sex_column_name = self._sex_mapper.get_column_name()\n    if self._variant_mapper is None:\n        variant_colname = None\n        genotype_colname = None\n    else:\n        variant_colname = self._variant_mapper.get_variant_column_name()\n        genotype_colname = self._variant_mapper.get_genotype_colname()\n    for index, row in df.iterrows():\n        individual_id = row[self._id_column_name]\n        age_of_onset = CohortEncoder._get_age(row, self._age_of_onset_mapper)\n        age_last_encounter = CohortEncoder._get_age(row, self._age_at_last_encounter_mapper)\n        if sex_column_name == Constants.NOT_PROVIDED:\n            sex = self._sex_mapper.map_cell(Constants.NOT_PROVIDED)\n        else:\n            sex_cell_contents = row[sex_column_name]\n            sex = self._sex_mapper.map_cell(sex_cell_contents)\n        hpo_terms = []\n        for column_mapper in self._column_mapper_list:\n            column_name = column_mapper.get_column_name()\n            if column_name not in df.columns:\n                raise ValueError(f\"Did not find column name '{column_name}' in dataframe -- check spelling!\")\n            cell_contents = row[column_name]\n            # Empty cells are often represented as float non-a-number by Pandas\n            if isinstance(cell_contents, float) and isnan(cell_contents):\n                continue\n            terms = column_mapper.map_cell(cell_contents)\n            hpo_terms.extend(terms)\n        if variant_colname is not None:\n            variant_cell_contents = row[variant_colname]\n            if genotype_colname is not None:\n                genotype_cell_contents = row[genotype_colname]\n            else:\n                genotype_cell_contents = None\n            if self._variant_mapper is not None:\n                interpretation_list = self._variant_mapper.map_cell(variant_cell_contents, genotype_cell_contents)\n            else:\n                interpretation_list = []\n        else:\n            interpretation_list = []\n        if self._disease_dictionary is not None and self._disease is None:\n            if individual_id not in self._disease_dictionary:\n                raise ValueError(f\"Could not find disease link for {individual_id}\")\n            disease = self._disease_dictionary.get(individual_id)\n            indi = Individual(individual_id=individual_id,\n                              sex=sex,\n                              age_of_onset=age_of_onset,\n                              age_at_last_encounter=age_last_encounter,\n                              hpo_terms=hpo_terms,\n                              citation=self._metadata.get_citation(),\n                              interpretation_list=interpretation_list,\n                              disease=disease)\n        elif self._disease_dictionary is None and self._disease is not None:\n            indi = Individual(individual_id=individual_id,\n                              sex=sex,\n                              age_of_onset=age_of_onset,\n                              age_at_last_encounter=age_last_encounter,\n                              hpo_terms=hpo_terms,\n                              citation=self._metadata.get_citation(),\n                              interpretation_list=interpretation_list,\n                              disease=self._disease)\n        else:\n            raise ValueError(f\"Could not find disease data for '{individual_id}'\")\n        individuals.append(indi)\n    if self._age_of_onset_mapper.has_error():\n        print(self._age_of_onset_mapper.error_summary())\n    if self._age_at_last_encounter_mapper.has_error():\n        print(self._age_at_last_encounter_mapper.error_summary())\n    if self._sex_mapper.has_error():\n        print(self._sex_mapper.error_summary())\n    return individuals\n</code></pre>"},{"location":"api/creation/cohort_encoder/#pyphetools.creation.CohortEncoder.preview_dataframe","title":"<code>preview_dataframe()</code>","text":"<p>Generate a dataframe with a preview of the parsed contents</p> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>a DataFrame representing the cohort to check results</p> Source code in <code>pyphetools/creation/cohort_encoder.py</code> <pre><code>def preview_dataframe(self):\n    \"\"\"\n    Generate a dataframe with a preview of the parsed contents\n\n    :returns: a DataFrame representing the cohort to check results\n    :rtype: pd.DataFrame\n    \"\"\"\n    df = self._df.reset_index()  # make sure indexes pair with number of rows\n    individuals = []\n    age_column_name = self._age_of_onset_mapper.get_column_name()\n    sex_column_name = self._sex_mapper.get_column_name()\n    for index, row in df.iterrows():\n        individual_id = row[self._id_column_name]\n        if age_column_name == Constants.NOT_PROVIDED:\n            age = Constants.NOT_PROVIDED\n        else:\n            age_cell_contents = row[age_column_name]\n            age = self._age_mapper.map_cell(age_cell_contents)\n        sex_cell_contents = row[sex_column_name]\n        sex = self._sex_mapper.map_cell(sex_cell_contents)\n        hpo_terms = []\n        for column_mapper in self.__column_mapper_list:\n            column_name = column_mapper.get_column_name()\n            cell_contents = row[column_name]\n            # Empty cells are often represented as float non-a-number by Pandas\n            if isinstance(cell_contents, float) and isnan(cell_contents):\n                continue\n            terms = column_mapper.map_cell(row[column_name])\n            hpo_terms.extend(terms)\n        hpo_string = \"\\n\".join([h.to_string() for h in hpo_terms])\n        d = {'id': individual_id,\n             'sex': sex,\n             'age': age,\n             'phenotypic features': hpo_string}\n        individuals.append(d)\n    df = pd.DataFrame(individuals)\n    return df.set_index('id')\n</code></pre>"},{"location":"api/creation/cohort_encoder/#pyphetools.creation.CohortEncoder.set_disease","title":"<code>set_disease(disease)</code>","text":"<p>Set the disease diagnosis for all patients in the cohort</p> <p>If all patients in the cohort have the same disease we can set it with this method</p> <p>Parameters:</p> Name Type Description Default <code>disease</code> <code>Disease</code> <p>Disease diagnosis for the individuals in this cohort</p> required Source code in <code>pyphetools/creation/cohort_encoder.py</code> <pre><code>def set_disease(self, disease: Disease):\n    \"\"\"Set the disease diagnosis for all patients in the cohort\n\n    If all patients in the cohort have the same disease we can set it with this method\n    :param disease: Disease diagnosis for the individuals in this cohort\n    :type disease: Disease\n    \"\"\"\n    self._disease = disease\n    self._disease_dictionary = None\n</code></pre>"},{"location":"api/creation/cohort_encoder/#pyphetools.creation.CohortEncoder.set_disease_dictionary","title":"<code>set_disease_dictionary(disease_d)</code>","text":"<p>Set the dictionary of disease ontology terms</p> <p>For tables with multiple different diseases, we provide a dictionary that has as key the string used in the original table and as value</p> Source code in <code>pyphetools/creation/cohort_encoder.py</code> <pre><code>def set_disease_dictionary(self,\n                           disease_d: typing.Dict[str, Disease]):\n    \"\"\"Set the dictionary of disease ontology terms\n\n    For tables with multiple different diseases, we provide a dictionary that has as key\n    the string used in the original table and as value\n    \"\"\"\n    self._disease_dictionary = disease_d\n    self._disease = None\n</code></pre>"},{"location":"api/creation/create_template/","title":"TemplateCreator","text":"<p>               Bases: <code>ColumnMapper</code></p> <p>Column mapper for cases in which all patients have an (optionally excluded) HPO term.</p> <p>Parameters:</p> Name Type Description Default <code>column_name</code> <code>str</code> <p>name of the column in the pandas DataFrame</p> required <code>hpo_id</code> <code>str</code> <p>HPO  id, e.g., HP:0004321</p> <code>None</code> <code>hpo_label</code> <code>str</code> <p>Corresponding term label</p> <code>None</code> <code>term_list</code> <code>List[lst]</code> <p>list of lists with [label, hpo_id</p> <code>None</code> <code>excluded</code> <code>bool</code> <p>if True, then all individuals had this feature explicitly excluded</p> <code>False</code> Source code in <code>pyphetools/creation/constant_column_mapper.py</code> <pre><code>class ConstantColumnMapper(ColumnMapper):\n    \"\"\"Column mapper for cases in which all patients have an (optionally excluded) HPO term.\n    :param column_name: name of the column in the pandas DataFrame\n    :type column_name: str\n    :param hpo_id: HPO  id, e.g., HP:0004321\n    :type hpo_id: str\n    :param hpo_label: Corresponding term label\n    :type hpo_label: str\n    :param term_list: list of lists with [label, hpo_id\n    :type term_list: List[lst]\n    :param excluded: if True, then all individuals had this feature explicitly excluded\n    :type excluded: bool\n    \"\"\"\n    def __init__(self, column_name,  hpo_id=None, hpo_label=None, term_list=None, excluded:bool=False) -&gt; None:\n\n        super().__init__(column_name=column_name)\n        self._hpo_id = hpo_id\n        if hpo_id is None and hpo_label is None and term_list is not None:\n            self._hpo_terms = []\n            for term in term_list:\n                if excluded:\n                    hpoterm = HpTerm(label=term[0], hpo_id=term[1], observed=False)\n                else:\n                    hpoterm = HpTerm(label=term[0], hpo_id=term[1], observed=True)\n                self._hpo_terms.append(hpoterm)\n        elif term_list is None and hpo_id is not None and hpo_label is not None:\n            if excluded:\n                hpoterm = HpTerm(label=hpo_label, hpo_id=hpo_id, observed=False)\n            else:\n                hpoterm = HpTerm(label=hpo_label, hpo_id=hpo_id, observed=True)\n            self._hpo_terms = [hpoterm]\n        else:\n            raise ValueError(f\"Error: Either hpo_id and hpo_label are not not or a list of HPO terms is passed\")\n        self._excluded = excluded\n\n    def map_cell(self, cell_contents) -&gt; List[HpTerm]:\n        \"\"\"if this mapper is used, then all individuals in the table have the list of HPO terms\n\n        Args:\n            cell_contents (str): not used, can be None or any other value\n\n        Returns:\n            List[HpTerm]: list of HPO terms\n        \"\"\"\n        return self._hpo_terms\n\n    def preview_column(self, df:pd.DataFrame) -&gt; pd.DataFrame:\n        if not isinstance(df, pd.DataFrame):\n            raise ValueError(\"df argument must be pandas DataFrame, but was {type(column)}\")\n        mapping_counter = defaultdict(int)\n\n        dlist = []\n        column = df[self._column_name]\n        for _, value in column.items():\n            display = \";\".join(hpterm.display_value for hpterm in self._hpo_terms)\n            display = f\"{value} -&gt; {display}\"\n            mapping_counter[display] +=1\n        for k, v in mapping_counter.items():\n            d = {\"mapping\": k, \"count\": str(v)}\n            dlist.append(d)\n        return pd.DataFrame(dlist)\n</code></pre>"},{"location":"api/creation/create_template/#pyphetools.creation.ConstantColumnMapper.map_cell","title":"<code>map_cell(cell_contents)</code>","text":"<p>if this mapper is used, then all individuals in the table have the list of HPO terms</p> <p>Args:     cell_contents (str): not used, can be None or any other value</p> <p>Returns:     List[HpTerm]: list of HPO terms</p> Source code in <code>pyphetools/creation/constant_column_mapper.py</code> <pre><code>def map_cell(self, cell_contents) -&gt; List[HpTerm]:\n    \"\"\"if this mapper is used, then all individuals in the table have the list of HPO terms\n\n    Args:\n        cell_contents (str): not used, can be None or any other value\n\n    Returns:\n        List[HpTerm]: list of HPO terms\n    \"\"\"\n    return self._hpo_terms\n</code></pre>"},{"location":"api/creation/discombobulator/","title":"Discombobulator","text":"<p>Discombobulate a column of the original data, using text mining to find HPO terms and make one column for each identified HPO term in the output. In the following example, \"Book2.xlsx\" is an Excel file derived from an original publication. It has a column called \"Cardiac defect\", some of  whose cells contain items such as Ventricular septal defect, Atrial septal defect, Patent foramen ovale. Some of the cells contain codes (here, \"na\", and \"UN\") that indicate that no information is available (so we want to output \"na\"). The assumeExcluded argument means that if an observation was made (e.g., echocardiography), then we assume all items are excluded except those that are named in the cell. The decode method returns a pandas DataFrame that has columns that can be inspected and then added to the pyphetools Excel template once any necessary revisions have been made. The DataFrame will have one column for the patient identifier and one column for each of the identified HPO terms. Finally, the last column will be the original column that we can use to vet results.</p> <pre><code>import pandas as pd\ndf = pd.read_excel(\"../../Book2.xlsx\")\nfrom pyphetools.creation import Discombobulator\ndc = Discombobulator(df=df, individual_id=\"individual column name\")\ncardiac = dc.decode(column=\"Cardiac defect\", trueNa={\"na\", \"UN\"}, assumeExcluded=True)\ncardiac.to_excel(\"cardiac.xlsx\")\n</code></pre> Source code in <code>pyphetools/creation/discombulator.py</code> <pre><code>class Discombobulator:\n    \"\"\"\n    Discombobulate a column of the original data, using text mining to find HPO terms and make one column for each identified HPO term in the output.\n    In the following example, \"Book2.xlsx\" is an Excel file derived from an original publication. It has a column called \"Cardiac defect\", some of \n    whose cells contain items such as Ventricular septal defect, Atrial septal defect, Patent foramen ovale. Some of the cells contain codes (here, \"na\",\n    and \"UN\") that indicate that no information is available (so we want to output \"na\"). The assumeExcluded argument means that if an observation\n    was made (e.g., echocardiography), then we assume all items are excluded except those that are named in the cell. The decode method returns\n    a pandas DataFrame that has columns that can be inspected and then added to the pyphetools Excel template once any necessary revisions have been made.\n    The DataFrame will have one column for the patient identifier and one column for each of the identified HPO terms. Finally, the last column will be\n    the original column that we can use to vet results.\n\n        import pandas as pd\n        df = pd.read_excel(\"../../Book2.xlsx\")\n        from pyphetools.creation import Discombobulator\n        dc = Discombobulator(df=df, individual_id=\"individual column name\")\n        cardiac = dc.decode(column=\"Cardiac defect\", trueNa={\"na\", \"UN\"}, assumeExcluded=True)\n        cardiac.to_excel(\"cardiac.xlsx\")\n\n    \"\"\"\n    def __init__(self, \n                df:pd.DataFrame,\n                individual_id:str,\n                hpo_cr:HpoConceptRecognizer = None) -&gt; None:\n        if hpo_cr is not None:\n            self._hpo_cr = hpo_cr\n        else:\n            parser = HpoParser()\n            self._hpo_cr = parser.get_hpo_concept_recognizer()\n        self._individual_id = individual_id\n        self._df = df\n\n    def decode(self,  \n               column:str, \n               delim:str=\",\", \n               assumeExcluded=False, \n               trueNa:typing.Union[str,typing.Set[str]]=\"na\") -&gt; pd.DataFrame:\n        \"\"\"\n        Discombobulate a column of the original data, using text mining to find HPO terms and make one column for each identified HPO term in the output.\n        :param column: The name of the column to dsicombobulate\n        :param delim: delimiter between items\n        :assumeExcluded: Assume that if an item is not mentioned in a cell, then it was excluded. This can be justified if the column is about Echocardiography findings, for instance.\n        :trueNa:  \n        \"\"\"\n        if not column in self._df.columns:\n            raise ValueError(f\"could not find column {column} in dataframe\")\n        index_to_hpo_d = defaultdict(set)\n        label_to_id = dict()\n        all_hpo_terms = set()\n        if isinstance(trueNa, str):\n            self._true_na_set = set()\n            self._true_na_set.add(trueNa)\n        elif isinstance(trueNa, set):\n            self._true_na_set = trueNa\n        else:\n            raise ValueError(f\"trueNa argument must be string or set, but was {type(trueNa)}\")\n        ## First get list of all HPO terms used\n        for idx, row in self._df.iterrows():\n            idx = str(idx)\n            contents = row[column]\n            contents = str(contents) ## coerce to string in case empty\n            hpo_term_list = self._hpo_cr.parse_cell(contents)\n            for hterm in hpo_term_list:\n                hpo_id = hterm.id\n                label = hterm.label\n                label_to_id[label] = hpo_id\n                index_to_hpo_d[idx].add(label)\n                all_hpo_terms.add(label)\n        label_list = list()\n        id_list = list()\n        label_list.append(\"individual_id\")\n        id_list.append(\"str\")\n\n        # Now create dataframe with these annotations\n        for h in all_hpo_terms:\n            label_list.append(h)\n            hpo_id = label_to_id.get(h)\n            id_list.append(hpo_id)\n        row_list = list()\n        row_list.append(id_list)\n        for hpo_list in index_to_hpo_d.values():\n            for hpo in hpo_term_list:\n                all_hpo_terms.add(hpo)\n        hpo_annot_row = list()\n        for idx, row in self._df.iterrows():\n            idx = str(idx)\n            if idx in index_to_hpo_d:\n                observed_hpo_set = index_to_hpo_d.get(idx)\n            else:\n                observed_hpo_set = set() ## now terms parsed for this index\n\n            arow = AnnotationRow(idx=idx)\n            for hpo in label_list[1:]:\n                if hpo in observed_hpo_set:\n                    arow.add_observed()\n                elif assumeExcluded:\n                    arow.add_excluded()\n                else:\n                    arow.add_na()\n            row_list.append(arow.get_annot_lst())\n        # Create DataFrame\n        df_out = pd.DataFrame(row_list, columns=label_list)\n        original_column = self._df[column]\n        a = pd.Series([\"Original\"])\n        new_column = pd.concat([a, original_column], axis=0, ignore_index=True)\n        new_column_header = f\"Original:{column}\"\n        df_out[new_column_header] = new_column\n        df_out[new_column_header] = new_column\n\n\n        # Now replace with na\n        # List of columns to exclude\n        for na_symbol in self._true_na_set:\n            exclude_columns = ['individual_id', new_column_header]\n            columns_to_change = df_out.columns.difference(exclude_columns)\n            df_out.loc[df_out[new_column_header] == na_symbol, columns_to_change] = \"na\"\n        # Now add back the original individual labels\n        individual_column = self._df[self._individual_id]\n        a = pd.Series([\"Individual\"])\n        individual_column = pd.concat([a, individual_column], axis=0, ignore_index=True)\n        df_out[\"original individual id\"] = individual_column\n\n        return df_out\n\n    def write(self, df:pd.DataFrame, column:str, delim:str=\",\", assumeExcluded=False):\n        df = self.decode(column=column, delim=delim, assumeExcluded=assumeExcluded)\n        fname = column.replace(\" \", \"_\") + \".xlsx\"\n        df.to_excel(fname, index=False)\n        print(f\"Wrote Excel File with parsed columns to {fname}\")\n</code></pre>"},{"location":"api/creation/discombobulator/#pyphetools.creation.Discombobulator.decode","title":"<code>decode(column, delim=',', assumeExcluded=False, trueNa='na')</code>","text":"<p>Discombobulate a column of the original data, using text mining to find HPO terms and make one column for each identified HPO term in the output. :assumeExcluded: Assume that if an item is not mentioned in a cell, then it was excluded. This can be justified if the column is about Echocardiography findings, for instance. :trueNa:</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The name of the column to dsicombobulate</p> required <code>delim</code> <code>str</code> <p>delimiter between items</p> <code>','</code> Source code in <code>pyphetools/creation/discombulator.py</code> <pre><code>def decode(self,  \n           column:str, \n           delim:str=\",\", \n           assumeExcluded=False, \n           trueNa:typing.Union[str,typing.Set[str]]=\"na\") -&gt; pd.DataFrame:\n    \"\"\"\n    Discombobulate a column of the original data, using text mining to find HPO terms and make one column for each identified HPO term in the output.\n    :param column: The name of the column to dsicombobulate\n    :param delim: delimiter between items\n    :assumeExcluded: Assume that if an item is not mentioned in a cell, then it was excluded. This can be justified if the column is about Echocardiography findings, for instance.\n    :trueNa:  \n    \"\"\"\n    if not column in self._df.columns:\n        raise ValueError(f\"could not find column {column} in dataframe\")\n    index_to_hpo_d = defaultdict(set)\n    label_to_id = dict()\n    all_hpo_terms = set()\n    if isinstance(trueNa, str):\n        self._true_na_set = set()\n        self._true_na_set.add(trueNa)\n    elif isinstance(trueNa, set):\n        self._true_na_set = trueNa\n    else:\n        raise ValueError(f\"trueNa argument must be string or set, but was {type(trueNa)}\")\n    ## First get list of all HPO terms used\n    for idx, row in self._df.iterrows():\n        idx = str(idx)\n        contents = row[column]\n        contents = str(contents) ## coerce to string in case empty\n        hpo_term_list = self._hpo_cr.parse_cell(contents)\n        for hterm in hpo_term_list:\n            hpo_id = hterm.id\n            label = hterm.label\n            label_to_id[label] = hpo_id\n            index_to_hpo_d[idx].add(label)\n            all_hpo_terms.add(label)\n    label_list = list()\n    id_list = list()\n    label_list.append(\"individual_id\")\n    id_list.append(\"str\")\n\n    # Now create dataframe with these annotations\n    for h in all_hpo_terms:\n        label_list.append(h)\n        hpo_id = label_to_id.get(h)\n        id_list.append(hpo_id)\n    row_list = list()\n    row_list.append(id_list)\n    for hpo_list in index_to_hpo_d.values():\n        for hpo in hpo_term_list:\n            all_hpo_terms.add(hpo)\n    hpo_annot_row = list()\n    for idx, row in self._df.iterrows():\n        idx = str(idx)\n        if idx in index_to_hpo_d:\n            observed_hpo_set = index_to_hpo_d.get(idx)\n        else:\n            observed_hpo_set = set() ## now terms parsed for this index\n\n        arow = AnnotationRow(idx=idx)\n        for hpo in label_list[1:]:\n            if hpo in observed_hpo_set:\n                arow.add_observed()\n            elif assumeExcluded:\n                arow.add_excluded()\n            else:\n                arow.add_na()\n        row_list.append(arow.get_annot_lst())\n    # Create DataFrame\n    df_out = pd.DataFrame(row_list, columns=label_list)\n    original_column = self._df[column]\n    a = pd.Series([\"Original\"])\n    new_column = pd.concat([a, original_column], axis=0, ignore_index=True)\n    new_column_header = f\"Original:{column}\"\n    df_out[new_column_header] = new_column\n    df_out[new_column_header] = new_column\n\n\n    # Now replace with na\n    # List of columns to exclude\n    for na_symbol in self._true_na_set:\n        exclude_columns = ['individual_id', new_column_header]\n        columns_to_change = df_out.columns.difference(exclude_columns)\n        df_out.loc[df_out[new_column_header] == na_symbol, columns_to_change] = \"na\"\n    # Now add back the original individual labels\n    individual_column = self._df[self._individual_id]\n    a = pd.Series([\"Individual\"])\n    individual_column = pd.concat([a, individual_column], axis=0, ignore_index=True)\n    df_out[\"original individual id\"] = individual_column\n\n    return df_out\n</code></pre>"},{"location":"api/creation/disease/","title":"Disease","text":"<p>Simple data object to hold ontology id/label for a disease diagnosis</p> <p>Parameters:</p> Name Type Description Default <code>disease_id</code> <code>str</code> <p>a CURIE such as OMIM:600324</p> required <code>disease_label</code> <code>str</code> <p>the name of the disease</p> required Source code in <code>pyphetools/creation/disease.py</code> <pre><code>class Disease:\n    \"\"\"\n    Simple data object to hold ontology id/label for a disease diagnosis\n\n    :param disease_id: a CURIE such as OMIM:600324\n    :type disease_id: str\n    :param disease_label: the name of the disease\n    :type disease_label: str\n    \"\"\"\n\n    def __init__(self, disease_id:str, disease_label):\n        if \" \" in disease_id:\n            raise ValueError(f\"Malformed disease identifier with white space: \\\"{disease_id}\\\"\")\n        if disease_label.startswith(\" \") or disease_label.endswith(\" \"):\n            raise ValueError(f\"Malformed disease label (starts/ends with whitespace): \\\"{disease_label}\\\"\")\n        # occasionally, copy-paste error leads to this kind of malformed label:  \"Developmental and epileptic encephalopathy 50\\t616457\\tAR\\t3\\t\"\n        if \"\\t\" in disease_label:\n            raise ValueError(f\"Malformed disease label (contains tabs): \\\"{disease_label}\\\"\")\n        self._id = disease_id\n        self._label = disease_label\n\n\n    @property\n    def id(self):\n        return self._id\n\n    @property\n    def label(self):\n        return self._label\n\n    def __hash__(self):\n        return hash((self._id, self._label))\n\n    def __eq__(self, other):\n        return (self.id, self.label) == (other.id, other.label)\n\n    def __repr__(self):\n        return f'{self.label} ({self.id})'\n</code></pre>"},{"location":"api/creation/hgvs_variant/","title":"HgvsVariant","text":"<p>               Bases: <code>Variant</code></p> <p>This encapsulates variant data that we retrieve from Variant Validator</p> <p>Parameters:</p> Name Type Description Default <code>assembly</code> <code>str</code> <p>the genome build (one of hg19, hg38)</p> required <code>vcf_d</code> <code>Dict[str]</code> <p>dictionary with values for chr, pos, ref, alt (VCF)</p> required <code>symbol</code> <code>str, optional</code> <p>the gene symbol</p> <code>None</code> <code>hgnc</code> <code>str, optional</code> <p>The Human Gene Nomenclature Comittee (HNGC) identifier, e.g. HGNS:123</p> <code>None</code> <code>transcript</code> <code>str, optional</code> <p>identifier of the transcript for defininf the variant</p> <code>None</code> <code>g_hgvs</code> <code>str, optional</code> <p>genomic hgvs</p> <code>None</code> <code>variant_id</code> <code>str, optional</code> <p>variant identifier</p> <code>None</code> Source code in <code>pyphetools/creation/hgvs_variant.py</code> <pre><code>class HgvsVariant(Variant):\n    \"\"\"\n    This encapsulates variant data that we retrieve from Variant Validator\n\n    :param assembly: the genome build (one of hg19, hg38)\n    :type assembly: str\n    :param vcf_d: dictionary with values for chr, pos, ref, alt (VCF)\n    :type vcf_d: Dict[str]\n    :param symbol: the gene symbol\n    :type symbol: str, optional\n    :param hgnc: The Human Gene Nomenclature Comittee (HNGC) identifier, e.g. HGNS:123\n    :type hgnc: str, optional\n    :param transcript: identifier of the transcript for defininf the variant\n    :type transcript: str, optional\n    :param g_hgvs: genomic hgvs\n    :type g_hgvs: str, optional\n    :param variant_id: variant identifier\n    :type variant_id: str, optional\n    \"\"\"\n    def __init__(self, assembly, vcf_d, symbol=None, hgnc=None, hgvs=None, transcript=None, g_hgvs=None,\n                 variant_id=None) -&gt; None:\n        super().__init__()\n        if not assembly in ACCEPTABLE_GENOMES:\n            raise ValueError(f\"Malformed assembly: \\\"{assembly}\\\"\")\n        self._assembly = assembly\n        if not isinstance(vcf_d, dict):\n            raise ValueError(f\"vcf_d argument must be dictionary\")\n        self._chr = vcf_d.get('chr')\n        self._position = int(vcf_d.get('pos'))\n        self._ref = vcf_d.get('ref')\n        self._alt = vcf_d.get('alt')\n        self._symbol = symbol\n        self._hgnc_id = hgnc\n        self._hgvs = hgvs\n        self._transcript = transcript\n        self._g_hgvs = g_hgvs\n        self._genotype = None\n        if variant_id is None:\n            self._variant_id = \"var_\" + \"\".join(random.choices(string.ascii_letters, k=25))\n        else:\n            self._variant_id = variant_id\n\n    @property\n    def assembly(self):\n        return self._assembly\n\n    @property\n    def chr(self):\n        return self._chr\n\n    @property\n    def position(self):\n        return self._position\n\n    @property\n    def ref(self):\n        return self._ref\n\n    @property\n    def alt(self):\n        return self._alt\n\n    @property\n    def genotype(self):\n        return self._genotype\n\n    def __str__(self):\n        return f\"{self._hgvs}({self._chr}:{self._position}{self._ref}&gt;{self._alt})\"\n\n    def to_string(self):\n        return self.__str__()\n\n    def to_ga4gh_variant_interpretation(self, acmg=None):\n        \"\"\"For the new interface. Refactor client code to use this function, which has an unambiguous name\n        \"\"\"\n        return self.to_ga4gh(acmg=acmg)\n\n    def to_ga4gh(self, acmg=None):\n        \"\"\"\n        Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n        \"\"\"\n        vdescriptor = phenopackets.VariationDescriptor()\n        vdescriptor.id = self._variant_id\n        if self._hgnc_id is not None and self._symbol is not None:\n            vdescriptor.gene_context.value_id = self._hgnc_id\n            vdescriptor.gene_context.symbol = self._symbol\n        hgvs_expression = phenopackets.Expression()\n        if self._hgvs is not None:\n            hgvs_expression.syntax = \"hgvs.c\"\n            hgvs_expression.value = self._hgvs\n            vdescriptor.expressions.append(hgvs_expression)\n        if self._g_hgvs is not None:\n            hgvs_expression.syntax = \"hgvs.g\"\n            hgvs_expression.value = self._g_hgvs\n            vdescriptor.expressions.append(hgvs_expression)\n        vdescriptor.molecule_context =  phenopackets.MoleculeContext.genomic\n        if self._genotype is not None:\n            if self._genotype == 'heterozygous':\n                vdescriptor.allelic_state.id = \"GENO:0000135\"\n                vdescriptor.allelic_state.label = \"heterozygous\"\n            elif self._genotype == 'homozygous':\n                vdescriptor.allelic_state.id = \"GENO:0000136\"\n                vdescriptor.allelic_state.label = \"homozygous\"\n            elif self._genotype == 'hemizygous':\n                vdescriptor.allelic_state.id = \"GENO:0000134\"\n                vdescriptor.allelic_state.label = \"hemizygous\"\n            else:\n                print(f\"Did not recognize genotype {self._genotype}\")\n        vinterpretation = phenopackets.VariantInterpretation()\n        if acmg is not None:\n            if acmg.lower() == 'benign':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.BENIGN\n            elif acmg.lower == 'likely benign' or acmg.lower() == 'likely_benign':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_BENIGN\n            elif acmg.lower == 'uncertain significance' or acmg.lower() == 'uncertain_significance':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.UNCERTAIN_SIGNIFICANCE\n            elif acmg.lower == 'likely pathogenic' or acmg.lower() == 'likely_pathogenic':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_PATHOGENIC\n            elif acmg.lower == 'pathogenic' or acmg.lower() == 'pathogenic':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.PATHOGENIC\n            else:\n                print(f\"Warning- did not recognize ACMG category {acmg}\")\n        vcf_record = phenopackets.VcfRecord()\n        vcf_record.genome_assembly =  self._assembly\n        vcf_record.chrom = self._chr\n        vcf_record.pos = self._position\n        vcf_record.ref = self._ref\n        vcf_record.alt = self._alt\n        vdescriptor.vcf_record.CopyFrom(vcf_record)\n        vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n        return vinterpretation\n\n    def to_variant_interpretation_202(self, \n                                      acmg:str=None) -&gt; VariantInterpretation202:\n        \"\"\"\n        Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n        \"\"\"\n\n        vcf_record = VcfRecord202(genome_assembly=self._assembly,\n                                  chrom=self._chr,\n                                  pos=self._position,\n                                  ref=self._ref,\n                                  alt=self._alt)\n        vdescriptor = VariationDescriptor202(id=self._variant_id, vcf_record=vcf_record, molecule_context=MoleculeContext202.genomic)\n        if self._hgnc_id is not None and self._symbol is not None:\n            gene_descriptor = GeneDescriptor202(value_id=self._hgnc_id, symbol=self._symbol)\n            vdescriptor.gene_context = gene_descriptor\n        if self._hgvs is not None:\n            hgvs_expression = Expression202(syntax=\"hgvs.c\", value=self._hgvs)\n            vdescriptor.expressions.append(hgvs_expression)\n        if self._g_hgvs is not None:\n            hgvs_expression = Expression202(syntax=\"hgvs.g\", value=self._g_hgvs)\n            vdescriptor.expressions.append(hgvs_expression)\n        gt_term = Variant._get_genotype_term(self._genotype)\n        # it can occur that the genotype is not set when we call this function (it will be set by calling code)\n        # therefore it is not necessarily an error if the genotype is None, calling code needs to check this appropriately\n        if gt_term is not None:\n            vdescriptor.allelic_state = gt_term\n        vinterpretation = VariantInterpretation202(variation_descriptor=vdescriptor)\n        acmg_code = Variant._get_acmg_classification(acmg=acmg)\n        if acmg_code is not None:\n            vinterpretation.acmg_pathogenicity_classification = acmg_code\n        else:\n            print(f\"Warning- did not recognize ACMG category {acmg}\")\n\n        return vinterpretation\n</code></pre>"},{"location":"api/creation/hgvs_variant/#pyphetools.creation.HgvsVariant.to_ga4gh","title":"<code>to_ga4gh(acmg=None)</code>","text":"<p>Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema</p> Source code in <code>pyphetools/creation/hgvs_variant.py</code> <pre><code>def to_ga4gh(self, acmg=None):\n    \"\"\"\n    Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n    \"\"\"\n    vdescriptor = phenopackets.VariationDescriptor()\n    vdescriptor.id = self._variant_id\n    if self._hgnc_id is not None and self._symbol is not None:\n        vdescriptor.gene_context.value_id = self._hgnc_id\n        vdescriptor.gene_context.symbol = self._symbol\n    hgvs_expression = phenopackets.Expression()\n    if self._hgvs is not None:\n        hgvs_expression.syntax = \"hgvs.c\"\n        hgvs_expression.value = self._hgvs\n        vdescriptor.expressions.append(hgvs_expression)\n    if self._g_hgvs is not None:\n        hgvs_expression.syntax = \"hgvs.g\"\n        hgvs_expression.value = self._g_hgvs\n        vdescriptor.expressions.append(hgvs_expression)\n    vdescriptor.molecule_context =  phenopackets.MoleculeContext.genomic\n    if self._genotype is not None:\n        if self._genotype == 'heterozygous':\n            vdescriptor.allelic_state.id = \"GENO:0000135\"\n            vdescriptor.allelic_state.label = \"heterozygous\"\n        elif self._genotype == 'homozygous':\n            vdescriptor.allelic_state.id = \"GENO:0000136\"\n            vdescriptor.allelic_state.label = \"homozygous\"\n        elif self._genotype == 'hemizygous':\n            vdescriptor.allelic_state.id = \"GENO:0000134\"\n            vdescriptor.allelic_state.label = \"hemizygous\"\n        else:\n            print(f\"Did not recognize genotype {self._genotype}\")\n    vinterpretation = phenopackets.VariantInterpretation()\n    if acmg is not None:\n        if acmg.lower() == 'benign':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.BENIGN\n        elif acmg.lower == 'likely benign' or acmg.lower() == 'likely_benign':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_BENIGN\n        elif acmg.lower == 'uncertain significance' or acmg.lower() == 'uncertain_significance':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.UNCERTAIN_SIGNIFICANCE\n        elif acmg.lower == 'likely pathogenic' or acmg.lower() == 'likely_pathogenic':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_PATHOGENIC\n        elif acmg.lower == 'pathogenic' or acmg.lower() == 'pathogenic':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.PATHOGENIC\n        else:\n            print(f\"Warning- did not recognize ACMG category {acmg}\")\n    vcf_record = phenopackets.VcfRecord()\n    vcf_record.genome_assembly =  self._assembly\n    vcf_record.chrom = self._chr\n    vcf_record.pos = self._position\n    vcf_record.ref = self._ref\n    vcf_record.alt = self._alt\n    vdescriptor.vcf_record.CopyFrom(vcf_record)\n    vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n    return vinterpretation\n</code></pre>"},{"location":"api/creation/hgvs_variant/#pyphetools.creation.HgvsVariant.to_ga4gh_variant_interpretation","title":"<code>to_ga4gh_variant_interpretation(acmg=None)</code>","text":"<p>For the new interface. Refactor client code to use this function, which has an unambiguous name</p> Source code in <code>pyphetools/creation/hgvs_variant.py</code> <pre><code>def to_ga4gh_variant_interpretation(self, acmg=None):\n    \"\"\"For the new interface. Refactor client code to use this function, which has an unambiguous name\n    \"\"\"\n    return self.to_ga4gh(acmg=acmg)\n</code></pre>"},{"location":"api/creation/hgvs_variant/#pyphetools.creation.HgvsVariant.to_variant_interpretation_202","title":"<code>to_variant_interpretation_202(acmg=None)</code>","text":"<p>Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema</p> Source code in <code>pyphetools/creation/hgvs_variant.py</code> <pre><code>def to_variant_interpretation_202(self, \n                                  acmg:str=None) -&gt; VariantInterpretation202:\n    \"\"\"\n    Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n    \"\"\"\n\n    vcf_record = VcfRecord202(genome_assembly=self._assembly,\n                              chrom=self._chr,\n                              pos=self._position,\n                              ref=self._ref,\n                              alt=self._alt)\n    vdescriptor = VariationDescriptor202(id=self._variant_id, vcf_record=vcf_record, molecule_context=MoleculeContext202.genomic)\n    if self._hgnc_id is not None and self._symbol is not None:\n        gene_descriptor = GeneDescriptor202(value_id=self._hgnc_id, symbol=self._symbol)\n        vdescriptor.gene_context = gene_descriptor\n    if self._hgvs is not None:\n        hgvs_expression = Expression202(syntax=\"hgvs.c\", value=self._hgvs)\n        vdescriptor.expressions.append(hgvs_expression)\n    if self._g_hgvs is not None:\n        hgvs_expression = Expression202(syntax=\"hgvs.g\", value=self._g_hgvs)\n        vdescriptor.expressions.append(hgvs_expression)\n    gt_term = Variant._get_genotype_term(self._genotype)\n    # it can occur that the genotype is not set when we call this function (it will be set by calling code)\n    # therefore it is not necessarily an error if the genotype is None, calling code needs to check this appropriately\n    if gt_term is not None:\n        vdescriptor.allelic_state = gt_term\n    vinterpretation = VariantInterpretation202(variation_descriptor=vdescriptor)\n    acmg_code = Variant._get_acmg_classification(acmg=acmg)\n    if acmg_code is not None:\n        vinterpretation.acmg_pathogenicity_classification = acmg_code\n    else:\n        print(f\"Warning- did not recognize ACMG category {acmg}\")\n\n    return vinterpretation\n</code></pre>"},{"location":"api/creation/hp_term/","title":"HpTerm","text":"<p>Class to represent a phenotypic observation as an HPO term with optional modifiers</p> <p>Parameters:</p> Name Type Description Default <code>hpo_id</code> <code>str</code> <p>a Human Phenotype Ontology (HPO) identifier such as HP:0001166</p> required <code>label</code> <code>str</code> <p>The HPO label that corresponds to the id (note: This class does not check for correct match)</p> required <code>observed</code> <code>bool</code> <p>a boolean that indicates whether the HPO term was observed (True) or excluded (False)</p> <code>True</code> <code>measured</code> <code>bool</code> <p>a boolean that indicates whether the HPO was measured (True) or not explicitly measured (False)</p> <code>True</code> <code>onset</code> <code>TimeElement</code> <p>an ISO8601 string representing the age of onset, optional</p> <code>None</code> <code>resolution</code> <code>TimeElement</code> <p>an ISO8601 string representing the age of resolution, optional</p> <code>None</code> Source code in <code>pyphetools/creation/hp_term.py</code> <pre><code>class HpTerm:\n    \"\"\"\n    Class to represent a phenotypic observation as an HPO term with optional modifiers\n\n    :param hpo_id: a Human Phenotype Ontology (HPO) identifier such as HP:0001166\n    :type hpo_id: str\n    :param label: The HPO label that corresponds to the id (note: This class does not check for correct match)\n    :type label: str\n    :param observed: a boolean that indicates whether the HPO term was observed (True) or excluded (False)\n    :type observed: bool\n    :param measured: a boolean that indicates whether the HPO was measured (True) or not explicitly measured (False)\n    :type measured: bool\n    :param onset: an ISO8601 string representing the age of onset, optional\n    :type onset: str\n    :param resolution: an ISO8601 string representing the age of resolution, optional\n    :type resolution: str\n    \"\"\"\n\n    def __init__(self,\n                 hpo_id: str,\n                 label: str,\n                 observed: bool = True,\n                 measured: bool = True,\n                 onset: TimeElement202 = None,\n                 resolution: TimeElement202 = None):\n        if hpo_id is None or len(hpo_id) == 0 or not hpo_id.startswith(\"HP\"):\n            raise ValueError(f\"invalid id argument: '{hpo_id}'\")\n        if label is None or len(label) == 0:\n            raise ValueError(f\"invalid label argument: '{label}'\")\n        self._id = hpo_id\n        self._label = label\n        self._observed = observed\n        self._measured = measured\n        #if not onset is None or str(type(onset)) != \"&lt;class 'pyphetools.pp.v202._base.TimeElement'&gt;\":\n        #    raise ValueError(f\"onset argument must be TimeElement202 or None but was {type(onset)}\")\n        self._onset = onset\n        self._resolution = resolution\n\n    def __eq__(self, other):\n        if isinstance(other, self.__class__):\n            return self._id == other._id and self._label == other._label and self._measured == other._measured and self._onset == other._onset and self._resolution == other._resolution\n        else:\n            return NotImplemented\n\n    def __hash__(self):\n        return hash((self._id, self._label, self._observed, self._measured, self._onset, self._resolution))\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"\n        :returns: The HPO identifier, e.g., HP:0001166\n        :rtype: str\n        \"\"\"\n        return self._id\n\n    @property\n    def label(self) -&gt; str:\n        \"\"\"\n        :returns: The HPO label, e.g., Arachnodactyly\n        :rtype: str\n        \"\"\"\n        return self._label\n\n    @property\n    def observed(self) -&gt; bool:\n        \"\"\"\n        :returns: True if this feature was observed (i.e., present)\n        :rtype: bool\n        \"\"\"\n        return self._observed\n\n    @property\n    def measured(self) -&gt; bool:\n        \"\"\"\n        :returns: True iff a measurement to assess this abnormality (HpTerm) was performed\n        :rtype: bool\n        \"\"\"\n        return self._measured\n\n    @property\n    def onset(self) -&gt; typing.Optional[TimeElement202]:\n        \"\"\"\n        :returns: A PyPheToolsAge object representing the age this abnormality first was observed\n        :rtype: typing.Optional[TimeElement202]\n        \"\"\"\n        return self._onset\n\n    def set_onset(self, onset: TimeElement202) -&gt; None:\n        if not isinstance(onset, TimeElement202):\n            raise ValueError(f\"argument of set_onset but be TimeElement202 but was {type(onset)}\")\n        self._onset = onset\n\n    @property\n    def resolution(self) -&gt; typing.Optional[TimeElement202]:\n        \"\"\"\n        :returns: A PyPheToolsAge object representing the age this abnormality resolved\n        :rtype: typing.Optional[TimeElement202]\n        \"\"\"\n        return self._resolution\n\n    @property\n    def display_value(self) -&gt; str:\n        \"\"\"\n        :returns: One of three strings describing the status of the term: \"not measured\", \"excluded\", or \"observed\"\n        :rtype: str\n        \"\"\"\n        if not self._measured:\n            return \"not measured\"\n        if not self._observed:\n            return \"excluded\"\n        else:\n            return \"observed\"\n\n    @property\n    def hpo_term_and_id(self) -&gt; str:\n        \"\"\"\n        :returns: A string such as Arachnodactyly (HP:0001166) for display\n        :rtype: str\n        \"\"\"\n        return f\"{self._label} ({self._id})\"\n\n    def _term_and_id_with_onset(self) -&gt; str:\n        if self._onset is not None:\n            return f\"{self.hpo_term_and_id}: onset {self._onset}\"\n        else:\n            return self.hpo_term_and_id\n\n    def __str__(self) -&gt; str:\n        if not self._measured:\n            return f\"not measured: {self._label} ({self._id})\"\n        elif not self._observed:\n            return f\"excluded: {self._term_and_id_with_onset()}\"\n        else:\n            return self._term_and_id_with_onset()\n\n    def to_string(self) -&gt; str:\n        return self.__str__()\n\n    def excluded(self) -&gt; None:\n        \"\"\"\n        Sets the current term to excluded (i.e., the abnormality was sought but explicitly ruled out clinically)\n        \"\"\"\n        self._observed = False\n\n    def to_ga4gh_phenotypic_feature(self) -&gt; PPKt.PhenotypicFeature:\n        \"\"\"\n        :returns: A GA4GH PhenotypcFeature corresponding to this HpTerm\n        :rtype: phenopackets.PhenotypicFeature\n        \"\"\"\n        pf = PPKt.PhenotypicFeature()\n        pf.type.id = self._id\n        pf.type.label = self._label\n        if not self._observed:\n            pf.excluded = True\n        if self._onset is not None:\n            pf.onset.CopyFrom(self._onset.to_message())\n        if self._resolution is not None:\n            pf.resolution.CopyFrom(self._resolution.to_message())\n        return pf\n\n    @staticmethod\n    def term_list_to_dataframe(hpo_list) -&gt; pd.DataFrame:\n        if not isinstance(hpo_list, list):\n            raise ValueError(f\"hpo_list argument must be a list but was {type(hpo_list)}\")\n        if len(hpo_list) &gt; 0:\n            hpo1 = hpo_list[0]\n            if not isinstance(hpo1, HpTerm):\n                raise ValueError(f\"hpo_list argument must consist of HpTerm objects but had {type(hpo1)}\")\n        if len(hpo_list) == 0:\n            return pd.DataFrame(columns=['Col1', 'Col2', 'Col3'])\n        items = []\n        for hp in hpo_list:\n            d = {\"id\": hp.id, \"label\": hp.label, \"observed\": hp.observed, \"measured\": hp.measured}\n            items.append(d)\n        return pd.DataFrame(items)\n\n    @staticmethod\n    def from_hpo_tk_term(hpotk_term: hpotk.Term) -&gt; \"HpTerm\":\n        \"\"\"Create a pyphetools HpTerm object from an hpo-toolkit Term object\n\n        :param hpotk_term: A term from the HPO toolkit\n        :type hpotk_term: hpotk.Term\n        :returns: The corresponding HpTerm object\n        :rtype: HpTerm\n        \"\"\"\n        hpo_id = hpotk_term.identifier.value\n        hpo_label = hpotk_term.name\n        return HpTerm(hpo_id=hpo_id, label=hpo_label)\n</code></pre>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.display_value","title":"<code>display_value</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>One of three strings describing the status of the term: \"not measured\", \"excluded\", or \"observed\"</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.hpo_term_and_id","title":"<code>hpo_term_and_id</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>A string such as Arachnodactyly (HP:0001166) for display</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.id","title":"<code>id</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>The HPO identifier, e.g., HP:0001166</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.label","title":"<code>label</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>The HPO label, e.g., Arachnodactyly</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.measured","title":"<code>measured</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>bool</code> <p>True iff a measurement to assess this abnormality (HpTerm) was performed</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.observed","title":"<code>observed</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>bool</code> <p>True if this feature was observed (i.e., present)</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.onset","title":"<code>onset</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>typing.Optional[TimeElement202]</code> <p>A PyPheToolsAge object representing the age this abnormality first was observed</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.resolution","title":"<code>resolution</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>typing.Optional[TimeElement202]</code> <p>A PyPheToolsAge object representing the age this abnormality resolved</p>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.excluded","title":"<code>excluded()</code>","text":"<p>Sets the current term to excluded (i.e., the abnormality was sought but explicitly ruled out clinically)</p> Source code in <code>pyphetools/creation/hp_term.py</code> <pre><code>def excluded(self) -&gt; None:\n    \"\"\"\n    Sets the current term to excluded (i.e., the abnormality was sought but explicitly ruled out clinically)\n    \"\"\"\n    self._observed = False\n</code></pre>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.from_hpo_tk_term","title":"<code>from_hpo_tk_term(hpotk_term)</code>  <code>staticmethod</code>","text":"<p>Create a pyphetools HpTerm object from an hpo-toolkit Term object</p> <p>Parameters:</p> Name Type Description Default <code>hpotk_term</code> <code>Term</code> <p>A term from the HPO toolkit</p> required <p>Returns:</p> Type Description <code>HpTerm</code> <p>The corresponding HpTerm object</p> Source code in <code>pyphetools/creation/hp_term.py</code> <pre><code>@staticmethod\ndef from_hpo_tk_term(hpotk_term: hpotk.Term) -&gt; \"HpTerm\":\n    \"\"\"Create a pyphetools HpTerm object from an hpo-toolkit Term object\n\n    :param hpotk_term: A term from the HPO toolkit\n    :type hpotk_term: hpotk.Term\n    :returns: The corresponding HpTerm object\n    :rtype: HpTerm\n    \"\"\"\n    hpo_id = hpotk_term.identifier.value\n    hpo_label = hpotk_term.name\n    return HpTerm(hpo_id=hpo_id, label=hpo_label)\n</code></pre>"},{"location":"api/creation/hp_term/#pyphetools.creation.HpTerm.to_ga4gh_phenotypic_feature","title":"<code>to_ga4gh_phenotypic_feature()</code>","text":"<p>Returns:</p> Type Description <code>phenopackets.PhenotypicFeature</code> <p>A GA4GH PhenotypcFeature corresponding to this HpTerm</p> Source code in <code>pyphetools/creation/hp_term.py</code> <pre><code>def to_ga4gh_phenotypic_feature(self) -&gt; PPKt.PhenotypicFeature:\n    \"\"\"\n    :returns: A GA4GH PhenotypcFeature corresponding to this HpTerm\n    :rtype: phenopackets.PhenotypicFeature\n    \"\"\"\n    pf = PPKt.PhenotypicFeature()\n    pf.type.id = self._id\n    pf.type.label = self._label\n    if not self._observed:\n        pf.excluded = True\n    if self._onset is not None:\n        pf.onset.CopyFrom(self._onset.to_message())\n    if self._resolution is not None:\n        pf.resolution.CopyFrom(self._resolution.to_message())\n    return pf\n</code></pre>"},{"location":"api/creation/hpo_cr/","title":"HpoConceptRecognizer","text":"<p>This abstract class acts as an interface for classes that implement parse_cell to perform HPO-based concept recognition.</p> Source code in <code>pyphetools/creation/hpo_cr.py</code> <pre><code>class HpoConceptRecognizer(metaclass=abc.ABCMeta):\n    \"\"\"\n    This abstract class acts as an interface for classes that implement parse_cell to perform HPO-based concept recognition.\n    \"\"\"\n\n    @abc.abstractmethod\n    def parse_cell(self, cell_contents, custom_d=None) -&gt; List[HpTerm]:\n        \"\"\"\n        parse HPO Terms from the contents of a cell of the original table\n\n        :param cell_contents: a cell of the original table\n        :type cell_contents: str\n        :param custom_d: a dictionary with keys for strings in the original table and their mappings to HPO labels\n        :type custom_d: Dict[str,str], optional\n        \"\"\"\n        pass\n\n\n    @abc.abstractmethod\n    def parse_cell_for_exact_matches(self, cell_contents, custom_d) -&gt; List[HpTerm]:\n        \"\"\"\n        Identify HPO Terms from the contents of a cell whose label exactly matches a string in the custom dictionary\n\n        :param cell_contents: a cell of the original table\n        :type cell_contents: str\n        :param custom_d: a dictionary with keys for strings in the original table and their mappings to HPO labels\n        :type custom_d: Dict[str,str]\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def get_term_from_id(self, hpo_id) -&gt; HpTerm:\n        \"\"\"\n        :param hpo_id: an HPO identifier, e.g., HP:0004372\n        :type hpo_id: str\n        :returns: corresponding HPO term\n        :rtype: HpTerm\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def get_term_from_label(self, label) -&gt; HpTerm:\n        \"\"\"\n        :param label: an HPO label, e.g., Arachnodactyly\n        :type label: str\n        :returns: corresponding HPO term\n        :rtype: HpTerm\n        \"\"\"\n        pass\n\n    @abc.abstractmethod\n    def initialize_simple_column_maps(self, column_name_to_hpo_label_map, observed, excluded, non_measured=None):\n        \"\"\"\n        Create a dictionary of SimpleColumnMappers\n        \"\"\"\n        pass\n</code></pre>"},{"location":"api/creation/hpo_cr/#pyphetools.creation.HpoConceptRecognizer.get_term_from_id","title":"<code>get_term_from_id(hpo_id)</code>  <code>abstractmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>hpo_id</code> <code>str</code> <p>an HPO identifier, e.g., HP:0004372</p> required <p>Returns:</p> Type Description <code>HpTerm</code> <p>corresponding HPO term</p> Source code in <code>pyphetools/creation/hpo_cr.py</code> <pre><code>@abc.abstractmethod\ndef get_term_from_id(self, hpo_id) -&gt; HpTerm:\n    \"\"\"\n    :param hpo_id: an HPO identifier, e.g., HP:0004372\n    :type hpo_id: str\n    :returns: corresponding HPO term\n    :rtype: HpTerm\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/creation/hpo_cr/#pyphetools.creation.HpoConceptRecognizer.get_term_from_label","title":"<code>get_term_from_label(label)</code>  <code>abstractmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>label</code> <code>str</code> <p>an HPO label, e.g., Arachnodactyly</p> required <p>Returns:</p> Type Description <code>HpTerm</code> <p>corresponding HPO term</p> Source code in <code>pyphetools/creation/hpo_cr.py</code> <pre><code>@abc.abstractmethod\ndef get_term_from_label(self, label) -&gt; HpTerm:\n    \"\"\"\n    :param label: an HPO label, e.g., Arachnodactyly\n    :type label: str\n    :returns: corresponding HPO term\n    :rtype: HpTerm\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/creation/hpo_cr/#pyphetools.creation.HpoConceptRecognizer.initialize_simple_column_maps","title":"<code>initialize_simple_column_maps(column_name_to_hpo_label_map, observed, excluded, non_measured=None)</code>  <code>abstractmethod</code>","text":"<p>Create a dictionary of SimpleColumnMappers</p> Source code in <code>pyphetools/creation/hpo_cr.py</code> <pre><code>@abc.abstractmethod\ndef initialize_simple_column_maps(self, column_name_to_hpo_label_map, observed, excluded, non_measured=None):\n    \"\"\"\n    Create a dictionary of SimpleColumnMappers\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/creation/hpo_cr/#pyphetools.creation.HpoConceptRecognizer.parse_cell","title":"<code>parse_cell(cell_contents, custom_d=None)</code>  <code>abstractmethod</code>","text":"<p>parse HPO Terms from the contents of a cell of the original table</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>a cell of the original table</p> required <code>custom_d</code> <code>Dict[str,str], optional</code> <p>a dictionary with keys for strings in the original table and their mappings to HPO labels</p> <code>None</code> Source code in <code>pyphetools/creation/hpo_cr.py</code> <pre><code>@abc.abstractmethod\ndef parse_cell(self, cell_contents, custom_d=None) -&gt; List[HpTerm]:\n    \"\"\"\n    parse HPO Terms from the contents of a cell of the original table\n\n    :param cell_contents: a cell of the original table\n    :type cell_contents: str\n    :param custom_d: a dictionary with keys for strings in the original table and their mappings to HPO labels\n    :type custom_d: Dict[str,str], optional\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/creation/hpo_cr/#pyphetools.creation.HpoConceptRecognizer.parse_cell_for_exact_matches","title":"<code>parse_cell_for_exact_matches(cell_contents, custom_d)</code>  <code>abstractmethod</code>","text":"<p>Identify HPO Terms from the contents of a cell whose label exactly matches a string in the custom dictionary</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>a cell of the original table</p> required <code>custom_d</code> <code>Dict[str,str]</code> <p>a dictionary with keys for strings in the original table and their mappings to HPO labels</p> required Source code in <code>pyphetools/creation/hpo_cr.py</code> <pre><code>@abc.abstractmethod\ndef parse_cell_for_exact_matches(self, cell_contents, custom_d) -&gt; List[HpTerm]:\n    \"\"\"\n    Identify HPO Terms from the contents of a cell whose label exactly matches a string in the custom dictionary\n\n    :param cell_contents: a cell of the original table\n    :type cell_contents: str\n    :param custom_d: a dictionary with keys for strings in the original table and their mappings to HPO labels\n    :type custom_d: Dict[str,str]\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/creation/hpo_exact_cr/","title":"HpoExactConceptRecognizer","text":"<p>               Bases: <code>HpoBaseConceptRecognizer</code></p> Source code in <code>pyphetools/creation/hpo_exact_cr.py</code> <pre><code>class HpoExactConceptRecognizer(HpoBaseConceptRecognizer):\n\n    @staticmethod\n    def from_hpo(hpo: hpotk.Ontology):\n        label_to_id = get_label_to_id_map(hpo)\n        id_to_primary_label = get_id_to_label_map(hpo)\n\n        return HpoExactConceptRecognizer(\n            label_to_id=label_to_id,\n            id_to_primary_label=id_to_primary_label,\n        )\n\n    def __init__(self, **kwargs):\n        super(HpoExactConceptRecognizer, self).__init__(**kwargs)\n\n    def _find_hpo_term_in_lc_chunk(self, lc_chunk) -&gt; typing.List[HpTerm]:\n        hits = []\n        for lower_case_hp_label, hpo_tid in self._label_to_id.items():\n            key = lower_case_hp_label.lower()\n            startpos = lc_chunk.find(key)\n            endpos = startpos + len(key) - 1\n            if startpos &lt; 0:\n                continue\n            # If we get here, we demand that the match is a complete word\n            # This is because otherwise we get some spurious matches such as Pica HP:0011856 matching to typical\n            # Create a regex to enforce the match is at word boundary\n            BOUNDARY_REGEX = re.compile(r'\\b%s\\b' % key, re.I)\n            if BOUNDARY_REGEX.search(lc_chunk):\n                hp_term = super(HpoExactConceptRecognizer, self).get_term_from_id(\n                    hpo_id=hpo_tid)  # Get properly capitalized label\n                hits.append(ConceptMatch(term=hp_term, start=startpos, end=endpos))\n        return hits\n</code></pre>"},{"location":"api/creation/hpo_parser/","title":"HpoParser","text":"<p>Class to retrieve and parse the HPO JSON file using the HPO-Toolkit</p> <p>Users probably will want to set the <code>release</code> option (e.g. <code>v2024-03-06</code> for the last release as of the time of this writing) or pass the path to the <code>hp.json</code> file via <code>hpo_json_file</code> option.</p> <p>Both options are optional, and the last HPO release will be used by default. The <code>release</code> has a priority over <code>hpo_json_file</code>.</p> <p>Parameters:</p> Name Type Description Default <code>hpo_json_file</code> <code>Optional[str]</code> <p>a <code>str</code> with a URL pointing to a remote <code>hp.json</code> (only <code>http</code> and <code>https</code> protocols are supported (no <code>file</code>, <code>ftp</code>)) or a path to a local <code>hp.json</code> file.</p> <code>None</code> <code>release</code> <code>Optional[str]</code> <p>an optional <code>str</code> with the HPO release tag or <code>None</code> if the latest HPO release should be used.</p> <code>None</code> Source code in <code>pyphetools/creation/hpo_parser.py</code> <pre><code>class HpoParser:\n    \"\"\"\n    Class to retrieve and parse the HPO JSON file using the HPO-Toolkit\n\n    Users probably will want to set the `release` option (e.g. `v2024-03-06` for the last release\n    as of the time of this writing) or pass the path to the `hp.json` file via `hpo_json_file` option.\n\n    Both options are optional, and the last HPO release will be used by default. The `release` has a priority\n    over `hpo_json_file`.\n\n    :param hpo_json_file: a `str` with a URL pointing to a remote `hp.json` (only ``http`` and ``https`` protocols\n    are supported (no ``file``, ``ftp``)) or a path to a local `hp.json` file.\n    :param release: an optional `str` with the HPO release tag or `None` if the latest HPO release should be used.\n    \"\"\"\n    # TODO: consider deprecating this class. It is not too useful after adding `OntologyStore` API to `hpo-toolkit&gt;=0.5.0`.\n\n    def __init__(\n            self,\n            hpo_json_file: typing.Optional[str] = None,\n            release: typing.Optional[str] = None,\n    ):\n        if release is not None:\n            store = hpotk.configure_ontology_store()\n            self._ontology = store.load_hpo(release=release)\n        elif hpo_json_file is not None:\n            if not hpo_json_file.startswith('http') and not os.path.isfile(hpo_json_file):\n                raise FileNotFoundError(f\"Could not find hp.json file at {hpo_json_file}\")\n            self._ontology = hpotk.load_ontology(hpo_json_file)\n        else:\n            store = hpotk.configure_ontology_store()\n            self._ontology = store.load_hpo()\n\n    def get_ontology(self) -&gt; hpotk.Ontology:\n        \"\"\"\n        :returns: a reference to the HPO\n        \"\"\"\n        return self._ontology\n\n    def get_label_to_id_map(self) -&gt; typing.Mapping[str, str]:\n        \"\"\"\n        Create a map from a lower case version of HPO labels to the corresponding HPO id\n        only include terms that are descendants of PHENOTYPE_ROOT\n\n        :returns: a map from lower-case HPO term labels to HPO ids\n        \"\"\"\n        label_to_id_d = {}\n        for term in self._ontology.terms:\n            hpo_id = term.identifier\n            if not self._ontology.graph.is_ancestor_of(hpotk.constants.hpo.base.PHENOTYPIC_ABNORMALITY, hpo_id):\n                continue\n            label_to_id_d[term.name.lower()] = hpo_id.value\n            # Add the labels of the synonyms\n            if term.synonyms is not None and len(term.synonyms) &gt; 0:\n                for synonym in term.synonyms:\n                    lc_syn = synonym.name.lower()\n                    # only take synonyms with length at least 5 to avoid spurious matches\n                    if len(lc_syn) &gt; 4:\n                        label_to_id_d[lc_syn] = hpo_id.value\n\n        return label_to_id_d\n\n    def get_id_to_label_map(self) -&gt; typing.Mapping[str, str]:\n        \"\"\"\n        :returns: a map from HPO term ids to HPO labels\n        :rtype: Dict[str,str]\n        \"\"\"\n        id_to_label_d = {}\n\n        for term in self._ontology.terms:\n            id_to_label_d[term.identifier.value] = term.name\n\n        return id_to_label_d\n\n    def get_hpo_concept_recognizer(self, hp_cr_index:str=None) -&gt; HpoConceptRecognizer:\n        if hp_cr_index:\n            return HpoFastHPOCRConceptRecognizer(\n                label_to_id=self.get_label_to_id_map(),\n                id_to_primary_label=self.get_id_to_label_map(),\n                hp_cr_index=hp_cr_index\n            )\n        return HpoExactConceptRecognizer(\n            label_to_id=self.get_label_to_id_map(),\n            id_to_primary_label=self.get_id_to_label_map(),\n        )\n\n    def get_version(self) -&gt; typing.Optional[str]:\n        return self._ontology.version\n</code></pre>"},{"location":"api/creation/hpo_parser/#pyphetools.creation.HpoParser.get_id_to_label_map","title":"<code>get_id_to_label_map()</code>","text":"<p>Returns:</p> Type Description <code>Dict[str,str]</code> <p>a map from HPO term ids to HPO labels</p> Source code in <code>pyphetools/creation/hpo_parser.py</code> <pre><code>def get_id_to_label_map(self) -&gt; typing.Mapping[str, str]:\n    \"\"\"\n    :returns: a map from HPO term ids to HPO labels\n    :rtype: Dict[str,str]\n    \"\"\"\n    id_to_label_d = {}\n\n    for term in self._ontology.terms:\n        id_to_label_d[term.identifier.value] = term.name\n\n    return id_to_label_d\n</code></pre>"},{"location":"api/creation/hpo_parser/#pyphetools.creation.HpoParser.get_label_to_id_map","title":"<code>get_label_to_id_map()</code>","text":"<p>Create a map from a lower case version of HPO labels to the corresponding HPO id only include terms that are descendants of PHENOTYPE_ROOT</p> <p>Returns:</p> Type Description <code>Mapping[str, str]</code> <p>a map from lower-case HPO term labels to HPO ids</p> Source code in <code>pyphetools/creation/hpo_parser.py</code> <pre><code>def get_label_to_id_map(self) -&gt; typing.Mapping[str, str]:\n    \"\"\"\n    Create a map from a lower case version of HPO labels to the corresponding HPO id\n    only include terms that are descendants of PHENOTYPE_ROOT\n\n    :returns: a map from lower-case HPO term labels to HPO ids\n    \"\"\"\n    label_to_id_d = {}\n    for term in self._ontology.terms:\n        hpo_id = term.identifier\n        if not self._ontology.graph.is_ancestor_of(hpotk.constants.hpo.base.PHENOTYPIC_ABNORMALITY, hpo_id):\n            continue\n        label_to_id_d[term.name.lower()] = hpo_id.value\n        # Add the labels of the synonyms\n        if term.synonyms is not None and len(term.synonyms) &gt; 0:\n            for synonym in term.synonyms:\n                lc_syn = synonym.name.lower()\n                # only take synonyms with length at least 5 to avoid spurious matches\n                if len(lc_syn) &gt; 4:\n                    label_to_id_d[lc_syn] = hpo_id.value\n\n    return label_to_id_d\n</code></pre>"},{"location":"api/creation/hpo_parser/#pyphetools.creation.HpoParser.get_ontology","title":"<code>get_ontology()</code>","text":"<p>Returns:</p> Type Description <code>Ontology</code> <p>a reference to the HPO</p> Source code in <code>pyphetools/creation/hpo_parser.py</code> <pre><code>def get_ontology(self) -&gt; hpotk.Ontology:\n    \"\"\"\n    :returns: a reference to the HPO\n    \"\"\"\n    return self._ontology\n</code></pre>"},{"location":"api/creation/individual/","title":"Individual","text":"<p>A class to represent one individual of the cohort</p> <p>Parameters:</p> Name Type Description Default <code>individual_id</code> <code>str</code> <p>The individual identifier</p> required <code>hpo_terms</code> <code>List[HpTerm]</code> <p>List of HpTerm objects</p> <code>None</code> <code>sex</code> <code>str</code> <p>String corresponding to the sex of the individual, default, n/a</p> <code>NOT_PROVIDED</code> <code>age</code> <code>str</code> <p>String corresponding to the age of the individual (ISO), default, n/a</p> required <code>interpretation_list</code> <code>List[VariantInterpretation]</code> <p>list of GA4GH VariationInterpretation objects</p> <code>None</code> <code>disease</code> <code>Disease</code> <p>object defining the disease diagnosos</p> <code>None</code> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>class Individual:\n    \"\"\"\n    A class to represent one individual of the cohort\n\n    :param individual_id: The individual identifier\n    :type individual_id: str\n    :param hpo_terms: List of HpTerm objects\n    :type hpo_terms: List[pyphetools.creation.HpTerm]\n    :param sex: String corresponding to the sex of the individual, default, n/a\n    :type sex: str\n    :param age: String corresponding to the age of the individual (ISO), default, n/a\n    :type age: str\n    :param interpretation_list: list of GA4GH VariationInterpretation objects\n    :type interpretation_list: List[PPKt.VariationInterpretation], optional\n    :param disease: object defining the disease diagnosos\n    :type disease: Disease, optional\n    \"\"\"\n\n    def __init__(self,\n                 individual_id: str,\n                 hpo_terms: List[HpTerm] = None,\n                 citation: Citation = None,\n                 sex: str = Constants.NOT_PROVIDED,\n                 age_of_onset: TimeElement202 = None,\n                 age_at_last_encounter: TimeElement202 = None,\n                 vital_status: VitalStatus202 = None,\n                 interpretation_list: List[PPKt.VariantInterpretation] = None,\n                 disease: Disease = None):\n        \"\"\"Constructor\n        \"\"\"\n        if isinstance(individual_id, int):\n            self._individual_id = str(individual_id)\n        elif isinstance(individual_id, str):\n            self._individual_id = individual_id\n        else:\n            raise ValueError(f\"individual_id argument must be int or string but was {type(individual_id)}\")\n        if sex is None:\n            self._sex = PPKt.Sex.UNKNOWN_SEX\n        else:\n            self._sex = sex\n        #if age_of_onset is None or isinstance(age_of_onset, str):\n        #    raise ValueError(f\"age_of_onset argument must be PyPheToolsAge but was {type(age_of_onset)}\")\n        self._age_of_onset = age_of_onset\n        #if age_at_last_encounter is None or isinstance(age_at_last_encounter, str):\n        #    raise ValueError(f\"age_at_last_encounter argument must be PyPheToolsAge but was {type(age_of_onset)}\")\n        self._age_at_last_encounter = age_at_last_encounter\n        self._vital_status = vital_status\n        if hpo_terms is None:\n            self._hpo_terms = list()\n        else:\n            self._hpo_terms = hpo_terms\n        if interpretation_list is None:\n            self._interpretation_list = list()\n        else:\n            self._interpretation_list = interpretation_list\n        self._disease = disease\n        self._citation = citation\n\n    @property\n    def id(self):\n        \"\"\"\n        :returns: the individual identifier\n        :rtype: str\n        \"\"\"\n        return self._individual_id\n\n    @property\n    def sex(self):\n        \"\"\"\n        :returns: one of 'MALE', 'FEMALE', 'OTHER', 'UNKNOWN'\n        :rtype: str\n        \"\"\"\n        return self._sex\n\n    def set_sex(self, sex):\n        self._sex = sex\n\n    @property\n    def age_of_onset(self) -&gt; typing.Optional[TimeElement202]:\n        \"\"\"\n        :returns: a representation of age when the disease first manifested\n        :rtype: PyPheToolsAge\n        \"\"\"\n        return self._age_of_onset\n\n    @property\n    def age_at_last_encounter(self) -&gt; typing.Optional[TimeElement202]:\n        \"\"\"\n        :returns: a representation of age when the individual was last seen in a medical context\n        :rtype: PyPheToolsAge\n        \"\"\"\n        return self._age_at_last_encounter\n\n    @property\n    def hpo_terms(self):\n        \"\"\"\n        :returns: a list of observed and excluded HPO terms\n        :rtype: List[pyphetools.creation.HpTerm]\n        \"\"\"\n        return self._hpo_terms\n\n    @property\n    def interpretation_list(self) -&gt; List[PPKt.VariantInterpretation]:\n        \"\"\"\n        :returns: a list of GA4GH Genomic Interpretations\n        :rtype: List[PPKt.VariantInterpretation]\n        \"\"\"\n        return self._interpretation_list\n\n    def add_variant(self, v: Union[Variant, PPKt.VariantInterpretation], acmg: str = None):\n        \"\"\"\n        :param v: A Variant obeserved in this individual\n        :type v: Union[Variant, PPKt.VariantInterpretation]\n        :param acmg: One of the five ACMG pathogenicity categories\n        :type acmg: str\n        \"\"\"\n        if isinstance(v, Variant):\n            variant = v.to_ga4gh_variant_interpretation(acmg=acmg)\n        else:\n            variant = v\n        if isinstance(variant, PPKt.VariantInterpretation):\n            self._interpretation_list.append(variant)\n        else:\n            raise ValueError(\n                f\"variant argument must be pyphetools Variant or GA4GH VariantInterpretation but was {type(variant)}\")\n\n    def add_hpo_term(self, term: HpTerm) -&gt; None:\n        \"\"\"\n        Adds one HPO term to the current individual.\n        :param term: An HPO term (observed or excluded, potentially with Age of observation\n        :type term: HpTerm\n        \"\"\"\n        if not isinstance(term, HpTerm):\n            raise ValueError(f\"\\\"term\\\" argument must be HpTerm but was {type(term)}\")\n        self._hpo_terms.append(term)\n\n    def set_disease(self, disease: Disease) -&gt; None:\n        \"\"\"\n        This method is typically useful for a cohort with multiple diagnoses; otherwise, the disease can be set by the\n        CohortEncoder\n\n        :param disease: the disease diagnosis for this individual\n        :type disease: Disease\n        \"\"\"\n        self._disease = disease\n\n    def disease_count(self) -&gt; int:\n        if self._disease is None:\n            return 0\n        else:\n            return 1\n\n    def set_hpo_terms(self, cleansed_hpo_terms: List[HpTerm]) -&gt; None:\n        \"\"\"\n        :param cleansed_hpo_terms: a list of HpTerm objects that has been cleansed by OntologyQC\n        :type cleansed_hpo_terms: List[pyphetools.creation.HpTerm]\n        \"\"\"\n        self._hpo_terms = cleansed_hpo_terms\n\n    @property\n    def pmid(self) -&gt; str:\n        return self._citation.pmid\n\n    def set_citation(self, citation: Citation) -&gt; None:\n        \"\"\"\n        :param citation: Object with the title and PubMed identifier for the publication in which this individual was described (e.g. PMID:321..)\n        :type citation: Citation\n        \"\"\"\n        self._citation = citation\n\n    def set_vital_status(self, vstatus: VitalStatus202):\n        if not isinstance(vstatus, VitalStatus202):\n            raise ValueError(f\"vstatus argument must be pyphetools.pp.v202.VitalStatus but was{type(vstatus)}\")\n        self._vital_status = vstatus\n\n    def get_vital_status(self) -&gt; VitalStatus202:\n        return self._vital_status\n\n    def get_phenopacket_id(self, phenopacket_id=None) -&gt; str:\n        \"\"\"\n        :returns: the Phenopacket identifier for this individual\n        :rtype: str\n        \"\"\"\n        if phenopacket_id is None:\n            indi_id = self._individual_id.replace(\" \", \"_\")\n            if self._citation is not None:\n                pmid = self._citation.pmid.replace(\":\", \"_\")\n                ppkt_id = f\"{pmid}_{indi_id}\"\n            else:\n                ppkt_id = indi_id\n        else:\n            ppkt_id = phenopacket_id\n        # strip non alphanumeric characters\n        ppkt_id = ''.join(e if e.isalnum() else \"_\" for e in ppkt_id)\n        ppkt_id = ppkt_id.replace(\"__\", \"_\")\n        if ppkt_id.endswith(\"_\"):\n            ppkt_id = ppkt_id[:-1]\n        return ppkt_id\n\n    def get_citation(self) -&gt; Citation:\n        \"\"\"\n        :returns: a Citation object with PMID and article title\n        :rtype: Citation\n        \"\"\"\n        return self._citation\n\n    def _get_onset(self) -&gt; typing.Optional[TimeElement202]:\n        \"\"\"The assumption of this method is that if we have a valid age of onset field, use this.\n        Otherwise, try to find an age of onset from the phenotypic features and take the youngest age\n        \"\"\"\n        if self._age_of_onset is not None and self._age_of_onset != Constants.NOT_PROVIDED:\n            return self._age_of_onset\n        phenotypic_feature_onsets = set()\n        if isinstance(self._hpo_terms, list):\n            for hp in self._hpo_terms:\n                if not hp.measured:\n                    continue\n                pf = hp.to_ga4gh_phenotypic_feature()\n                if pf.onset.age.iso8601duration is None:\n                    phenotypic_feature_onsets.add(pf.onset)\n        if len(phenotypic_feature_onsets) == 0:\n            return None\n        age_format_list = list(phenotypic_feature_onsets)\n        sorted_age_list = AgeSorter.sort_by_age(age_format_list)\n        youngest_age = sorted_age_list[0]\n        return youngest_age\n\n    def _get_disease_object(self):\n        iso_age = self._get_onset()\n        disease_term = PPKt.OntologyClass()\n        if self._disease is not None:\n            disease_term.id = self._disease.id\n            disease_term.label = self._disease.label\n        else:\n            disease_term.id = \"MONDO:0000001\"\n            disease_term.label = \"disease\"\n            print(\"[WARNING] could not find disease information\")\n        disease_object = PPKt.Disease()\n        disease_object.term.CopyFrom(disease_term)\n        if self.age_of_onset is not None:\n            disease_object.onset.CopyFrom(self.age_of_onset.to_message())\n        if iso_age is not None:\n            disease_object.onset.CopyFrom(iso_age.to_message())\n        return disease_object\n\n    def to_ga4gh_phenopacket(self, metadata, phenopacket_id=None) -&gt; PPKt.Phenopacket:\n        \"\"\"\n        Transform the data into GA4GH Phenopacket format\n        :returns:  a GA4GH Phenopacket representing this individual\n        :rtype: PPKt.Phenopacket\n        \"\"\"\n        if isinstance(metadata, MetaData):\n            metadata = metadata.to_ga4gh()\n        if not isinstance(metadata, PPKt.MetaData):\n            raise ValueError(\n                f\"metadata argument must be pyphetools.MetaData or GA4GH MetaData but was {type(metadata)}\")\n        php = PPKt.Phenopacket()\n        php.id = self.get_phenopacket_id(phenopacket_id=phenopacket_id)\n        php.subject.id = self._individual_id\n        if self._age_at_last_encounter is not None:\n            php.subject.time_at_last_encounter.CopyFrom(self._age_at_last_encounter.to_message())\n        if self._sex == Constants.MALE_SYMBOL:\n            php.subject.sex = PPKt.Sex.MALE\n        elif self._sex == Constants.FEMALE_SYMBOL:\n            php.subject.sex = PPKt.Sex.FEMALE\n        elif self._sex == Constants.OTHER_SEX_SYMBOL:\n            php.subject.sex = PPKt.Sex.OTHER_SEX\n        elif self._sex == Constants.UNKNOWN_SEX_SYMBOL:\n            php.subject.sex = PPKt.Sex.UNKNOWN_SEX\n        if self._vital_status is not None:\n            vs = self._vital_status.to_message()\n            php.subject.vital_status.CopyFrom(vs)\n        disease_object = self._get_disease_object()\n        php.diseases.append(disease_object)\n        if isinstance(self._hpo_terms, list):\n            for hp in self._hpo_terms:\n                if not hp.measured:\n                    continue\n                pf = hp.to_ga4gh_phenotypic_feature()\n                if pf.onset.age.iso8601duration is None and self._age_of_onset != Constants.NOT_PROVIDED:\n                    pf.onset.age.iso8601duration = self._age_of_onset\n                php.phenotypic_features.append(pf)\n        elif isinstance(self._hpo_terms, dict):\n            for age_key, hpoterm_list in self._hpo_terms.items():\n                for hp in hpoterm_list:\n                    if not hp.measured:\n                        continue\n                    pf = hp.to_phenotypic_feature()\n                    # only adjust age of onset if not present\n                    if pf.onset.age.iso8601duration is None and age_key.startswith(\"P\"):\n                        pf.onset.age.iso8601duration = age_key\n                    php.phenotypic_features.append(pf)\n        if len(self._interpretation_list) &gt; 0:\n            interpretation = PPKt.Interpretation()\n            interpretation.id = self._individual_id\n            interpretation.progress_status = PPKt.Interpretation.ProgressStatus.SOLVED\n            if self._disease is not None:\n                interpretation.diagnosis.disease.id = self._disease.id\n                interpretation.diagnosis.disease.label = self._disease.label\n            for var in self._interpretation_list:\n                genomic_interpretation = PPKt.GenomicInterpretation()\n                genomic_interpretation.subject_or_biosample_id = self._individual_id\n                # by assumption, variants passed to this package are all causative\n                genomic_interpretation.interpretation_status = PPKt.GenomicInterpretation.InterpretationStatus.CAUSATIVE\n                genomic_interpretation.variant_interpretation.CopyFrom(var)\n                interpretation.diagnosis.genomic_interpretations.append(genomic_interpretation)\n            php.interpretations.append(interpretation)\n        if self._citation is not None:\n            # overrides the \"general\" setting of the external reference for the entire cohort\n            while len(metadata.external_references) &gt; 0:\n                # `protobuf` devs must have removed `clear()` method\n                # This is a workaround to clear the list of external references.\n                _ = metadata.external_references.pop()\n            extref202 = self._citation.to_external_reference()\n            metadata.external_references.append(extref202.to_message())\n        php.meta_data.CopyFrom(metadata)\n        return php\n\n    def __str__(self):\n        hpo_list = [t.to_string() for t in self._hpo_terms]\n        hpo_str = \"\\n\" + \"\\n\".join(hpo_list)\n        return f\"{self._individual_id}: {self._age_of_onset}, {self._sex}: {self._disease} {hpo_str}\"\n\n    @staticmethod\n    def output_individuals_as_phenopackets(individual_list, metadata: MetaData, outdir=\"phenopackets\"):\n        \"\"\"write a list of Individual objects to file in GA4GH Phenopacket format\n\n        This methods depends on the MetaData object having a PMID and will fail otherwise\n\n        :param individual_list: List of individuals to be written to file as phenopackets\n        :type individual_list: List[Individual]\n        :param metadata: pyphetools MetaData object\n        :type metadata: MetaData\n        :param outdir: Path to output directory. Defaults to \"phenopackets\". Created if not exists.\n        :type outdir: str\n        \"\"\"\n        if os.path.isfile(outdir):\n            raise ValueError(f\"Attempt to create directory with name of existing file {outdir}\")\n        if not os.path.isdir(outdir):\n            os.makedirs(outdir)\n        written = 0\n        if not isinstance(metadata, MetaData):\n            raise ValueError(\n                f\"metadata argument must be pyphetools MetaData object (not GA4GH metadata message), but was {type(metadata)}\")\n        pmid = metadata.get_pmid()\n        for individual in individual_list:\n            phenopckt = individual.to_ga4gh_phenopacket(metadata=metadata)\n            json_string = MessageToJson(phenopckt)\n            if pmid is None:\n                fname = \"phenopacket_\" + individual.id\n            else:\n                pmid = pmid.replace(\" \", \"\").replace(\":\", \"_\")\n                fname = pmid + \"_\" + individual.id\n            fname = re.sub('[^A-Za-z0-9_-]', '', fname)  # remove any illegal characters from filename\n            fname = fname.replace(\" \", \"_\") + \".json\"\n            outpth = os.path.join(outdir, fname)\n            with open(outpth, \"wt\") as fh:\n                fh.write(json_string)\n                written += 1\n        print(f\"We output {written} GA4GH phenopackets to the directory {outdir}\")\n\n    @staticmethod\n    def from_ga4gh_metadata(mdata: PPKt.MetaData) -&gt; MetaData:\n        created_by = mdata.created_by\n        created_time = str(mdata.created)\n        if len(mdata.external_references) &gt; 1:\n            raise ValueError(\"multiple external references not supported\")\n        elif len(mdata.external_references) == 0:\n            id = None\n            reference = None\n            description = None\n        else:\n            eref = mdata.external_references[0]\n            id = eref.id\n            reference = eref.reference\n            description = eref.description\n        resource_list = []\n        for resource in mdata.resources:\n            resource_id = resource.id\n            name = resource.name\n            namespace_prefix = resource.namespace_prefix\n            iri_prefix = resource.iri_prefix\n            url = resource.url\n            version = resource.version\n            r = Resource(resource_id=resource_id, name=name, namespace_prefix=namespace_prefix, iriprefix=iri_prefix,\n                         url=url, version=version)\n            resource_list.append(r)\n        cite = Citation(pmid=id, title=description)\n        metadata = MetaData(created_by=created_by, citation=cite)\n        for r in resource_list:\n            metadata.add_reference(r)\n        return metadata\n\n    @staticmethod\n    def get_variants_and_disease(ppkt: PPKt.Phenopacket):\n        \"\"\"extract the pyphetools Disease object and the VariantInterpretation objects that can be used to construct an Individual\n\n        :param ppkt: a GA4GH phenopacket\n        :type ppkt: PPKT.Phenopacket\n        :returns: tjhe corresponding Individual object\n        :rtype: Individual, List[PPKt.VariantInterpretation]\n        \"\"\"\n        if len(ppkt.interpretations) == 0:\n            print(f\"No interpretation found for {ppkt.id}\")\n            return None, []\n        if len(ppkt.interpretations) &gt; 1:\n            raise ValueError(\n                f\"pyphetools dpoes not currently support multiple Interpretation messages in one phenopacket but we found {len(ppkt.interpretations)}\")\n        interpretation = ppkt.interpretations[0]\n        if interpretation.HasField(\"diagnosis\") and interpretation.diagnosis.HasField(\"disease\"):\n            d = interpretation.diagnosis.disease\n            disease = Disease(disease_id=d.id, disease_label=d.label)\n        else:\n            disease = None\n        if len(interpretation.diagnosis.genomic_interpretations) == 0:\n            return disease, []\n        else:\n            variant_list = []\n            for gen_interpretation in interpretation.diagnosis.genomic_interpretations:\n                variant_list.append(gen_interpretation.variant_interpretation)\n            return disease, variant_list\n\n    @staticmethod\n    def from_ga4gh_phenopacket(ppkt: PPKt.Phenopacket):\n        \"\"\"\n        Transform a GA4GH Phenopacket into an Individual object -- useful for testing\n        :returns:  an individual object corresponding to the GA4GH Phenopacket\n        :rtype: Individual\n        \"\"\"\n        if not isinstance(ppkt, PPKt.Phenopacket):\n            raise ValueError(f\"argument must be a GA4GH Phenopacket Message but was {type(ppkt)}\")\n        #metadata = ppkt.meta_data\n        #pypt_metadata = Individual.from_ga4gh_metadata(mdata=metadata)\n        subject_id = ppkt.subject.id\n        sex = ppkt.subject.sex\n        age_at_last_encounter = ppkt.subject.time_at_last_encounter.age.iso8601duration\n        age_of_onset = None\n        if len(ppkt.diseases) &gt; 0:\n            d = ppkt.diseases[0]\n            if d.HasField(\"onset\") and d.onset.HasField(\"age\"):\n                age_of_onset = TimeElement202.from_message(d.onset.age)\n        hpo_terms = []\n        for pf in ppkt.phenotypic_features:\n            hpo_id = pf.type.id\n            hpo_label = pf.type.label\n            observed = not pf.excluded\n            onset_age = None\n            if pf.HasField(\"onset\"):\n                onset_age = TimeElement202.from_message(pf.onset)\n            hpo_terms.append(HpTerm(hpo_id=hpo_id, label=hpo_label, observed=observed, onset=onset_age))\n        disease, var_list = Individual.get_variants_and_disease(ppkt)\n        indi = Individual(individual_id=subject_id,\n                          hpo_terms=hpo_terms,\n                          citation=None,\n                          sex=sex,\n                          age_of_onset=age_of_onset,\n                          age_at_last_encounter=age_at_last_encounter,\n                          interpretation_list=var_list)\n        if disease is not None:\n            indi.set_disease(disease=disease)\n        return indi\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.age_at_last_encounter","title":"<code>age_at_last_encounter</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>PyPheToolsAge</code> <p>a representation of age when the individual was last seen in a medical context</p>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.age_of_onset","title":"<code>age_of_onset</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>PyPheToolsAge</code> <p>a representation of age when the disease first manifested</p>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.hpo_terms","title":"<code>hpo_terms</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>List[pyphetools.creation.HpTerm]</code> <p>a list of observed and excluded HPO terms</p>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.id","title":"<code>id</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>the individual identifier</p>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.interpretation_list","title":"<code>interpretation_list</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>List[PPKt.VariantInterpretation]</code> <p>a list of GA4GH Genomic Interpretations</p>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.sex","title":"<code>sex</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>one of 'MALE', 'FEMALE', 'OTHER', 'UNKNOWN'</p>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.__init__","title":"<code>__init__(individual_id, hpo_terms=None, citation=None, sex=Constants.NOT_PROVIDED, age_of_onset=None, age_at_last_encounter=None, vital_status=None, interpretation_list=None, disease=None)</code>","text":"<p>Constructor</p> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def __init__(self,\n             individual_id: str,\n             hpo_terms: List[HpTerm] = None,\n             citation: Citation = None,\n             sex: str = Constants.NOT_PROVIDED,\n             age_of_onset: TimeElement202 = None,\n             age_at_last_encounter: TimeElement202 = None,\n             vital_status: VitalStatus202 = None,\n             interpretation_list: List[PPKt.VariantInterpretation] = None,\n             disease: Disease = None):\n    \"\"\"Constructor\n    \"\"\"\n    if isinstance(individual_id, int):\n        self._individual_id = str(individual_id)\n    elif isinstance(individual_id, str):\n        self._individual_id = individual_id\n    else:\n        raise ValueError(f\"individual_id argument must be int or string but was {type(individual_id)}\")\n    if sex is None:\n        self._sex = PPKt.Sex.UNKNOWN_SEX\n    else:\n        self._sex = sex\n    #if age_of_onset is None or isinstance(age_of_onset, str):\n    #    raise ValueError(f\"age_of_onset argument must be PyPheToolsAge but was {type(age_of_onset)}\")\n    self._age_of_onset = age_of_onset\n    #if age_at_last_encounter is None or isinstance(age_at_last_encounter, str):\n    #    raise ValueError(f\"age_at_last_encounter argument must be PyPheToolsAge but was {type(age_of_onset)}\")\n    self._age_at_last_encounter = age_at_last_encounter\n    self._vital_status = vital_status\n    if hpo_terms is None:\n        self._hpo_terms = list()\n    else:\n        self._hpo_terms = hpo_terms\n    if interpretation_list is None:\n        self._interpretation_list = list()\n    else:\n        self._interpretation_list = interpretation_list\n    self._disease = disease\n    self._citation = citation\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.add_hpo_term","title":"<code>add_hpo_term(term)</code>","text":"<p>Adds one HPO term to the current individual.</p> <p>Parameters:</p> Name Type Description Default <code>term</code> <code>HpTerm</code> <p>An HPO term (observed or excluded, potentially with Age of observation</p> required Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def add_hpo_term(self, term: HpTerm) -&gt; None:\n    \"\"\"\n    Adds one HPO term to the current individual.\n    :param term: An HPO term (observed or excluded, potentially with Age of observation\n    :type term: HpTerm\n    \"\"\"\n    if not isinstance(term, HpTerm):\n        raise ValueError(f\"\\\"term\\\" argument must be HpTerm but was {type(term)}\")\n    self._hpo_terms.append(term)\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.add_variant","title":"<code>add_variant(v, acmg=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>v</code> <code>Union[Variant, VariantInterpretation]</code> <p>A Variant obeserved in this individual</p> required <code>acmg</code> <code>str</code> <p>One of the five ACMG pathogenicity categories</p> <code>None</code> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def add_variant(self, v: Union[Variant, PPKt.VariantInterpretation], acmg: str = None):\n    \"\"\"\n    :param v: A Variant obeserved in this individual\n    :type v: Union[Variant, PPKt.VariantInterpretation]\n    :param acmg: One of the five ACMG pathogenicity categories\n    :type acmg: str\n    \"\"\"\n    if isinstance(v, Variant):\n        variant = v.to_ga4gh_variant_interpretation(acmg=acmg)\n    else:\n        variant = v\n    if isinstance(variant, PPKt.VariantInterpretation):\n        self._interpretation_list.append(variant)\n    else:\n        raise ValueError(\n            f\"variant argument must be pyphetools Variant or GA4GH VariantInterpretation but was {type(variant)}\")\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.from_ga4gh_phenopacket","title":"<code>from_ga4gh_phenopacket(ppkt)</code>  <code>staticmethod</code>","text":"<p>Transform a GA4GH Phenopacket into an Individual object -- useful for testing</p> <p>Returns:</p> Type Description <code>Individual</code> <p>an individual object corresponding to the GA4GH Phenopacket</p> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>@staticmethod\ndef from_ga4gh_phenopacket(ppkt: PPKt.Phenopacket):\n    \"\"\"\n    Transform a GA4GH Phenopacket into an Individual object -- useful for testing\n    :returns:  an individual object corresponding to the GA4GH Phenopacket\n    :rtype: Individual\n    \"\"\"\n    if not isinstance(ppkt, PPKt.Phenopacket):\n        raise ValueError(f\"argument must be a GA4GH Phenopacket Message but was {type(ppkt)}\")\n    #metadata = ppkt.meta_data\n    #pypt_metadata = Individual.from_ga4gh_metadata(mdata=metadata)\n    subject_id = ppkt.subject.id\n    sex = ppkt.subject.sex\n    age_at_last_encounter = ppkt.subject.time_at_last_encounter.age.iso8601duration\n    age_of_onset = None\n    if len(ppkt.diseases) &gt; 0:\n        d = ppkt.diseases[0]\n        if d.HasField(\"onset\") and d.onset.HasField(\"age\"):\n            age_of_onset = TimeElement202.from_message(d.onset.age)\n    hpo_terms = []\n    for pf in ppkt.phenotypic_features:\n        hpo_id = pf.type.id\n        hpo_label = pf.type.label\n        observed = not pf.excluded\n        onset_age = None\n        if pf.HasField(\"onset\"):\n            onset_age = TimeElement202.from_message(pf.onset)\n        hpo_terms.append(HpTerm(hpo_id=hpo_id, label=hpo_label, observed=observed, onset=onset_age))\n    disease, var_list = Individual.get_variants_and_disease(ppkt)\n    indi = Individual(individual_id=subject_id,\n                      hpo_terms=hpo_terms,\n                      citation=None,\n                      sex=sex,\n                      age_of_onset=age_of_onset,\n                      age_at_last_encounter=age_at_last_encounter,\n                      interpretation_list=var_list)\n    if disease is not None:\n        indi.set_disease(disease=disease)\n    return indi\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.get_citation","title":"<code>get_citation()</code>","text":"<p>Returns:</p> Type Description <code>Citation</code> <p>a Citation object with PMID and article title</p> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def get_citation(self) -&gt; Citation:\n    \"\"\"\n    :returns: a Citation object with PMID and article title\n    :rtype: Citation\n    \"\"\"\n    return self._citation\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.get_phenopacket_id","title":"<code>get_phenopacket_id(phenopacket_id=None)</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>the Phenopacket identifier for this individual</p> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def get_phenopacket_id(self, phenopacket_id=None) -&gt; str:\n    \"\"\"\n    :returns: the Phenopacket identifier for this individual\n    :rtype: str\n    \"\"\"\n    if phenopacket_id is None:\n        indi_id = self._individual_id.replace(\" \", \"_\")\n        if self._citation is not None:\n            pmid = self._citation.pmid.replace(\":\", \"_\")\n            ppkt_id = f\"{pmid}_{indi_id}\"\n        else:\n            ppkt_id = indi_id\n    else:\n        ppkt_id = phenopacket_id\n    # strip non alphanumeric characters\n    ppkt_id = ''.join(e if e.isalnum() else \"_\" for e in ppkt_id)\n    ppkt_id = ppkt_id.replace(\"__\", \"_\")\n    if ppkt_id.endswith(\"_\"):\n        ppkt_id = ppkt_id[:-1]\n    return ppkt_id\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.get_variants_and_disease","title":"<code>get_variants_and_disease(ppkt)</code>  <code>staticmethod</code>","text":"<p>extract the pyphetools Disease object and the VariantInterpretation objects that can be used to construct an Individual</p> <p>Parameters:</p> Name Type Description Default <code>ppkt</code> <code>Phenopacket</code> <p>a GA4GH phenopacket</p> required <p>Returns:</p> Type Description <code>Individual, List[PPKt.VariantInterpretation]</code> <p>tjhe corresponding Individual object</p> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>@staticmethod\ndef get_variants_and_disease(ppkt: PPKt.Phenopacket):\n    \"\"\"extract the pyphetools Disease object and the VariantInterpretation objects that can be used to construct an Individual\n\n    :param ppkt: a GA4GH phenopacket\n    :type ppkt: PPKT.Phenopacket\n    :returns: tjhe corresponding Individual object\n    :rtype: Individual, List[PPKt.VariantInterpretation]\n    \"\"\"\n    if len(ppkt.interpretations) == 0:\n        print(f\"No interpretation found for {ppkt.id}\")\n        return None, []\n    if len(ppkt.interpretations) &gt; 1:\n        raise ValueError(\n            f\"pyphetools dpoes not currently support multiple Interpretation messages in one phenopacket but we found {len(ppkt.interpretations)}\")\n    interpretation = ppkt.interpretations[0]\n    if interpretation.HasField(\"diagnosis\") and interpretation.diagnosis.HasField(\"disease\"):\n        d = interpretation.diagnosis.disease\n        disease = Disease(disease_id=d.id, disease_label=d.label)\n    else:\n        disease = None\n    if len(interpretation.diagnosis.genomic_interpretations) == 0:\n        return disease, []\n    else:\n        variant_list = []\n        for gen_interpretation in interpretation.diagnosis.genomic_interpretations:\n            variant_list.append(gen_interpretation.variant_interpretation)\n        return disease, variant_list\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.output_individuals_as_phenopackets","title":"<code>output_individuals_as_phenopackets(individual_list, metadata, outdir='phenopackets')</code>  <code>staticmethod</code>","text":"<p>write a list of Individual objects to file in GA4GH Phenopacket format</p> <p>This methods depends on the MetaData object having a PMID and will fail otherwise</p> <p>Parameters:</p> Name Type Description Default <code>individual_list</code> <code>List[Individual]</code> <p>List of individuals to be written to file as phenopackets</p> required <code>metadata</code> <code>MetaData</code> <p>pyphetools MetaData object</p> required <code>outdir</code> <code>str</code> <p>Path to output directory. Defaults to \"phenopackets\". Created if not exists.</p> <code>'phenopackets'</code> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>@staticmethod\ndef output_individuals_as_phenopackets(individual_list, metadata: MetaData, outdir=\"phenopackets\"):\n    \"\"\"write a list of Individual objects to file in GA4GH Phenopacket format\n\n    This methods depends on the MetaData object having a PMID and will fail otherwise\n\n    :param individual_list: List of individuals to be written to file as phenopackets\n    :type individual_list: List[Individual]\n    :param metadata: pyphetools MetaData object\n    :type metadata: MetaData\n    :param outdir: Path to output directory. Defaults to \"phenopackets\". Created if not exists.\n    :type outdir: str\n    \"\"\"\n    if os.path.isfile(outdir):\n        raise ValueError(f\"Attempt to create directory with name of existing file {outdir}\")\n    if not os.path.isdir(outdir):\n        os.makedirs(outdir)\n    written = 0\n    if not isinstance(metadata, MetaData):\n        raise ValueError(\n            f\"metadata argument must be pyphetools MetaData object (not GA4GH metadata message), but was {type(metadata)}\")\n    pmid = metadata.get_pmid()\n    for individual in individual_list:\n        phenopckt = individual.to_ga4gh_phenopacket(metadata=metadata)\n        json_string = MessageToJson(phenopckt)\n        if pmid is None:\n            fname = \"phenopacket_\" + individual.id\n        else:\n            pmid = pmid.replace(\" \", \"\").replace(\":\", \"_\")\n            fname = pmid + \"_\" + individual.id\n        fname = re.sub('[^A-Za-z0-9_-]', '', fname)  # remove any illegal characters from filename\n        fname = fname.replace(\" \", \"_\") + \".json\"\n        outpth = os.path.join(outdir, fname)\n        with open(outpth, \"wt\") as fh:\n            fh.write(json_string)\n            written += 1\n    print(f\"We output {written} GA4GH phenopackets to the directory {outdir}\")\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.set_citation","title":"<code>set_citation(citation)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>citation</code> <code>Citation</code> <p>Object with the title and PubMed identifier for the publication in which this individual was described (e.g. PMID:321..)</p> required Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def set_citation(self, citation: Citation) -&gt; None:\n    \"\"\"\n    :param citation: Object with the title and PubMed identifier for the publication in which this individual was described (e.g. PMID:321..)\n    :type citation: Citation\n    \"\"\"\n    self._citation = citation\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.set_disease","title":"<code>set_disease(disease)</code>","text":"<p>This method is typically useful for a cohort with multiple diagnoses; otherwise, the disease can be set by the CohortEncoder</p> <p>Parameters:</p> Name Type Description Default <code>disease</code> <code>Disease</code> <p>the disease diagnosis for this individual</p> required Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def set_disease(self, disease: Disease) -&gt; None:\n    \"\"\"\n    This method is typically useful for a cohort with multiple diagnoses; otherwise, the disease can be set by the\n    CohortEncoder\n\n    :param disease: the disease diagnosis for this individual\n    :type disease: Disease\n    \"\"\"\n    self._disease = disease\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.set_hpo_terms","title":"<code>set_hpo_terms(cleansed_hpo_terms)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>cleansed_hpo_terms</code> <code>List[HpTerm]</code> <p>a list of HpTerm objects that has been cleansed by OntologyQC</p> required Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def set_hpo_terms(self, cleansed_hpo_terms: List[HpTerm]) -&gt; None:\n    \"\"\"\n    :param cleansed_hpo_terms: a list of HpTerm objects that has been cleansed by OntologyQC\n    :type cleansed_hpo_terms: List[pyphetools.creation.HpTerm]\n    \"\"\"\n    self._hpo_terms = cleansed_hpo_terms\n</code></pre>"},{"location":"api/creation/individual/#pyphetools.creation.Individual.to_ga4gh_phenopacket","title":"<code>to_ga4gh_phenopacket(metadata, phenopacket_id=None)</code>","text":"<p>Transform the data into GA4GH Phenopacket format</p> <p>Returns:</p> Type Description <code>PPKt.Phenopacket</code> <p>a GA4GH Phenopacket representing this individual</p> Source code in <code>pyphetools/creation/individual.py</code> <pre><code>def to_ga4gh_phenopacket(self, metadata, phenopacket_id=None) -&gt; PPKt.Phenopacket:\n    \"\"\"\n    Transform the data into GA4GH Phenopacket format\n    :returns:  a GA4GH Phenopacket representing this individual\n    :rtype: PPKt.Phenopacket\n    \"\"\"\n    if isinstance(metadata, MetaData):\n        metadata = metadata.to_ga4gh()\n    if not isinstance(metadata, PPKt.MetaData):\n        raise ValueError(\n            f\"metadata argument must be pyphetools.MetaData or GA4GH MetaData but was {type(metadata)}\")\n    php = PPKt.Phenopacket()\n    php.id = self.get_phenopacket_id(phenopacket_id=phenopacket_id)\n    php.subject.id = self._individual_id\n    if self._age_at_last_encounter is not None:\n        php.subject.time_at_last_encounter.CopyFrom(self._age_at_last_encounter.to_message())\n    if self._sex == Constants.MALE_SYMBOL:\n        php.subject.sex = PPKt.Sex.MALE\n    elif self._sex == Constants.FEMALE_SYMBOL:\n        php.subject.sex = PPKt.Sex.FEMALE\n    elif self._sex == Constants.OTHER_SEX_SYMBOL:\n        php.subject.sex = PPKt.Sex.OTHER_SEX\n    elif self._sex == Constants.UNKNOWN_SEX_SYMBOL:\n        php.subject.sex = PPKt.Sex.UNKNOWN_SEX\n    if self._vital_status is not None:\n        vs = self._vital_status.to_message()\n        php.subject.vital_status.CopyFrom(vs)\n    disease_object = self._get_disease_object()\n    php.diseases.append(disease_object)\n    if isinstance(self._hpo_terms, list):\n        for hp in self._hpo_terms:\n            if not hp.measured:\n                continue\n            pf = hp.to_ga4gh_phenotypic_feature()\n            if pf.onset.age.iso8601duration is None and self._age_of_onset != Constants.NOT_PROVIDED:\n                pf.onset.age.iso8601duration = self._age_of_onset\n            php.phenotypic_features.append(pf)\n    elif isinstance(self._hpo_terms, dict):\n        for age_key, hpoterm_list in self._hpo_terms.items():\n            for hp in hpoterm_list:\n                if not hp.measured:\n                    continue\n                pf = hp.to_phenotypic_feature()\n                # only adjust age of onset if not present\n                if pf.onset.age.iso8601duration is None and age_key.startswith(\"P\"):\n                    pf.onset.age.iso8601duration = age_key\n                php.phenotypic_features.append(pf)\n    if len(self._interpretation_list) &gt; 0:\n        interpretation = PPKt.Interpretation()\n        interpretation.id = self._individual_id\n        interpretation.progress_status = PPKt.Interpretation.ProgressStatus.SOLVED\n        if self._disease is not None:\n            interpretation.diagnosis.disease.id = self._disease.id\n            interpretation.diagnosis.disease.label = self._disease.label\n        for var in self._interpretation_list:\n            genomic_interpretation = PPKt.GenomicInterpretation()\n            genomic_interpretation.subject_or_biosample_id = self._individual_id\n            # by assumption, variants passed to this package are all causative\n            genomic_interpretation.interpretation_status = PPKt.GenomicInterpretation.InterpretationStatus.CAUSATIVE\n            genomic_interpretation.variant_interpretation.CopyFrom(var)\n            interpretation.diagnosis.genomic_interpretations.append(genomic_interpretation)\n        php.interpretations.append(interpretation)\n    if self._citation is not None:\n        # overrides the \"general\" setting of the external reference for the entire cohort\n        while len(metadata.external_references) &gt; 0:\n            # `protobuf` devs must have removed `clear()` method\n            # This is a workaround to clear the list of external references.\n            _ = metadata.external_references.pop()\n        extref202 = self._citation.to_external_reference()\n        metadata.external_references.append(extref202.to_message())\n    php.meta_data.CopyFrom(metadata)\n    return php\n</code></pre>"},{"location":"api/creation/metadata/","title":"MetaData","text":"<p>A representation of the MetaData element of the GA4GH Phenopacket Schema</p> <p>Parameters:</p> Name Type Description Default <code>created_by</code> <code>str</code> <p>identifier (such as ORCID id) of the person who created this Phenopacket</p> required <code>citation</code> <code>Citation</code> <p>PubMed identifier of the article from which the data for the phenopacket was taken, optional</p> <code>None</code> Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>class MetaData:\n    \"\"\"\n    A representation of the MetaData element of the GA4GH Phenopacket Schema\n\n    :param created_by: identifier (such as ORCID id) of the person who created this Phenopacket\n    :type created_by: str\n    :param citation: PubMed identifier of the article from which the data for the phenopacket was taken, optional\n    :type citation: Citation\n    \"\"\"\n\n    def __init__(self, created_by, citation:Citation=None) -&gt; None:\n        \"\"\"\n        Constructor\n        \"\"\"\n        self._created_by = created_by\n        self._schema_version = \"2.0\"\n        self._extref = None\n        if citation is not None:\n            self.set_external_reference(pmid=citation.pmid, pubmed_title=citation.title)\n        self._citation = citation\n        self._resource_d = defaultdict(Resource)\n\n    def default_versions_with_hpo(self, version):\n        \"\"\"\n        Add resources for HPO (with specified version), GENO, HGNC, and OMIM (with default versions)\n        The HPO version can be easily obtained from the HpoParser using the get_version() function\n\n        :param version: version of the Human Phenotype Ontology (HPO) used to create this phenopacket\n        :type version: str\n        :param pmid: PubMed identifier of the article from which the data for the phenopacket was taken, optional\n        :type pmid: str\n        :param pubmed_title: title of the article (if any), for use in the Resource section\n        :type pubmed_title: str\n        \"\"\"\n        self.geno()\n        self.hgnc()\n        self.omim()\n        self.sequence_ontology()\n        self.hpo(version=version)\n\n    def hpo(self, version):\n        \"\"\"\n        :param version: version of the Human Phenotype Ontology (HPO) used to create this phenopacket\n        :type version: str\n        \"\"\"\n        self._resource_d[\"hp\"] = Resource(resource_id=\"hp\",\n                                        name=\"human phenotype ontology\",\n                                        namespace_prefix=\"HP\",\n                                        iriprefix=\"http://purl.obolibrary.org/obo/HP_\",\n                                        url=\"http://purl.obolibrary.org/obo/hp.owl\",\n                                        version=version)\n\n    def geno(self, version=default_versions.get('geno')):\n        \"\"\"_summary_\n        GENO is used for three terms: homozygous, heterozygous, hemizygous\n        For this reason, we use a default version, since we assume these terms will not change.\n        Args:\n            version (str, optional): GENO version. Defaults to \"2022-03-05\".\n\n        Returns:\n            _type_: Resource object representing GENO\n        \"\"\"\n        self._resource_d[\"geno\"] = Resource(resource_id=\"geno\",\n                                            name=\"Genotype Ontology\",\n                                            namespace_prefix=\"GENO\",\n                                            iriprefix=\"http://purl.obolibrary.org/obo/GENO_\",\n                                            url=\"http://purl.obolibrary.org/obo/geno.owl\",\n                                            version=version)\n\n    def hgnc(self, version=default_versions.get('hgnc')):\n        self._resource_d[\"hgnc\"] = Resource(resource_id=\"hgnc\",\n                                            name=\"HUGO Gene Nomenclature Committee\",\n                                            namespace_prefix=\"HGNC\",\n                                            iriprefix=\"https://www.genenames.org/data/gene-symbol-report/#!/hgnc_id/\",\n                                            url=\"https://www.genenames.org\",\n                                            version=version)\n\n    def omim(self, version=default_versions.get('omim')):\n        self._resource_d[\"omim\"] = Resource(resource_id=\"omim\",\n                                            name=\"An Online Catalog of Human Genes and Genetic Disorders\",\n                                            namespace_prefix=\"OMIM\",\n                                            iriprefix=\"https://www.omim.org/entry/\",\n                                            url=\"https://www.omim.org\",\n                                            version=version)\n\n    def mondo(self, version=default_versions.get('mondo')):\n        \"\"\"\n        Add a resource for Mondo to the current MetaData object\n        :param version: the Mondo version\n        \"\"\"\n        self._resource_d[\"mondo\"] = Resource(resource_id=\"mondo\",\n                                            name=\"Mondo Disease Ontology\",\n                                            namespace_prefix=\"MONDO\",\n                                            iriprefix=\"http://purl.obolibrary.org/obo/MONDO_\",\n                                            url=\"http://purl.obolibrary.org/obo/mondo.obo\",\n                                            version=version)\n\n    def sequence_ontology(self, version=default_versions.get(\"so\")) -&gt; Resource:\n        self._resource_d[\"so\"] = Resource(resource_id=\"so\",\n                                            name=\"Sequence types and features ontology\",\n                                            namespace_prefix=\"SO\",\n                                            iriprefix=\"http://purl.obolibrary.org/obo/SO_\",\n                                            url=\"http://purl.obolibrary.org/obo/so.obo\",\n                                            version=version)\n\n    def add_reference(self, resource:Resource) -&gt; None:\n        resource_id = resource.id\n        self._resource_d[resource_id] = resource\n\n    def set_external_reference(self, pmid, pubmed_title) -&gt; None:\n        \"\"\"\n        Set the external reference for this phenopacket/individual to be the PubMed identifier and title of an article\n\n        :param pmid: The PubMed identifier of the publication from which the data was derived\n        :type pmid: str\n        :param pubmed_title: The title of the publication\n        :type pubmed_title: str\n        \"\"\"\n        self._extref = PPKt.ExternalReference()\n        self._extref.id = pmid\n        pm = pmid.replace(\"PMID:\", \"\")\n        self._extref.reference = f\"https://pubmed.ncbi.nlm.nih.gov/{pm}\"\n        self._extref.description = pubmed_title\n\n    def get_citation(self):\n        return self._citation\n\n    def get_pmid(self)-&gt;str:\n        \"\"\"\n        :returns: The PubMed identifier\n        :rtype: str:\n        :raises ValueError: Throw an error if no PMID is available\n        \"\"\"\n        if self._extref is not None:\n            if self._extref.id.startswith(\"PMID\"):\n                return self._extref.id\n            else:\n                raise ValueError(f\"Malformed PMID in external reference: {self._extref.id}\")\n        else:\n            raise ValueError(\"Could not get PMID because MetaData._extref was None\")\n\n    def get_created_by(self) -&gt; str:\n        return self._created_by\n\n\n    def to_ga4gh(self):\n        \"\"\"\n        Use a time stamp for the current instant\n        :returns: A MetaData formated as a GA4GH Phenopacket Schema message\n        :rtype: PPkt.MetaData\n        \"\"\"\n        metadata = PPKt.MetaData()\n        metadata.created_by = self._created_by\n        now = time.time()\n        seconds = int(now)\n        nanos = int((now - seconds) * 10 ** 9)\n        timestamp = protobuf.timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n        metadata.created.CopyFrom(timestamp)\n        metadata.phenopacket_schema_version = self._schema_version\n        for _, resource in self._resource_d.items():\n            res = PPKt.Resource()\n            res.id = resource.id\n            res.name = resource.name\n            res.namespace_prefix = resource.namespace_prefix\n            res.iri_prefix = resource.iri_prefix\n            res.url = resource.url\n            res.version = resource.version\n            metadata.resources.append(res)\n        if self._extref is not None:\n            metadata.external_references.append(self._extref)\n        return metadata\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.__init__","title":"<code>__init__(created_by, citation=None)</code>","text":"<p>Constructor</p> Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def __init__(self, created_by, citation:Citation=None) -&gt; None:\n    \"\"\"\n    Constructor\n    \"\"\"\n    self._created_by = created_by\n    self._schema_version = \"2.0\"\n    self._extref = None\n    if citation is not None:\n        self.set_external_reference(pmid=citation.pmid, pubmed_title=citation.title)\n    self._citation = citation\n    self._resource_d = defaultdict(Resource)\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.default_versions_with_hpo","title":"<code>default_versions_with_hpo(version)</code>","text":"<p>Add resources for HPO (with specified version), GENO, HGNC, and OMIM (with default versions) The HPO version can be easily obtained from the HpoParser using the get_version() function</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <code>str</code> <p>version of the Human Phenotype Ontology (HPO) used to create this phenopacket</p> required <code>pmid</code> <code>str</code> <p>PubMed identifier of the article from which the data for the phenopacket was taken, optional</p> required <code>pubmed_title</code> <code>str</code> <p>title of the article (if any), for use in the Resource section</p> required Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def default_versions_with_hpo(self, version):\n    \"\"\"\n    Add resources for HPO (with specified version), GENO, HGNC, and OMIM (with default versions)\n    The HPO version can be easily obtained from the HpoParser using the get_version() function\n\n    :param version: version of the Human Phenotype Ontology (HPO) used to create this phenopacket\n    :type version: str\n    :param pmid: PubMed identifier of the article from which the data for the phenopacket was taken, optional\n    :type pmid: str\n    :param pubmed_title: title of the article (if any), for use in the Resource section\n    :type pubmed_title: str\n    \"\"\"\n    self.geno()\n    self.hgnc()\n    self.omim()\n    self.sequence_ontology()\n    self.hpo(version=version)\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.geno","title":"<code>geno(version=default_versions.get('geno'))</code>","text":"<p>summary GENO is used for three terms: homozygous, heterozygous, hemizygous For this reason, we use a default version, since we assume these terms will not change. Args:     version (str, optional): GENO version. Defaults to \"2022-03-05\".</p> <p>Returns:     type: Resource object representing GENO</p> Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def geno(self, version=default_versions.get('geno')):\n    \"\"\"_summary_\n    GENO is used for three terms: homozygous, heterozygous, hemizygous\n    For this reason, we use a default version, since we assume these terms will not change.\n    Args:\n        version (str, optional): GENO version. Defaults to \"2022-03-05\".\n\n    Returns:\n        _type_: Resource object representing GENO\n    \"\"\"\n    self._resource_d[\"geno\"] = Resource(resource_id=\"geno\",\n                                        name=\"Genotype Ontology\",\n                                        namespace_prefix=\"GENO\",\n                                        iriprefix=\"http://purl.obolibrary.org/obo/GENO_\",\n                                        url=\"http://purl.obolibrary.org/obo/geno.owl\",\n                                        version=version)\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.get_pmid","title":"<code>get_pmid()</code>","text":"<p>Returns:</p> Type Description <code>str:</code> <p>The PubMed identifier</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>Throw an error if no PMID is available</p> Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def get_pmid(self)-&gt;str:\n    \"\"\"\n    :returns: The PubMed identifier\n    :rtype: str:\n    :raises ValueError: Throw an error if no PMID is available\n    \"\"\"\n    if self._extref is not None:\n        if self._extref.id.startswith(\"PMID\"):\n            return self._extref.id\n        else:\n            raise ValueError(f\"Malformed PMID in external reference: {self._extref.id}\")\n    else:\n        raise ValueError(\"Could not get PMID because MetaData._extref was None\")\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.hpo","title":"<code>hpo(version)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>version</code> <code>str</code> <p>version of the Human Phenotype Ontology (HPO) used to create this phenopacket</p> required Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def hpo(self, version):\n    \"\"\"\n    :param version: version of the Human Phenotype Ontology (HPO) used to create this phenopacket\n    :type version: str\n    \"\"\"\n    self._resource_d[\"hp\"] = Resource(resource_id=\"hp\",\n                                    name=\"human phenotype ontology\",\n                                    namespace_prefix=\"HP\",\n                                    iriprefix=\"http://purl.obolibrary.org/obo/HP_\",\n                                    url=\"http://purl.obolibrary.org/obo/hp.owl\",\n                                    version=version)\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.mondo","title":"<code>mondo(version=default_versions.get('mondo'))</code>","text":"<p>Add a resource for Mondo to the current MetaData object</p> <p>Parameters:</p> Name Type Description Default <code>version</code> <p>the Mondo version</p> <code>get('mondo')</code> Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def mondo(self, version=default_versions.get('mondo')):\n    \"\"\"\n    Add a resource for Mondo to the current MetaData object\n    :param version: the Mondo version\n    \"\"\"\n    self._resource_d[\"mondo\"] = Resource(resource_id=\"mondo\",\n                                        name=\"Mondo Disease Ontology\",\n                                        namespace_prefix=\"MONDO\",\n                                        iriprefix=\"http://purl.obolibrary.org/obo/MONDO_\",\n                                        url=\"http://purl.obolibrary.org/obo/mondo.obo\",\n                                        version=version)\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.set_external_reference","title":"<code>set_external_reference(pmid, pubmed_title)</code>","text":"<p>Set the external reference for this phenopacket/individual to be the PubMed identifier and title of an article</p> <p>Parameters:</p> Name Type Description Default <code>pmid</code> <code>str</code> <p>The PubMed identifier of the publication from which the data was derived</p> required <code>pubmed_title</code> <code>str</code> <p>The title of the publication</p> required Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def set_external_reference(self, pmid, pubmed_title) -&gt; None:\n    \"\"\"\n    Set the external reference for this phenopacket/individual to be the PubMed identifier and title of an article\n\n    :param pmid: The PubMed identifier of the publication from which the data was derived\n    :type pmid: str\n    :param pubmed_title: The title of the publication\n    :type pubmed_title: str\n    \"\"\"\n    self._extref = PPKt.ExternalReference()\n    self._extref.id = pmid\n    pm = pmid.replace(\"PMID:\", \"\")\n    self._extref.reference = f\"https://pubmed.ncbi.nlm.nih.gov/{pm}\"\n    self._extref.description = pubmed_title\n</code></pre>"},{"location":"api/creation/metadata/#pyphetools.creation.MetaData.to_ga4gh","title":"<code>to_ga4gh()</code>","text":"<p>Use a time stamp for the current instant</p> <p>Returns:</p> Type Description <code>PPkt.MetaData</code> <p>A MetaData formated as a GA4GH Phenopacket Schema message</p> Source code in <code>pyphetools/creation/metadata.py</code> <pre><code>def to_ga4gh(self):\n    \"\"\"\n    Use a time stamp for the current instant\n    :returns: A MetaData formated as a GA4GH Phenopacket Schema message\n    :rtype: PPkt.MetaData\n    \"\"\"\n    metadata = PPKt.MetaData()\n    metadata.created_by = self._created_by\n    now = time.time()\n    seconds = int(now)\n    nanos = int((now - seconds) * 10 ** 9)\n    timestamp = protobuf.timestamp_pb2.Timestamp(seconds=seconds, nanos=nanos)\n    metadata.created.CopyFrom(timestamp)\n    metadata.phenopacket_schema_version = self._schema_version\n    for _, resource in self._resource_d.items():\n        res = PPKt.Resource()\n        res.id = resource.id\n        res.name = resource.name\n        res.namespace_prefix = resource.namespace_prefix\n        res.iri_prefix = resource.iri_prefix\n        res.url = resource.url\n        res.version = resource.version\n        metadata.resources.append(res)\n    if self._extref is not None:\n        metadata.external_references.append(self._extref)\n    return metadata\n</code></pre>"},{"location":"api/creation/structural_variant/","title":"StructuralVariant","text":"<p>               Bases: <code>Variant</code></p> <p>This encapsulates variant about a structural variant For instance, we may see things like this chr7.hg19:g.(35674000_37280000)_(46_111_000_46_598_000)del (fuzzy boundaries) chr7.hg19:g(38521704_45810267)del (precise boundaries) rsa7p14.1(kit P179)x1 46,XY.ish del(7)(p14.1)(RP11-816F16-) 46,XX.ish del(7)(p14.1p14.1)(GLI3-) 46,XY.ish del(7)(p14.1)(GLI3-)[56]/7p14.1(GLI3x2)[44] (various ICSN or bespoke) Our strategy is not to model these variants precisely. Instead, for genotype-phenotype analysis, it may be enough to know that these are structural variants and thus likely to be complete loss of function. So we record something about the variant and add it by hand to the Individual object We want to be able to create a GA4GH VariationDescriptor object with the following fields - id - required, autogenerate if user provides no id - variant (VRS) -- leave this field empty - label -- the original contents of the cell, e.g., 46,XY.ish del(7)(p14.1)(RP11-816F16-) - gene context -- the gene that is disrupted by the structural variant - expressions, empty - vcf_record, empty - structural type: Ontology Class - allelic state: het/hom/emi etc.</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>the string from the original table that we want to map as a structural variant</p> required <code>gene_symbol</code> <code>str</code> <p>the gene affected by the structural variant, e.g., GLI3</p> required <code>gene_id</code> <code>str</code> <p>the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319</p> required <code>sequence_ontology_id</code> <code>str</code> <p>An identifier from the Sequence Ontology</p> required <code>sequence_ontology_label</code> <code>str</code> <p>the SO label corresponding to the ID</p> required <code>variant_id</code> <code>None</code> <p>an identifier for the variant, optional</p> required Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>class StructuralVariant(Variant):\n    \"\"\"\n    This encapsulates variant about a structural variant\n    For instance, we may see things like this\n    chr7.hg19:g.(35674000_37280000)_(46_111_000_46_598_000)del (fuzzy boundaries)\n    chr7.hg19:g(38521704_45810267)del (precise boundaries)\n    rsa7p14.1(kit P179)x1\n    46,XY.ish del(7)(p14.1)(RP11-816F16-)\n    46,XX.ish del(7)(p14.1p14.1)(GLI3-)\n    46,XY.ish del(7)(p14.1)(GLI3-)[56]/7p14.1(GLI3x2)[44] (various ICSN or bespoke)\n    Our strategy is not to model these variants precisely. Instead, for genotype-phenotype\n    analysis, it may be enough to know that these are structural variants and thus\n    likely to be complete loss of function.\n    So we record something about the variant and add it by hand to the Individual object\n    We want to be able to create a GA4GH VariationDescriptor object with the following fields\n    - id - required, autogenerate if user provides no id\n    - variant (VRS) -- leave this field empty\n    - label -- the original contents of the cell, e.g., 46,XY.ish del(7)(p14.1)(RP11-816F16-)\n    - gene context -- the gene that is disrupted by the structural variant\n    - expressions, empty\n    - vcf_record, empty\n    - structural type: Ontology Class\n    - allelic state: het/hom/emi etc.\n\n    :param cell_contents: the string from the original table that we want to map as a structural variant\n    :type cell_contents: str\n    :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n    :type gene_symbol: str\n    :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n    :type gene_id: str\n    :param sequence_ontology_id: An identifier from the Sequence Ontology\n    :type sequence_ontology_id: str\n    :param sequence_ontology_label: the SO label corresponding to the ID\n    :type sequence_ontology_label: str\n    :param variant_id: an identifier for the variant, optional\n    :type variant_id: str\n    \"\"\"\n\n    def __init__(self, cell_contents,\n                 gene_symbol,\n                 gene_id,\n                 sequence_ontology_id,\n                 sequence_ontology_label,\n                 variant_id: None):\n        super().__init__()\n        if variant_id is None:\n            self._variant_id = \"var_\" + \"\".join(random.choices(string.ascii_letters, k=25))\n        else:\n            self._variant_id = variant_id\n        self._label = cell_contents.strip()\n        if gene_symbol is None:\n            raise ValueError(f\"Need to pass a valid gene symbol!\")\n        self._gene_symbol = gene_symbol\n        if gene_id is None:\n            raise ValueError(f\"Need to pass a valid HGNC gene id!\")\n        self._hgnc_id = gene_id\n        self._so_id = sequence_ontology_id\n        self._so_label = sequence_ontology_label\n        self._genotype = None\n\n    def to_ga4gh_variant_interpretation(self, acmg=None):\n        \"\"\"\n        Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n        \"\"\"\n        vdescriptor = phenopackets.VariationDescriptor()\n        vdescriptor.id = self._variant_id\n        vdescriptor.gene_context.value_id = self._hgnc_id\n        vdescriptor.gene_context.symbol = self._gene_symbol\n        vdescriptor.label = self._label\n        vdescriptor.molecule_context = phenopackets.MoleculeContext.genomic\n        if self._genotype is not None:\n            if self._genotype == 'heterozygous':\n                vdescriptor.allelic_state.id = \"GENO:0000135\"\n                vdescriptor.allelic_state.label = \"heterozygous\"\n            elif self._genotype == 'homozygous':\n                vdescriptor.allelic_state.id = \"GENO:0000136\"\n                vdescriptor.allelic_state.label = \"homozygous\"\n            elif self._genotype == 'hemizygous':\n                vdescriptor.allelic_state.id = \"GENO:0000134\"\n                vdescriptor.allelic_state.label = \"hemizygous\"\n            else:\n                print(f\"Did not recognize genotype {self._genotype}\")\n        vdescriptor.structural_type.id = self._so_id\n        vdescriptor.structural_type.label = self._so_label\n        vinterpretation = phenopackets.VariantInterpretation()\n        if acmg is not None:\n            if acmg.lower() == 'benign':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.BENIGN\n            elif acmg.lower == 'likely benign' or acmg.lower() == 'likely_benign':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_BENIGN\n            elif acmg.lower == 'uncertain significance' or acmg.lower() == 'uncertain_significance':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.UNCERTAIN_SIGNIFICANCE\n            elif acmg.lower == 'likely pathogenic' or acmg.lower() == 'likely_pathogenic':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_PATHOGENIC\n            elif acmg.lower == 'pathogenic' or acmg.lower() == 'pathogenic':\n                vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.PATHOGENIC\n            else:\n                print(f\"Warning- did not recognize ACMG category {acmg}\")\n        vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n        return vinterpretation\n\n    def to_variant_interpretation_202(self, acmg=None):\n        \"\"\"\n        Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n        \"\"\"\n        from ..pp.v202 import VariantInterpretation as VariantInterpretation202\n        from ..pp.v202 import VariationDescriptor as VariationDescriptor202\n        from ..pp.v202 import GeneDescriptor as GeneDescriptor202\n        from ..pp.v202 import OntologyClass as OntologyClass202\n        from ..pp.v202 import MoleculeContext as MoleculeContext202\n\n        gdesc = GeneDescriptor202(value_id=self._hgnc_id, symbol=self._gene_symbol)\n        vdescriptor = VariationDescriptor202(id=self._variant_id,\n                                             gene_context=gdesc,\n                                             label=self._label,\n                                             molecule_context=MoleculeContext202.genomic)\n        # Note that it is possible to first create a StructuralVariant object and later set its genotype\n        # Therefore, it is not an error if gt_term is None\n        gt_term = Variant._get_genotype_term(self._genotype)\n        if gt_term is not None:\n            vdescriptor.allelic_state = gt_term\n        structural_type = OntologyClass202(id=self._so_id, label=self._so_label)\n        vdescriptor.structural_type = structural_type\n        vinterpretation = VariantInterpretation202(variation_descriptor=vdescriptor)\n        acmg_code = Variant._get_acmg_classification(acmg=acmg)\n        if acmg_code is not None:\n            vinterpretation.acmgPathogenicityClassification = acmg_code\n        else:\n            print(f\"Warning- did not recognize ACMG category \\\"{acmg}\\\"\")\n        return vinterpretation\n\n    # provide static constructors for most important structural variation types\n\n    @staticmethod\n    def chromosomal_deletion(cell_contents,\n                             gene_symbol,\n                             gene_id,\n                             variant_id=None):\n        \"\"\"\n        create a StructuralVariant object for a chromosomal deletion\n\n        :param cell_contents: the string from the original table that we want to map as a structural variant\n        :type cell_contents: str\n        :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n        :type gene_symbol: str\n        :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n        :type gene_id: str\n        :param variant_id: an identifier for the variant\n        :type variant_id: str, optional\n        \"\"\"\n        return StructuralVariant(cell_contents=cell_contents,\n                                 gene_symbol=gene_symbol,\n                                 gene_id=gene_id,\n                                 sequence_ontology_id=\"SO:1000029\",\n                                 sequence_ontology_label=\"chromosomal_deletion\",\n                                 variant_id=variant_id)\n\n    @staticmethod\n    def chromosomal_duplication(cell_contents,\n                                gene_symbol,\n                                gene_id,\n                                variant_id=None):\n        \"\"\"\n        create a StructuralVariant object for a chromosomal duplication\n\n        :param cell_contents: the string from the original table that we want to map as a structural variant\n        :type cell_contents: str\n        :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n        :type gene_symbol: str\n        :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n        :type gene_id: str\n        :param variant_id: an identifier for the variant\n        :type variant_id: str, optional\n        \"\"\"\n        return StructuralVariant(cell_contents=cell_contents,\n                                 gene_symbol=gene_symbol,\n                                 gene_id=gene_id,\n                                 sequence_ontology_id=\"SO:1000037\",\n                                 sequence_ontology_label=\"chromosomal_duplication\",\n                                 variant_id=variant_id)\n\n    @staticmethod\n    def chromosomal_inversion(cell_contents,\n                              gene_symbol,\n                              gene_id,\n                              variant_id=None):\n        \"\"\"\n        create a StructuralVariant object for a chromosomal inversion\n\n        :param cell_contents: the string from the original table that we want to map as a structural variant\n        :type cell_contents: str\n        :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n        :type gene_symbol: str\n        :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n        :type gene_id: str\n        :param variant_id: an identifier for the variant\n        :type variant_id: str, optional\n        \"\"\"\n        return StructuralVariant(cell_contents=cell_contents,\n                                 gene_symbol=gene_symbol,\n                                 gene_id=gene_id,\n                                 sequence_ontology_id=\"SO:1000030\",\n                                 sequence_ontology_label=\"chromosomal_inversion\",\n                                 variant_id=variant_id)\n\n    @staticmethod\n    def chromosomal_translocation(cell_contents,\n                              gene_symbol,\n                              gene_id,\n                              variant_id=None):\n        \"\"\"\n        create a StructuralVariant object for a chromosomal translocation\n\n        :param cell_contents: the string from the original table that we want to map as a structural variant\n        :type cell_contents: str\n        :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n        :type gene_symbol: str\n        :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n        :type gene_id: str\n        :param variant_id: an identifier for the variant\n        :type variant_id: str, optional\n        \"\"\"\n        return StructuralVariant(cell_contents=cell_contents,\n                                 gene_symbol=gene_symbol,\n                                 gene_id=gene_id,\n                                 sequence_ontology_id=\"SO:1000044\",\n                                 sequence_ontology_label=\"chromosomal_translocation\",\n                                 variant_id=variant_id)\n</code></pre>"},{"location":"api/creation/structural_variant/#pyphetools.creation.StructuralVariant.chromosomal_deletion","title":"<code>chromosomal_deletion(cell_contents, gene_symbol, gene_id, variant_id=None)</code>  <code>staticmethod</code>","text":"<p>create a StructuralVariant object for a chromosomal deletion</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>the string from the original table that we want to map as a structural variant</p> required <code>gene_symbol</code> <code>str</code> <p>the gene affected by the structural variant, e.g., GLI3</p> required <code>gene_id</code> <code>str</code> <p>the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319</p> required <code>variant_id</code> <code>str, optional</code> <p>an identifier for the variant</p> <code>None</code> Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>@staticmethod\ndef chromosomal_deletion(cell_contents,\n                         gene_symbol,\n                         gene_id,\n                         variant_id=None):\n    \"\"\"\n    create a StructuralVariant object for a chromosomal deletion\n\n    :param cell_contents: the string from the original table that we want to map as a structural variant\n    :type cell_contents: str\n    :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n    :type gene_symbol: str\n    :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n    :type gene_id: str\n    :param variant_id: an identifier for the variant\n    :type variant_id: str, optional\n    \"\"\"\n    return StructuralVariant(cell_contents=cell_contents,\n                             gene_symbol=gene_symbol,\n                             gene_id=gene_id,\n                             sequence_ontology_id=\"SO:1000029\",\n                             sequence_ontology_label=\"chromosomal_deletion\",\n                             variant_id=variant_id)\n</code></pre>"},{"location":"api/creation/structural_variant/#pyphetools.creation.StructuralVariant.chromosomal_duplication","title":"<code>chromosomal_duplication(cell_contents, gene_symbol, gene_id, variant_id=None)</code>  <code>staticmethod</code>","text":"<p>create a StructuralVariant object for a chromosomal duplication</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>the string from the original table that we want to map as a structural variant</p> required <code>gene_symbol</code> <code>str</code> <p>the gene affected by the structural variant, e.g., GLI3</p> required <code>gene_id</code> <code>str</code> <p>the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319</p> required <code>variant_id</code> <code>str, optional</code> <p>an identifier for the variant</p> <code>None</code> Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>@staticmethod\ndef chromosomal_duplication(cell_contents,\n                            gene_symbol,\n                            gene_id,\n                            variant_id=None):\n    \"\"\"\n    create a StructuralVariant object for a chromosomal duplication\n\n    :param cell_contents: the string from the original table that we want to map as a structural variant\n    :type cell_contents: str\n    :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n    :type gene_symbol: str\n    :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n    :type gene_id: str\n    :param variant_id: an identifier for the variant\n    :type variant_id: str, optional\n    \"\"\"\n    return StructuralVariant(cell_contents=cell_contents,\n                             gene_symbol=gene_symbol,\n                             gene_id=gene_id,\n                             sequence_ontology_id=\"SO:1000037\",\n                             sequence_ontology_label=\"chromosomal_duplication\",\n                             variant_id=variant_id)\n</code></pre>"},{"location":"api/creation/structural_variant/#pyphetools.creation.StructuralVariant.chromosomal_inversion","title":"<code>chromosomal_inversion(cell_contents, gene_symbol, gene_id, variant_id=None)</code>  <code>staticmethod</code>","text":"<p>create a StructuralVariant object for a chromosomal inversion</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>the string from the original table that we want to map as a structural variant</p> required <code>gene_symbol</code> <code>str</code> <p>the gene affected by the structural variant, e.g., GLI3</p> required <code>gene_id</code> <code>str</code> <p>the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319</p> required <code>variant_id</code> <code>str, optional</code> <p>an identifier for the variant</p> <code>None</code> Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>@staticmethod\ndef chromosomal_inversion(cell_contents,\n                          gene_symbol,\n                          gene_id,\n                          variant_id=None):\n    \"\"\"\n    create a StructuralVariant object for a chromosomal inversion\n\n    :param cell_contents: the string from the original table that we want to map as a structural variant\n    :type cell_contents: str\n    :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n    :type gene_symbol: str\n    :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n    :type gene_id: str\n    :param variant_id: an identifier for the variant\n    :type variant_id: str, optional\n    \"\"\"\n    return StructuralVariant(cell_contents=cell_contents,\n                             gene_symbol=gene_symbol,\n                             gene_id=gene_id,\n                             sequence_ontology_id=\"SO:1000030\",\n                             sequence_ontology_label=\"chromosomal_inversion\",\n                             variant_id=variant_id)\n</code></pre>"},{"location":"api/creation/structural_variant/#pyphetools.creation.StructuralVariant.chromosomal_translocation","title":"<code>chromosomal_translocation(cell_contents, gene_symbol, gene_id, variant_id=None)</code>  <code>staticmethod</code>","text":"<p>create a StructuralVariant object for a chromosomal translocation</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>the string from the original table that we want to map as a structural variant</p> required <code>gene_symbol</code> <code>str</code> <p>the gene affected by the structural variant, e.g., GLI3</p> required <code>gene_id</code> <code>str</code> <p>the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319</p> required <code>variant_id</code> <code>str, optional</code> <p>an identifier for the variant</p> <code>None</code> Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>@staticmethod\ndef chromosomal_translocation(cell_contents,\n                          gene_symbol,\n                          gene_id,\n                          variant_id=None):\n    \"\"\"\n    create a StructuralVariant object for a chromosomal translocation\n\n    :param cell_contents: the string from the original table that we want to map as a structural variant\n    :type cell_contents: str\n    :param gene_symbol: the gene affected by the structural variant, e.g., GLI3\n    :type gene_symbol: str\n    :param gene_id: the identifier (using HGNC) of the gene, e.g., GLI3 is HGNC:4319\n    :type gene_id: str\n    :param variant_id: an identifier for the variant\n    :type variant_id: str, optional\n    \"\"\"\n    return StructuralVariant(cell_contents=cell_contents,\n                             gene_symbol=gene_symbol,\n                             gene_id=gene_id,\n                             sequence_ontology_id=\"SO:1000044\",\n                             sequence_ontology_label=\"chromosomal_translocation\",\n                             variant_id=variant_id)\n</code></pre>"},{"location":"api/creation/structural_variant/#pyphetools.creation.StructuralVariant.to_ga4gh_variant_interpretation","title":"<code>to_ga4gh_variant_interpretation(acmg=None)</code>","text":"<p>Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema</p> Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>def to_ga4gh_variant_interpretation(self, acmg=None):\n    \"\"\"\n    Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n    \"\"\"\n    vdescriptor = phenopackets.VariationDescriptor()\n    vdescriptor.id = self._variant_id\n    vdescriptor.gene_context.value_id = self._hgnc_id\n    vdescriptor.gene_context.symbol = self._gene_symbol\n    vdescriptor.label = self._label\n    vdescriptor.molecule_context = phenopackets.MoleculeContext.genomic\n    if self._genotype is not None:\n        if self._genotype == 'heterozygous':\n            vdescriptor.allelic_state.id = \"GENO:0000135\"\n            vdescriptor.allelic_state.label = \"heterozygous\"\n        elif self._genotype == 'homozygous':\n            vdescriptor.allelic_state.id = \"GENO:0000136\"\n            vdescriptor.allelic_state.label = \"homozygous\"\n        elif self._genotype == 'hemizygous':\n            vdescriptor.allelic_state.id = \"GENO:0000134\"\n            vdescriptor.allelic_state.label = \"hemizygous\"\n        else:\n            print(f\"Did not recognize genotype {self._genotype}\")\n    vdescriptor.structural_type.id = self._so_id\n    vdescriptor.structural_type.label = self._so_label\n    vinterpretation = phenopackets.VariantInterpretation()\n    if acmg is not None:\n        if acmg.lower() == 'benign':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.BENIGN\n        elif acmg.lower == 'likely benign' or acmg.lower() == 'likely_benign':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_BENIGN\n        elif acmg.lower == 'uncertain significance' or acmg.lower() == 'uncertain_significance':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.UNCERTAIN_SIGNIFICANCE\n        elif acmg.lower == 'likely pathogenic' or acmg.lower() == 'likely_pathogenic':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.LIKELY_PATHOGENIC\n        elif acmg.lower == 'pathogenic' or acmg.lower() == 'pathogenic':\n            vinterpretation.acmgPathogenicityClassification = phenopackets.AcmgPathogenicityClassification.PATHOGENIC\n        else:\n            print(f\"Warning- did not recognize ACMG category {acmg}\")\n    vinterpretation.variation_descriptor.CopyFrom(vdescriptor)\n    return vinterpretation\n</code></pre>"},{"location":"api/creation/structural_variant/#pyphetools.creation.StructuralVariant.to_variant_interpretation_202","title":"<code>to_variant_interpretation_202(acmg=None)</code>","text":"<p>Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema</p> Source code in <code>pyphetools/creation/structural_variant.py</code> <pre><code>def to_variant_interpretation_202(self, acmg=None):\n    \"\"\"\n    Transform this Variant object into a \"variantInterpretation\" message of the GA4GH Phenopacket schema\n    \"\"\"\n    from ..pp.v202 import VariantInterpretation as VariantInterpretation202\n    from ..pp.v202 import VariationDescriptor as VariationDescriptor202\n    from ..pp.v202 import GeneDescriptor as GeneDescriptor202\n    from ..pp.v202 import OntologyClass as OntologyClass202\n    from ..pp.v202 import MoleculeContext as MoleculeContext202\n\n    gdesc = GeneDescriptor202(value_id=self._hgnc_id, symbol=self._gene_symbol)\n    vdescriptor = VariationDescriptor202(id=self._variant_id,\n                                         gene_context=gdesc,\n                                         label=self._label,\n                                         molecule_context=MoleculeContext202.genomic)\n    # Note that it is possible to first create a StructuralVariant object and later set its genotype\n    # Therefore, it is not an error if gt_term is None\n    gt_term = Variant._get_genotype_term(self._genotype)\n    if gt_term is not None:\n        vdescriptor.allelic_state = gt_term\n    structural_type = OntologyClass202(id=self._so_id, label=self._so_label)\n    vdescriptor.structural_type = structural_type\n    vinterpretation = VariantInterpretation202(variation_descriptor=vdescriptor)\n    acmg_code = Variant._get_acmg_classification(acmg=acmg)\n    if acmg_code is not None:\n        vinterpretation.acmgPathogenicityClassification = acmg_code\n    else:\n        print(f\"Warning- did not recognize ACMG category \\\"{acmg}\\\"\")\n    return vinterpretation\n</code></pre>"},{"location":"api/creation/thresholded_column_mapper/","title":"ThresholdedColumnMapper","text":"<p>               Bases: <code>ColumnMapper</code></p> Source code in <code>pyphetools/creation/thresholded_column_mapper.py</code> <pre><code>class ThresholdedColumnMapper(ColumnMapper):\n\n    def __init__(self, column_name, thresholder:Thresholder):\n        super().__init__(column_name=column_name)\n        self._thresholder = thresholder\n\n    def map_cell(self, cell_contents) -&gt; List[HpTerm]:\n        hpterm = self._thresholder.map_value(cell_contents=cell_contents)\n        if hpterm is not None:\n            return [hpterm]\n        else:\n            return []\n\n\n    def preview_column(self, df:pd.DataFrame):\n        if not isinstance(df, pd.DataFrame):\n            raise ValueError(\"df argument must be pandas DataFrame, but was {type(column)}\")\n        column = df[self._column_name]\n        mapping_counter = defaultdict(int)\n        for _, value in column.items():\n            results = self.map_cell(str(value))\n            if len(results) &gt; 0:\n                hpterm = results[0]\n                mapped = f\"{hpterm.hpo_term_and_id}: {hpterm.display_value}\"\n                mapping_counter[mapped] += 1\n        dlist = []\n        colname = f\"mapping: {self._thresholder.get_reference_range()}\"\n        for k, v in mapping_counter.items():\n            d = {colname: k, \"count\": str(v)}\n            dlist.append(d)\n        return pd.DataFrame(dlist)\n</code></pre>"},{"location":"api/creation/thresholder/","title":"Thresholder","text":"<p>A class to simplify the interpretation of thresholded values</p> <p>The class organizes the interpretation of numerical values for tests such as blood potassium. Results can be low, normal, or high, and there is an HPO term for each. The class also provides commonly used normal ranges. We note that many lab tests have different ranges for males and females or for adults and children. We do not attempt to model this, but instead provide ranges for adults. In cases where there are different ranges for males and females, we by default use the minimum and maximum value for each sex. It is possible to specify the range that should be used in the constructor method; in this case, the default values are overriden. In very complicated cases with multiple different normal ranges, consider using the OptionColumnMapper.</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>class Thresholder:\n    \"\"\"A class to simplify the interpretation of thresholded values\n\n    The class organizes the interpretation of numerical values for tests such as blood potassium. Results\n    can be low, normal, or high, and there is an HPO term for each. The class also provides\n    commonly used normal ranges. We note that many lab tests have different ranges for males and females or\n    for adults and children. We do not attempt to model this, but instead provide ranges for adults.\n    In cases where there are different ranges for males and females, we by default use the minimum and maximum\n    value for each sex. It is possible to specify the range that should be used in the constructor method;\n    in this case, the default values are overriden. In very complicated cases with multiple different\n    normal ranges, consider using the OptionColumnMapper.\n    \"\"\"\n\n    THRESHOLDER_MAP_NEEDS_INITIALIZATION = True\n\n    THRESHOLDER_MAP = {}\n\n    def __init__(self, unit:str, hpo_term_low=None, hpo_term_high=None, hpo_term_abn=None, threshold_low=None, threshold_high=None):\n        \"\"\"\n        if hpo_term_low is not None and not isinstance(hpo_term_low, HpTerm):\n            raise ValueError(f\"hpo_term_low argument must be HpTerm but was {type(hpo_term_low)}\")\n        if hpo_term_high is not None and not isinstance(hpo_term_high, HpTerm):\n            raise ValueError(f\"hpo_term_high argument must be HpTerm but was {type(hpo_term_high)}\")\n        if hpo_term_abn is not None and not  not isinstance(hpo_term_abn, HpTerm):\n            raise ValueError(f\"hpo_term_abn argument must be HpTerm but was {type(hpo_term_abn)}\")\n        \"\"\"\n        self._hpo_low = hpo_term_low\n        self._hpo_high = hpo_term_high\n        self._hpo_term_abn = hpo_term_abn\n        # The thresholds are allowed to be None but if they are given they must be numbers\n        if threshold_low is not None and not isinstance(threshold_low, int) and not isinstance(threshold_low, float):\n            raise ValueError(f\"threshold_low argument must be integer or float but was {threshold_low}\")\n        if threshold_high is not None and not isinstance(threshold_high, int) and not isinstance(threshold_high, float):\n            raise ValueError(f\"threshold_high argument must be integer or float but was {threshold_high}\")\n        self._unit = unit\n        self._threshold_low = self._set_threshold_to_float_or_none(threshold_low)\n        self._threshold_high = self._set_threshold_to_float_or_none(threshold_high)\n\n    def _set_threshold_to_float_or_none(self, thresh):\n        \"\"\"in the input file, a threshold value can be set to na or n/a. If so, we set the value to None.\n        Otherwise, we convert all values to floats\n        \"\"\"\n        if thresh is not None:\n            return float(thresh)\n        else:\n            return None\n\n\n    def set_unit(self, unit) -&gt; None:\n        \"\"\"\n        :param unit: a user-defined unit. This can be useful, for instance, if a paper uses mg/dL instead of SI units\n        :type unit: str\n        \"\"\"\n        self._unit = unit\n\n    def set_high_threshold(self, value):\n        \"\"\"Set a user-defined high threshold value. This can be useful, for instance, if a paper uses mg/dL instead of SI units\n        \"\"\"\n        value = float(value)\n        self._threshold_high = value\n\n    def set_low_threshold(self, value):\n        \"\"\"Set a user-defined low threshold value. This can be useful, for instance, if a paper uses mg/dL instead of SI units\n        \"\"\"\n        value = float(value)\n        self._threshold_low = value\n\n    def get_reference_range(self):\n        return f\"{self._threshold_low}-{self._threshold_high} {self._unit}\"\n\n\n    def _value_is_high(self, value):\n        if self._threshold_high is None:\n            return False\n        if self._hpo_high is None:\n            return False\n        return self._threshold_high &lt; value\n\n    def _value_is_low(self, value):\n        if self._threshold_low is None:\n            return False\n        if self._hpo_low is None:\n            return False\n        return self._threshold_low &gt; value\n\n    def _value_is_normal(self, value):\n        if self._threshold_high is None or self._threshold_low is None:\n            return False\n        if self._hpo_term_abn is None:\n            return False\n        return  value &gt;= self._threshold_low and value &lt;= self._threshold_high\n\n\n    def _non_measured_term(self):\n        if self._hpo_term_abn is not None:\n            return HpTerm(hpo_id=self._hpo_term_abn.id, label=self._hpo_term_abn.label, measured=False)\n        elif self._hpo_high is not None:\n            return HpTerm(hpo_id=self._hpo_high.id, label=self._hpo_high.label, measured=False)\n        elif self._hpo_low is not None:\n            return HpTerm(hpo_id=self._hpo_low.id, label=self._hpo_low.label, measured=False)\n        else:\n            # should never happen\n            raise ValueError(\"No HPO Term found for unmeasured\")\n\n\n    def map_value(self, cell_contents) -&gt; HpTerm:\n        if isinstance(cell_contents, str):\n            contents = cell_contents.strip()\n            if contents.lower() == \"nan\":\n                return HpTerm(hpo_id=self._hpo_term_abn.id, label=self._hpo_term_abn.label, measured=False)\n        elif isinstance(cell_contents, int):\n            contents = cell_contents\n        elif isinstance(cell_contents, float):\n            if math.isnan(cell_contents):\n                return HpTerm(hpo_id=self._hpo_term_abn.id, label=self._hpo_term_abn.label, measured=False)\n            contents = cell_contents\n        else:\n            raise ValueError(\n                f\"Malformed cell contents for ThresholdedColumnMapper: {cell_contents}, type={type(cell_contents)}\")\n        try:\n            value = float(contents)\n            if self._value_is_high(value=value):\n                return self._hpo_high\n            elif self._value_is_low(value=value):\n                return self._hpo_low\n            elif self._value_is_normal(value=value):\n                return HpTerm(hpo_id=self._hpo_term_abn.id, label=self._hpo_term_abn.label, observed=False)\n            else:\n                return self._non_measured_term()\n        except Exception as exc:\n            return self._non_measured_term()\n\n\n    @staticmethod\n    def _get_hpo_term_or_none(hpo_id, hpo_label):\n        \"\"\"It is OK if we do not have threshold terms for all three possible slots (Abnormal, High, Low)\n        If we do not have a term, then we return None and the thresholder object will know what to do\n        \"\"\"\n        # It is OK if there is a blank cell or a cell with na\n        if hpo_id is None or hpo_label is None:\n            return None\n        if len(hpo_id) == 0 or len(hpo_label) == 0:\n            return None\n        if hpo_id == 'na' or hpo_label == 'na':\n            return None\n        # if the hpo_id is present, it must be well formed\n        if not hpo_id.startswith('HP:') or len(hpo_id) != 10:\n            raise ValueError(f\"Malformed HP id: \\\"{hpo_id}\\\"\")\n        # we should be good to go when we get here\n        return HpTerm(hpo_id=hpo_id, label=hpo_label)\n\n    @staticmethod\n    def _get_threshold_or_none(thresh):\n        \"\"\"the threshold cell can be empty or na -- this is OK, return None\n        Otherwise return a float\n        \"\"\"\n        if thresh is None:\n            return None\n        if isinstance(thresh, str):\n            if len(thresh) == 0 or thresh == 'na' or thresh == \"n/a\":\n                return None\n        if isinstance(thresh, float) and math.isnan(thresh):\n            return None\n        return float(thresh)\n\n\n    @staticmethod\n    def _initialize_map():\n        #current_dir = os.path.dirname(__file__)\n        #thresholds_file = os.path.join(current_dir, \"data\", \"thresholds.tsv\");\n        df = pd.read_csv(THRESHOLDS_FILE, delimiter=\"\\t\")\n        for _, row in df.iterrows():\n            label = row[\"label\"]\n            hpo_abn_label  = row[\"hpo_abn_label\"]\n            hpo_abn_id  = row[\"hpo_abn_id\"]\n            hpo_low_label  = row[\"hpo_low_label\"]\n            hpo_low_id  = row[\"hpo_low_id\"]\n            hpo_high_label  = row[\"hpo_high_label\"]\n            hpo_high_id   = row[\"hpo_high_id\"]\n            \"\"\"\n            # Uncomment to test whether there are format errors\n            for item in [hpo_abn_label, hpo_abn_id, hpo_low_label, hpo_low_id,hpo_high_label, hpo_high_id]:\n                if item.startswith(\" \") or item.endswith(\" \"):\n                    raise ValueError(f\"Mqlformed HPO term: \\\"{item}\\\"\")\n            \"\"\"\n            unit   = row[\"unit\"]\n            low  = row[\"low\"]\n            high  = row[\"high\"]\n            # Reference = row[\"Reference\"] -- not needed here, for human consumption only\n            hp_abnormal = Thresholder._get_hpo_term_or_none(hpo_id=hpo_abn_id, hpo_label=hpo_abn_label)\n            hp_low = Thresholder._get_hpo_term_or_none(hpo_id=hpo_low_id, hpo_label=hpo_low_label)\n            hp_high = Thresholder._get_hpo_term_or_none(hpo_id=hpo_high_id, hpo_label=hpo_high_label)\n            low_thresh = Thresholder._get_threshold_or_none(low)\n            high_thresh = Thresholder._get_threshold_or_none(high)\n            thresh = Thresholder(unit=unit, hpo_term_abn=hp_abnormal, hpo_term_high=hp_high, hpo_term_low=hp_low, threshold_high=high_thresh, threshold_low=low_thresh)\n            Thresholder.THRESHOLDER_MAP[label] = thresh\n        Thresholder.THRESHOLDER_MAP_NEEDS_INITIALIZATION = False\n\n\n\n\n\n    @staticmethod\n    def _get_thresholder(thresholder_label, unit=None, low_thresh=None, high_thresh=None):\n        if Thresholder.THRESHOLDER_MAP_NEEDS_INITIALIZATION:\n            Thresholder._initialize_map()\n        if not thresholder_label in Thresholder.THRESHOLDER_MAP:\n            raise ValueError(f\"Could not find thresholder object for \\\"{thresholder_label}\\\"\")\n        thresh = Thresholder.THRESHOLDER_MAP.get(thresholder_label)\n        if unit is not None:\n            thresh.set_unit(unit)\n        if low_thresh is not None:\n            thresh.set_low_threshold(low_thresh)\n        if high_thresh is not None:\n            thresh.set_high_threshold(high_thresh)\n        return thresh\n\n\n    #################\n    ## Static methods for commonly used lab tests.\n    ## data in data/thresholds.tsv\n\n    @staticmethod\n    def albumin_urine(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Albuminuria - Urine Albumin-Creatinine Ratio (uACR)\n        \"\"\"\n        return Thresholder._get_thresholder(\"albumin urine\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def ALT_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"ALT blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"ALT blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def AST_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"AST blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"AST blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n\n    @staticmethod\n    def alkaline_phophatase_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Alkaline phosphatase in the blood circulation (U/L)\n        \"\"\"\n        return Thresholder._get_thresholder(\"alkaline phosphatase blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def ALT_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"ALT_blood in the blood circulation (U/L)\u201a\n        \"\"\"\n        return Thresholder._get_thresholder(\"ALT blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def AST_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"AST_blood in the blood circulation (U/L)\u201a\n        \"\"\"\n        return Thresholder._get_thresholder(\"AST blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def calcium_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Calcium in the blood circulation 8.5 to 10.2 mg/dL (2.13 to 2.55 millimol/L).\n        \"\"\"\n        return Thresholder._get_thresholder(\"calcium blood\",unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n\n    @staticmethod\n    def creatine_kinase_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"CK females is 30 to 145 U/L; males 55 to 170 U/L\n        \"\"\"\n        return Thresholder._get_thresholder(\"creatine kinase blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n\n\n    @staticmethod\n    def creatinine_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Serum crea,  0.6-1.2 mg/dL in adult males and 0.5-1.1 mg/dL in adult females\n        \"\"\"\n        return Thresholder._get_thresholder(\"creatinine blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n\n\n    @staticmethod\n    def CRP_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\" CRP blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"CRP blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n\n    @staticmethod\n    def free_fatty_acid_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"free fatty acid\n        \"\"\"\n        return Thresholder._get_thresholder(\"free fatty acid blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n\n    @staticmethod\n    def glucose_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"fasting blood glucose; 70 mg/dL (3.9 mmol/L) and 100 mg/dL (5.6 mmol/L).\n        \"\"\"\n        return Thresholder._get_thresholder(\"glucose blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n\n    @staticmethod\n    def hemoglobin_A1c(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"hemoglobin_A1c\n        \"\"\"\n        return Thresholder._get_thresholder(\"hemoglobin A1c\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n\n\n\n    @staticmethod\n    def HDL_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"HDL cholesterol blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"HDL cholesterol blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def insulin_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"insulin blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"insulin blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n\n    @staticmethod\n    def lactate_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Serum lactate (0.5-1 mmol/L)\n        \"\"\"\n        return Thresholder._get_thresholder(\"lactate blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def LDL_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"LDL cholesterol blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"LDL cholesterol blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def NTproBNP_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"NT-proBNP &lt; 100 picograms per milliliter (pg/mL)\n        \"\"\"\n        return Thresholder._get_thresholder(\"NT-proBNP blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def sodium_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Sodium in the blood circulation 135-145 mEq/L\n        \"\"\"\n        return Thresholder._get_thresholder(\"sodium blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def potassium_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"Serum potassium 3.5 to 5.2 mEq/L (adults)\n        \"\"\"\n        return Thresholder._get_thresholder(\"potassium blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def total_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"total cholesterol blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"total cholesterol blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n\n    @staticmethod\n    def triglyceride_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"triglyceride blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"triglyceride blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n    @staticmethod\n    def troponin_t_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"troponin t blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"troponin t blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n\n\n    @staticmethod\n    def uric_acid_blood(unit=None, low_thresh=None, high_thresh=None):\n        \"\"\"uric acid blood\n        \"\"\"\n        return Thresholder._get_thresholder(\"uric acid blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.ALT_blood","title":"<code>ALT_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>ALT_blood in the blood circulation (U/L)\u201a</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef ALT_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"ALT_blood in the blood circulation (U/L)\u201a\n    \"\"\"\n    return Thresholder._get_thresholder(\"ALT blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.AST_blood","title":"<code>AST_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>AST_blood in the blood circulation (U/L)\u201a</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef AST_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"AST_blood in the blood circulation (U/L)\u201a\n    \"\"\"\n    return Thresholder._get_thresholder(\"AST blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.CRP_blood","title":"<code>CRP_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>CRP blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef CRP_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\" CRP blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"CRP blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.HDL_cholesterol_blood","title":"<code>HDL_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>HDL cholesterol blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef HDL_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"HDL cholesterol blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"HDL cholesterol blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.LDL_cholesterol_blood","title":"<code>LDL_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>LDL cholesterol blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef LDL_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"LDL cholesterol blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"LDL cholesterol blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.NTproBNP_blood","title":"<code>NTproBNP_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>NT-proBNP &lt; 100 picograms per milliliter (pg/mL)</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef NTproBNP_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"NT-proBNP &lt; 100 picograms per milliliter (pg/mL)\n    \"\"\"\n    return Thresholder._get_thresholder(\"NT-proBNP blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.__init__","title":"<code>__init__(unit, hpo_term_low=None, hpo_term_high=None, hpo_term_abn=None, threshold_low=None, threshold_high=None)</code>","text":"<p>if hpo_term_low is not None and not isinstance(hpo_term_low, HpTerm):     raise ValueError(f\"hpo_term_low argument must be HpTerm but was {type(hpo_term_low)}\") if hpo_term_high is not None and not isinstance(hpo_term_high, HpTerm):     raise ValueError(f\"hpo_term_high argument must be HpTerm but was {type(hpo_term_high)}\") if hpo_term_abn is not None and not  not isinstance(hpo_term_abn, HpTerm):     raise ValueError(f\"hpo_term_abn argument must be HpTerm but was {type(hpo_term_abn)}\")</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>def __init__(self, unit:str, hpo_term_low=None, hpo_term_high=None, hpo_term_abn=None, threshold_low=None, threshold_high=None):\n    \"\"\"\n    if hpo_term_low is not None and not isinstance(hpo_term_low, HpTerm):\n        raise ValueError(f\"hpo_term_low argument must be HpTerm but was {type(hpo_term_low)}\")\n    if hpo_term_high is not None and not isinstance(hpo_term_high, HpTerm):\n        raise ValueError(f\"hpo_term_high argument must be HpTerm but was {type(hpo_term_high)}\")\n    if hpo_term_abn is not None and not  not isinstance(hpo_term_abn, HpTerm):\n        raise ValueError(f\"hpo_term_abn argument must be HpTerm but was {type(hpo_term_abn)}\")\n    \"\"\"\n    self._hpo_low = hpo_term_low\n    self._hpo_high = hpo_term_high\n    self._hpo_term_abn = hpo_term_abn\n    # The thresholds are allowed to be None but if they are given they must be numbers\n    if threshold_low is not None and not isinstance(threshold_low, int) and not isinstance(threshold_low, float):\n        raise ValueError(f\"threshold_low argument must be integer or float but was {threshold_low}\")\n    if threshold_high is not None and not isinstance(threshold_high, int) and not isinstance(threshold_high, float):\n        raise ValueError(f\"threshold_high argument must be integer or float but was {threshold_high}\")\n    self._unit = unit\n    self._threshold_low = self._set_threshold_to_float_or_none(threshold_low)\n    self._threshold_high = self._set_threshold_to_float_or_none(threshold_high)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.albumin_urine","title":"<code>albumin_urine(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Albuminuria - Urine Albumin-Creatinine Ratio (uACR)</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef albumin_urine(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Albuminuria - Urine Albumin-Creatinine Ratio (uACR)\n    \"\"\"\n    return Thresholder._get_thresholder(\"albumin urine\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.alkaline_phophatase_blood","title":"<code>alkaline_phophatase_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Alkaline phosphatase in the blood circulation (U/L)</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef alkaline_phophatase_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Alkaline phosphatase in the blood circulation (U/L)\n    \"\"\"\n    return Thresholder._get_thresholder(\"alkaline phosphatase blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.calcium_blood","title":"<code>calcium_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Calcium in the blood circulation 8.5 to 10.2 mg/dL (2.13 to 2.55 millimol/L).</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef calcium_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Calcium in the blood circulation 8.5 to 10.2 mg/dL (2.13 to 2.55 millimol/L).\n    \"\"\"\n    return Thresholder._get_thresholder(\"calcium blood\",unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.creatine_kinase_blood","title":"<code>creatine_kinase_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>CK females is 30 to 145 U/L; males 55 to 170 U/L</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef creatine_kinase_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"CK females is 30 to 145 U/L; males 55 to 170 U/L\n    \"\"\"\n    return Thresholder._get_thresholder(\"creatine kinase blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.creatinine_blood","title":"<code>creatinine_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Serum crea,  0.6-1.2 mg/dL in adult males and 0.5-1.1 mg/dL in adult females</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef creatinine_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Serum crea,  0.6-1.2 mg/dL in adult males and 0.5-1.1 mg/dL in adult females\n    \"\"\"\n    return Thresholder._get_thresholder(\"creatinine blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.free_fatty_acid_blood","title":"<code>free_fatty_acid_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>free fatty acid</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef free_fatty_acid_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"free fatty acid\n    \"\"\"\n    return Thresholder._get_thresholder(\"free fatty acid blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.glucose_blood","title":"<code>glucose_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>fasting blood glucose; 70 mg/dL (3.9 mmol/L) and 100 mg/dL (5.6 mmol/L).</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef glucose_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"fasting blood glucose; 70 mg/dL (3.9 mmol/L) and 100 mg/dL (5.6 mmol/L).\n    \"\"\"\n    return Thresholder._get_thresholder(\"glucose blood\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.hemoglobin_A1c","title":"<code>hemoglobin_A1c(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>hemoglobin_A1c</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef hemoglobin_A1c(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"hemoglobin_A1c\n    \"\"\"\n    return Thresholder._get_thresholder(\"hemoglobin A1c\", unit=unit, low_thresh=low_thresh, high_thresh=high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.insulin_blood","title":"<code>insulin_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>insulin blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef insulin_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"insulin blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"insulin blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.lactate_blood","title":"<code>lactate_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Serum lactate (0.5-1 mmol/L)</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef lactate_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Serum lactate (0.5-1 mmol/L)\n    \"\"\"\n    return Thresholder._get_thresholder(\"lactate blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.potassium_blood","title":"<code>potassium_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Serum potassium 3.5 to 5.2 mEq/L (adults)</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef potassium_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Serum potassium 3.5 to 5.2 mEq/L (adults)\n    \"\"\"\n    return Thresholder._get_thresholder(\"potassium blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.set_high_threshold","title":"<code>set_high_threshold(value)</code>","text":"<p>Set a user-defined high threshold value. This can be useful, for instance, if a paper uses mg/dL instead of SI units</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>def set_high_threshold(self, value):\n    \"\"\"Set a user-defined high threshold value. This can be useful, for instance, if a paper uses mg/dL instead of SI units\n    \"\"\"\n    value = float(value)\n    self._threshold_high = value\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.set_low_threshold","title":"<code>set_low_threshold(value)</code>","text":"<p>Set a user-defined low threshold value. This can be useful, for instance, if a paper uses mg/dL instead of SI units</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>def set_low_threshold(self, value):\n    \"\"\"Set a user-defined low threshold value. This can be useful, for instance, if a paper uses mg/dL instead of SI units\n    \"\"\"\n    value = float(value)\n    self._threshold_low = value\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.set_unit","title":"<code>set_unit(unit)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>unit</code> <code>str</code> <p>a user-defined unit. This can be useful, for instance, if a paper uses mg/dL instead of SI units</p> required Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>def set_unit(self, unit) -&gt; None:\n    \"\"\"\n    :param unit: a user-defined unit. This can be useful, for instance, if a paper uses mg/dL instead of SI units\n    :type unit: str\n    \"\"\"\n    self._unit = unit\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.sodium_blood","title":"<code>sodium_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>Sodium in the blood circulation 135-145 mEq/L</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef sodium_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"Sodium in the blood circulation 135-145 mEq/L\n    \"\"\"\n    return Thresholder._get_thresholder(\"sodium blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.total_cholesterol_blood","title":"<code>total_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>total cholesterol blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef total_cholesterol_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"total cholesterol blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"total cholesterol blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.triglyceride_blood","title":"<code>triglyceride_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>triglyceride blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef triglyceride_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"triglyceride blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"triglyceride blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.troponin_t_blood","title":"<code>troponin_t_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>troponin t blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef troponin_t_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"troponin t blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"troponin t blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/thresholder/#pyphetools.creation.Thresholder.uric_acid_blood","title":"<code>uric_acid_blood(unit=None, low_thresh=None, high_thresh=None)</code>  <code>staticmethod</code>","text":"<p>uric acid blood</p> Source code in <code>pyphetools/creation/thresholder.py</code> <pre><code>@staticmethod\ndef uric_acid_blood(unit=None, low_thresh=None, high_thresh=None):\n    \"\"\"uric acid blood\n    \"\"\"\n    return Thresholder._get_thresholder(\"uric acid blood\", unit=unit, low_thresh=low_thresh, high_thresh= high_thresh)\n</code></pre>"},{"location":"api/creation/variant/","title":"Variant","text":"<p>Superclass for classes that create GA4GH VariantInterpretationObjects. Subclass HgvsVariant is used for small variants encoded using HGVS notation, e.g., NM_00123.5:c.543G&gt;T. Subclass StructuralVariant is used for structural variants that are likely to completely disrupt a gene.</p> Source code in <code>pyphetools/creation/variant.py</code> <pre><code>class Variant(metaclass=abc.ABCMeta):\n    \"\"\"\n    Superclass for classes that create GA4GH VariantInterpretationObjects.\n    Subclass HgvsVariant is used for small variants encoded using HGVS notation, e.g., NM_00123.5:c.543G&gt;T.\n    Subclass StructuralVariant is used for structural variants that are likely to completely disrupt a gene.\n\n    \"\"\"\n\n    def __init__(self):\n        self._genotype = None\n\n    @abc.abstractmethod\n    def to_ga4gh_variant_interpretation(self, acmg=None):\n        \"\"\"\n        Embed the variant object into a GA4GH Genomic Interpretation object (abstract method)\n\n        The argument acmg must be one of the strings 'benign', 'likely_benign', 'uncertain_significance',\n            'likely_pathogenic', or 'pathogenic' (underscores are optional). If it is not provided or\n            not one of these strings, the level will be set to not available\n\n        :param acmg: ACMG pathogenicity level\n        :type acmg: str\n        \"\"\"\n        pass\n\n    def set_heterozygous(self):\n        \"\"\"\n        Assign heterozygous allele status to this variant\n\n        \"\"\"\n        self._genotype = 'heterozygous'\n\n    def set_homozygous(self):\n        \"\"\"\n        Assign homozygous allele status to this variant\n\n        \"\"\"\n        self._genotype = 'homozygous'\n\n    def set_hemizygous(self):\n        \"\"\"\n        Assign hemizygous allele status to this variant\n\n        \"\"\"\n        self._genotype = 'hemizygous'\n\n    def set_genotype(self, gt):\n        \"\"\"\n        Assign an allele status to this variant\n\n        :param gt: The genotype (allele status) of this variant\n\n        \"\"\"\n        genotype = gt.lower()\n        if genotype not in {'heterozygous', 'homozygous', 'hemizygous'}:\n            raise ValueError(f\"Unrecognized genotype {gt}\")\n        self._genotype = genotype\n\n    @staticmethod\n    def _get_genotype_term(genotype: str) -&gt; typing.Optional[OntologyClass202]:\n        if genotype is None:\n            return None\n        if genotype == \"heterozygous\":\n            return OntologyClass202(id=\"GENO:0000135\", label=genotype)\n        elif genotype == \"homozygous\":\n            return OntologyClass202(id=\"GENO:0000136\", label=genotype)\n        elif genotype == \"hemizygous\":\n            return OntologyClass202(id=\"GENO:0000134\", label=genotype)\n        else:\n            raise ValueError(f\"Did not recognize genotype {genotype}\")\n\n    @staticmethod\n    def _get_acmg_classification(acmg: str = None) -&gt; ACMG202:\n        \"\"\"\n        Get the Phenopacket Schema code for ACMG variant pathogenicity classification.\n        \"\"\"\n        if acmg is None:\n            return ACMG202.NOT_PROVIDED\n        acmg = acmg.lower()\n        acmg_d = {\n            'benign': ACMG202.BENIGN,\n            'likely benign': ACMG202.LIKELY_BENIGN,\n            'likely_benign': ACMG202.LIKELY_BENIGN,\n            'uncertain significance': ACMG202.UNCERTAIN_SIGNIFICANCE,\n            'uncertain_significance': ACMG202.UNCERTAIN_SIGNIFICANCE,\n            'likely pathogenic': ACMG202.LIKELY_PATHOGENIC,\n            'likely_pathogenic': ACMG202.LIKELY_PATHOGENIC,\n            'pathogenic': ACMG202.PATHOGENIC\n        }\n        if acmg in acmg_d:\n            return acmg_d.get(acmg)\n        else:\n            print(f\"Warning- did not recognize ACMG category {acmg}\")\n            return ACMG202.NOT_PROVIDED\n</code></pre>"},{"location":"api/creation/variant/#pyphetools.creation.Variant.set_genotype","title":"<code>set_genotype(gt)</code>","text":"<p>Assign an allele status to this variant</p> <p>Parameters:</p> Name Type Description Default <code>gt</code> <p>The genotype (allele status) of this variant</p> required Source code in <code>pyphetools/creation/variant.py</code> <pre><code>def set_genotype(self, gt):\n    \"\"\"\n    Assign an allele status to this variant\n\n    :param gt: The genotype (allele status) of this variant\n\n    \"\"\"\n    genotype = gt.lower()\n    if genotype not in {'heterozygous', 'homozygous', 'hemizygous'}:\n        raise ValueError(f\"Unrecognized genotype {gt}\")\n    self._genotype = genotype\n</code></pre>"},{"location":"api/creation/variant/#pyphetools.creation.Variant.set_hemizygous","title":"<code>set_hemizygous()</code>","text":"<p>Assign hemizygous allele status to this variant</p> Source code in <code>pyphetools/creation/variant.py</code> <pre><code>def set_hemizygous(self):\n    \"\"\"\n    Assign hemizygous allele status to this variant\n\n    \"\"\"\n    self._genotype = 'hemizygous'\n</code></pre>"},{"location":"api/creation/variant/#pyphetools.creation.Variant.set_heterozygous","title":"<code>set_heterozygous()</code>","text":"<p>Assign heterozygous allele status to this variant</p> Source code in <code>pyphetools/creation/variant.py</code> <pre><code>def set_heterozygous(self):\n    \"\"\"\n    Assign heterozygous allele status to this variant\n\n    \"\"\"\n    self._genotype = 'heterozygous'\n</code></pre>"},{"location":"api/creation/variant/#pyphetools.creation.Variant.set_homozygous","title":"<code>set_homozygous()</code>","text":"<p>Assign homozygous allele status to this variant</p> Source code in <code>pyphetools/creation/variant.py</code> <pre><code>def set_homozygous(self):\n    \"\"\"\n    Assign homozygous allele status to this variant\n\n    \"\"\"\n    self._genotype = 'homozygous'\n</code></pre>"},{"location":"api/creation/variant/#pyphetools.creation.Variant.to_ga4gh_variant_interpretation","title":"<code>to_ga4gh_variant_interpretation(acmg=None)</code>  <code>abstractmethod</code>","text":"<p>Embed the variant object into a GA4GH Genomic Interpretation object (abstract method)</p> <p>The argument acmg must be one of the strings 'benign', 'likely_benign', 'uncertain_significance',     'likely_pathogenic', or 'pathogenic' (underscores are optional). If it is not provided or     not one of these strings, the level will be set to not available</p> <p>Parameters:</p> Name Type Description Default <code>acmg</code> <code>str</code> <p>ACMG pathogenicity level</p> <code>None</code> Source code in <code>pyphetools/creation/variant.py</code> <pre><code>@abc.abstractmethod\ndef to_ga4gh_variant_interpretation(self, acmg=None):\n    \"\"\"\n    Embed the variant object into a GA4GH Genomic Interpretation object (abstract method)\n\n    The argument acmg must be one of the strings 'benign', 'likely_benign', 'uncertain_significance',\n        'likely_pathogenic', or 'pathogenic' (underscores are optional). If it is not provided or\n        not one of these strings, the level will be set to not available\n\n    :param acmg: ACMG pathogenicity level\n    :type acmg: str\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/creation/variant_column_mapper/","title":"VariantColumnMapper","text":"<p>Column mapper for the variants identified in individuals</p> <p>To use this mapper, first create a dictionary with all variants in the cohort using the VariantValidator (for HGVS) and the StructuralVariant classes. The key to the variant is the cell contents of the column with variant information in the original table. The Values are the Variant objects (implemented as HgvsVariant or StructuralVariant). This mapper will split cells that contain multiple variants if needed and also will add genotype information.</p> <p>Parameters:</p> Name Type Description Default <code>variant_d</code> <code>Dict[str,Variant]</code> <p>Dictionary with all variants found in the column</p> required <code>variant_column_name</code> <code>str</code> <p>name of the variant column in the original table</p> required <code>genotype_column_name</code> <code>str</code> <p>name of the genotype column in the original table, optional</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>symbol used to separate variants if more than one variant is provided, optional</p> <code>None</code> Source code in <code>pyphetools/creation/variant_column_mapper.py</code> <pre><code>class VariantColumnMapper:\n    \"\"\"Column mapper for the variants identified in individuals\n\n    To use this mapper, first create a dictionary with all variants in the cohort using the\n    VariantValidator (for HGVS) and the StructuralVariant classes. The key to the variant is\n    the cell contents of the column with variant information in the original table. The Values\n    are the Variant objects (implemented as HgvsVariant or StructuralVariant). This mapper will\n    split cells that contain multiple variants if needed and also will add genotype information.\n\n    :param variant_d: Dictionary with all variants found in the column\n    :type variant_d: Dict[str,Variant]\n    :param variant_column_name: name of the variant column in the original table\n    :type variant_column_name: str\n    :param genotype_column_name: name of the genotype column in the original table, optional\n    :type genotype_column_name: str\n    :param delimiter: symbol used to separate variants if more than one variant is provided, optional\n    :type delimiter: str\n    \"\"\"\n    def __init__(self,\n                variant_d,\n                variant_column_name,\n                genotype_column_name=None,\n                default_genotype=None,\n                delimiter=None) -&gt; None:\n\n        if default_genotype is not None and default_genotype not in ACCEPTABLE_GENOTYPES:\n            raise ValueError(f\"Did not recognize default genotype {default_genotype}\")\n        if not isinstance(variant_d, dict):\n            raise ValueError(f\"Argument variant_d must be a dictionary but was {type(variant_d)}\")\n        self._variant_d = variant_d\n        self._default_genotype = default_genotype\n        self._variant_column_name = variant_column_name\n        self._genotype_column_name = genotype_column_name\n        self._delimiter = delimiter\n\n\n    def _get_genotype(self, genotype_contents):\n        \"\"\"\n        Get a genotype string\n\n        get the genotype from the argument (which comes from the genotype column if available) or from the\n        default genotype.\n        :returns: one of \"heterozygous\", \"homozygous\", \"hemizygous\", None\n        \"\"\"\n        if genotype_contents is not None and genotype_contents.lower() in ACCEPTABLE_GENOTYPES:\n            return genotype_contents.lower()\n        else:\n            return self._default_genotype\n\n\n    def map_cell(self, cell_contents, genotype_contents=None, delimiter=None) -&gt; List[Variant]:\n        \"\"\"\n        Map the contents of a variant cell (and optionally a genotype cell).\n\n        If the delimiter is not None, search for the delimiter and split the cell into two variants\n        :param cell_contents: contents of the original table cell representing the variant string\n        :type cell_contents: str\n        :param genotype_contents: contents of the original table cell representing the genotype (allelic status), optional\n        :type genotype_contents: str\n        :param delimiter: string or character that splits the cell contents into multiple entries, e.g., \";\", optional\n        :type delimiter: str\n        \"\"\"\n        if delimiter is None:\n            delimiter = self._delimiter\n        if delimiter is not None:\n            items = [x.strip() for x in cell_contents.split(delimiter)]\n        else:\n            items = [cell_contents]\n        variant_interpretation_list = []\n        for item in items:\n            if item in self._variant_d:\n                variant: Variant = self._variant_d.get(item)\n                gt = self._get_genotype(genotype_contents)\n                if gt is not None:\n                    variant.set_genotype(gt)\n                interpretation = variant.to_ga4gh_variant_interpretation()\n                variant_interpretation_list.append(interpretation)\n            else:\n                raise ValueError(f\"Did not recognize variant string \\\"{item}\\\"\")\n\n        return variant_interpretation_list\n\n\n\n    def preview_column(self, column) -&gt; pd.DataFrame:\n        if not isinstance(column, pd.Series):\n            raise ValueError(\"column argument must be pandas Series, but was {type(column)}\")\n        dlist = []\n        for _, value in column.items():\n            variant_interpretation_list = self.map_cell(str(value))\n            if len(variant_interpretation_list) == 0:\n                dlist.append({\"variant\": \"n/a\"})\n            else:\n                result_strings = []\n                for v in variant_interpretation_list:\n                    result_strings.append(v.__str__())\n                dlist.append({\"variant\": \": \".join(result_strings)})\n        return pd.DataFrame(dlist)\n\n    def get_variant_column_name(self):\n        return self._variant_column_name\n\n    def get_genotype_colname(self):\n        return self._genotype_column_name\n</code></pre>"},{"location":"api/creation/variant_column_mapper/#pyphetools.creation.VariantColumnMapper.map_cell","title":"<code>map_cell(cell_contents, genotype_contents=None, delimiter=None)</code>","text":"<p>Map the contents of a variant cell (and optionally a genotype cell).</p> <p>If the delimiter is not None, search for the delimiter and split the cell into two variants</p> <p>Parameters:</p> Name Type Description Default <code>cell_contents</code> <code>str</code> <p>contents of the original table cell representing the variant string</p> required <code>genotype_contents</code> <code>str</code> <p>contents of the original table cell representing the genotype (allelic status), optional</p> <code>None</code> <code>delimiter</code> <code>str</code> <p>string or character that splits the cell contents into multiple entries, e.g., \";\", optional</p> <code>None</code> Source code in <code>pyphetools/creation/variant_column_mapper.py</code> <pre><code>def map_cell(self, cell_contents, genotype_contents=None, delimiter=None) -&gt; List[Variant]:\n    \"\"\"\n    Map the contents of a variant cell (and optionally a genotype cell).\n\n    If the delimiter is not None, search for the delimiter and split the cell into two variants\n    :param cell_contents: contents of the original table cell representing the variant string\n    :type cell_contents: str\n    :param genotype_contents: contents of the original table cell representing the genotype (allelic status), optional\n    :type genotype_contents: str\n    :param delimiter: string or character that splits the cell contents into multiple entries, e.g., \";\", optional\n    :type delimiter: str\n    \"\"\"\n    if delimiter is None:\n        delimiter = self._delimiter\n    if delimiter is not None:\n        items = [x.strip() for x in cell_contents.split(delimiter)]\n    else:\n        items = [cell_contents]\n    variant_interpretation_list = []\n    for item in items:\n        if item in self._variant_d:\n            variant: Variant = self._variant_d.get(item)\n            gt = self._get_genotype(genotype_contents)\n            if gt is not None:\n                variant.set_genotype(gt)\n            interpretation = variant.to_ga4gh_variant_interpretation()\n            variant_interpretation_list.append(interpretation)\n        else:\n            raise ValueError(f\"Did not recognize variant string \\\"{item}\\\"\")\n\n    return variant_interpretation_list\n</code></pre>"},{"location":"api/creation/variant_manager/","title":"VariantManager","text":"<p>This class is designed to extract Variant objects from a pandas DataFrame that represents the input data. It will work out of the box for dataframes created by the CaseTemplateEncoder, and can be adapted to work with other datasets. The assumption is that there is one column per allele. For autosomal dominant, there would thus be one column. For recessive, there would be two columns. We do not try to automatically map non-HGVS (i.e., chromosomal variants). Instead, we first map HGVS using VariantValidator, and then we return a Pandas DataFrame that shows the other variants. These can be use to create chromosomal deletions, duplications, and inversions. Finally, the class can be used to add variants to a list of Individual objects.</p> <p>If the Excel template is used, this class will be called internally and users do not need to use the code. If the  data is ingested manually, the class can be used as follows.</p> <pre><code>gnas_symbol = \"GNAS\"\ngnas_id = \"HGNC:4392\"\ngnas_MANE_transcript = \"NM_000516.7\"\nvmanager = VariantManager(df=df, \n                  individual_column_name=\"individual\", \n                  transcript=gnas_MANE_transcript, \n                  gene_id=gnas_id, \n                  gene_symbol=gnas_symbol, \n                  allele_1_column_name=\"allele_1\")\n</code></pre> <p>See also variant_manager.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>DataFrame representing the input data</p> required <code>individual_column_name</code> <code>str</code> <p>Name of the individual (patient) column</p> required <code>transcript</code> <code>str</code> <p>accession number and version of the transcript, e.g., \"NM_000342.3\"</p> required <code>allele_1_column_name</code> <code>str</code> <p>name of the column with alleles (#1)</p> required <code>allele_2_column_name</code> <code>str</code> <p>name of the column with alleles (#2), optional</p> <code>None</code> <code>gene_symbol</code> <code>str</code> <p>Symbol of affected gene (only required if chromosomal variants need to be coded)</p> required <code>gene_id</code> <code>str</code> <p>HGNC identifier of affected gene (only required if chromosomal variants need to be coded)</p> <code>None</code> Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>class VariantManager:\n    \"\"\"This class is designed to extract Variant objects from a pandas DataFrame that represents the input data.\n    It will work out of the box for dataframes created by the CaseTemplateEncoder, and can be adapted to work\n    with other datasets. The assumption is that there is one column per allele. For autosomal dominant, there would\n    thus be one column. For recessive, there would be two columns. We do not try to automatically map non-HGVS (i.e.,\n    chromosomal variants). Instead, we first map HGVS using VariantValidator, and then we return a Pandas DataFrame that\n    shows the other variants. These can be use to create chromosomal deletions, duplications, and inversions. Finally,\n    the class can be used to add variants to a list of Individual objects.\n\n    If the Excel template is used, this class will be called internally and users do not need to use the code. If the \n    data is ingested manually, the class can be used as follows.\n\n        gnas_symbol = \"GNAS\"\n        gnas_id = \"HGNC:4392\"\n        gnas_MANE_transcript = \"NM_000516.7\"\n        vmanager = VariantManager(df=df, \n                          individual_column_name=\"individual\", \n                          transcript=gnas_MANE_transcript, \n                          gene_id=gnas_id, \n                          gene_symbol=gnas_symbol, \n                          allele_1_column_name=\"allele_1\")\n\n    See also [variant_manager](https://monarch-initiative.github.io/pyphetools/api/creation/variant_manager/).\n\n    :param df: DataFrame representing the input data\n    :type df: pd.DataFrame\n    :param individual_column_name: Name of the individual (patient) column\n    :type individual_column_name: str\n    :param transcript: accession number and version of the transcript, e.g., \"NM_000342.3\"\n    :type transcript: str\n    :param allele_1_column_name: name of the column with alleles (#1)\n    :type allele_1_column_name: str\n    :param allele_2_column_name: name of the column with alleles (#2), optional\n    :type allele_2_column_name: str\n    :param gene_symbol: Symbol of affected gene (only required if chromosomal variants need to be coded)\n    :type gene_symbol: str\n    :param gene_id: HGNC identifier of affected gene (only required if chromosomal variants need to be coded)\n    :type gene_id: str\n    \"\"\"\n\n    def __init__(self,\n                 df: pd.DataFrame,\n                 individual_column_name: str,\n                 transcript: str,\n                 gene_symbol: str,\n                 allele_1_column_name: str,\n                 allele_2_column_name: str = None,\n                 gene_id: str = None,\n                 overwrite: bool = False\n                 ):\n        if not isinstance(df, pd.DataFrame):\n            raise ValueError(f\"The \\\"df\\\" argument must be a pandas DataFrame but was {type(df)}\")\n        if individual_column_name not in df.columns:\n            raise ValueError(f\"The \\\"individual_column_name\\\" argument must be a a column in df (a pandas DataFrame)\")\n        if allele_1_column_name not in df.columns:\n            raise ValueError(f\"The \\\"allele_1_column_name\\\" argument must be a a column in df (a pandas DataFrame)\")\n        if allele_2_column_name is not None and allele_2_column_name not in df.columns:\n            raise ValueError(\n                f\"If not None, the \\\"allele_2_column_name\\\" argument must be a a column in df (a pandas DataFrame)\")\n        self._dataframe = df\n        self._individual_column_name = individual_column_name\n        self._transcript = transcript\n        self._allele_1_column_name = allele_1_column_name\n        self._allele_2_column_name = allele_2_column_name\n        self._gene_symbol = gene_symbol\n        self._gene_id = gene_id\n        self._var_d = {}\n        self._unmapped_alleles = set()\n        self._individual_to_alleles_d = defaultdict(list)\n        if \"PMID\" in df.columns:\n            self._pmid_column_name = \"PMID\"\n        else:\n            self._pmid_column_name = None\n        self._create_variant_d(overwrite)\n\n    def _format_pmid_id(self, identifier, pmid) -&gt; str:\n        if pmid is not None:\n            return f\"{pmid}_{identifier}\"\n        else:\n            return identifier\n\n    def _get_identifier_with_pmid(self, row: pd.Series) -&gt; str:\n        \"\"\"Get an identifier such as PMID_33087723_A2 for a daa row with PMID:33087723 and identifier within that publication A2\n\n        Identifiers such as P1 are commonly used and there is a risk of a clash with collections of phenopackets from various papers.\n        Therefore, we use an identifier such as PMID_33087723_A2 if we can find a PMID\n        \"\"\"\n        individual_id = row[self._individual_column_name]\n        individual_id = str(individual_id)  # prevent automatic conversion into int for patient id 1, 2, 3 etc\n        if self._pmid_column_name is not None:\n            return self._format_pmid_id(identifier=individual_id, pmid=row[self._pmid_column_name])\n        else:\n            return individual_id\n\n    def _create_variant_d(self, overwrite) -&gt; None:\n        \"\"\"\n        Creates a dictionary with all HGVS variants, and as a side effect creates a set with variants that\n        are not HGVS and need to be mapped manually. This method has the following effects\n        - self._var_d, a dictionary, is filled with key: HGVS strings, value: corresponding Variant objects\n        - self._unmapped_alleles: set of all alleles that do not start eith \"c.\" (non HGVS), that will need intervention by the user to map\n        - self._individual_to_alleles_d: key individual ID, value-one or two element list of allele strings\n        \"\"\"\n        if overwrite:\n            v_d = {}\n        else:\n            v_d = load_variant_pickle(self._gene_symbol)\n        if v_d is None:\n            self._var_d = {}\n        else:\n            self._var_d = v_d\n        genome_assembly = \"hg38\"  # Nothing else is good enough, sorry hg19\n        variant_set = set()  # we expect HGVS nomenclature. Everything else will be parsed as chromosomal\n        vvalidator = VariantValidator(genome_build=genome_assembly, transcript=self._transcript)\n        # The DataFrame has two header rows.\n        # For CaseTemplateEncoder, the second header row is the first row of the DataFrame, so we drop it here.\n        # For CaseTemplateEncoder, the second row will contain \"str\" in the second row of the PMID column\n        # For other encoders, there may not be a \"PMID\" column, and if so it will not contain \"CURIE\" in the second row\n        if \"PMID\" in self._dataframe.columns and self._dataframe.iloc[0][\"PMID\"] == \"CURIE\":\n            df = self._dataframe.iloc[1:]\n        else:\n            df = self._dataframe\n        for _, row in df.iterrows():\n            individual_id = self._get_identifier_with_pmid(row=row)\n            allele1 = row[self._allele_1_column_name]\n            if allele1.startswith(\" \") or allele1.endswith(\" \"):\n                raise ValueError(f\"Malformed allele_1 description that starts/ends with whitespace: \\\"{allele1}\\\".\")\n            self._individual_to_alleles_d[individual_id].append(allele1)\n            # take mRNA (c.) or noncoding RNA (n.)\n            if allele1.startswith(\"c.\") or allele1.startswith(\"n.\"):\n                variant_set.add(allele1)\n            else:\n                self._unmapped_alleles.add(allele1)\n            if self._allele_2_column_name is not None:\n                allele2 = row[self._allele_2_column_name]\n                if allele2 is None:\n                    continue\n                if allele2 == \"na\" or allele2 == \"n/a\":\n                    continue\n                self._individual_to_alleles_d[individual_id].append(allele2)\n                if allele2.startswith(\" \") or allele2.endswith(\" \"):\n                    raise ValueError(f\"Malformed allele_2 description that starts/ends with whitespace: \\\"{allele2}\\\".\")\n                if allele2.startswith(\"c.\") or allele2.startswith(\"n.\"):\n                    variant_set.add(allele2)\n                else:\n                    self._unmapped_alleles.add(allele2)\n        for v in variant_set:\n            if v in self._var_d:\n                continue\n            if v == \"na\" or v == \"n/a\":\n                continue\n            print(f\"[INFO] encoding variant \\\"{v}\\\"\")\n            try:\n                var = vvalidator.encode_hgvs(v)\n                self._var_d[v] = var\n            except Exception as e:\n                print(f\"[ERROR] Could not retrieve Variant Validator information for {v}: {str(e)}\")\n                self._unmapped_alleles.add(v)  # This allows us to use the chromosomal mappers.\n        write_variant_pickle(name=self._gene_symbol, my_object=self._var_d)\n\n    def code_as_chromosomal_deletion(self, allele_set) -&gt; None:\n        \"\"\"\n        Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal deletion)\n        :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal deletion)\n        \"\"\"\n        # first check that all of the alleles are in self._unmapped_alleles\n        if not allele_set.issubset(self._unmapped_alleles):\n            for a in allele_set:\n                if not a in self._unmapped_alleles:\n                    print(f\"Could not find allele \\\"{a}\\\"\")\n            raise ValueError(\n                \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n        if self._gene_id is None or self._gene_symbol is None:\n            raise ValueError(\n                \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n        for allele in allele_set:\n            var = StructuralVariant.chromosomal_deletion(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                         gene_id=self._gene_id)\n            self._unmapped_alleles.remove(allele)\n            self._var_d[allele] = var\n\n    def code_as_chromosomal_duplication(self, allele_set) -&gt; None:\n        \"\"\"\n        Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal duplication)\n        :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal duplication)\n        \"\"\"\n        # first check that all of the alleles are in self._unmapped_alleles\n        if not allele_set.issubset(self._unmapped_alleles):\n            raise ValueError(\n                \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n        if self._gene_id is None or self._gene_symbol is None:\n            raise ValueError(\n                \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n        for allele in allele_set:\n            var = StructuralVariant.chromosomal_duplication(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                            gene_id=self._gene_id)\n            self._unmapped_alleles.remove(allele)\n            self._var_d[allele] = var\n\n    def code_as_chromosomal_inversion(self, allele_set) -&gt; None:\n        \"\"\"\n        Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal inversion)\n        :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal inversion)\n        \"\"\"\n        # first check that all of the alleles are in self._unmapped_alleles\n        if not allele_set.issubset(self._unmapped_alleles):\n            raise ValueError(\n                \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n        if self._gene_id is None or self._gene_symbol is None:\n            raise ValueError(\n                \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n        for allele in allele_set:\n            var = StructuralVariant.chromosomal_inversion(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                          gene_id=self._gene_id)\n            self._unmapped_alleles.remove(allele)\n            self._var_d[allele] = var\n\n    def code_as_chromosomal_translocation(self, allele_set) -&gt; None:\n        \"\"\"\n        Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal translocation)\n        :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal translocation)\n        \"\"\"\n        # first check that all of the alleles are in self._unmapped_alleles\n        if not allele_set.issubset(self._unmapped_alleles):\n            raise ValueError(\n                \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n        if self._gene_id is None or self._gene_symbol is None:\n            raise ValueError(\n                \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n        for allele in allele_set:\n            var = StructuralVariant.chromosomal_translocation(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                              gene_id=self._gene_id)\n            self._unmapped_alleles.remove(allele)\n            self._var_d[allele] = var\n\n    def to_summary(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Create and return a DataFrame with current status of mapping efforts. The resulting dataframe can be used to\n        check mapping and to retrieve the allele strings that could not be mapped (and therefore probably need to\n        be mapped with one of the chromosomal methods)\n        \"\"\"\n        dlist = []\n        n_mapped = len(self._var_d)\n        mapped_alleles = \", \".join(self._var_d.keys())\n        d = {\"status\": \"mapped\", \"count\": n_mapped, \"alleles\": mapped_alleles}\n        dlist.append(d)\n        n_unmapped = len(self._unmapped_alleles)\n        unmapped_alleles = \", \".join(self._unmapped_alleles)\n        for allele in self._unmapped_alleles:\n            if allele != allele.strip():\n                unmapped_alleles = f\"{unmapped_alleles}; warning \\\"{allele}\\\" has extra white space - check format\"\n        d = {\"status\": \"unmapped\", \"count\": n_unmapped, \"alleles\": unmapped_alleles}\n        dlist.append(d)\n        return pd.DataFrame(dlist)\n\n    def has_unmapped_alleles(self):\n        return len(self._unmapped_alleles) &gt; 0\n\n    def get_unmapped_alleles(self):\n        return self._unmapped_alleles\n\n    def get_mapped_allele_count(self):\n        return len(self._var_d)\n\n    def add_variants_to_individuals(self, individual_list: List[Individual], hemizygous: bool = False):\n        \"\"\"\n        Add Variant objects to individuals. Here, we use the map self._individual_to_alleles_d that\n        relates the individual IDs to the allele strings in the original data, together with the\n        map self._var_d, which relates the allele strings to Variant objects. If anything is missing, then\n        we raise an Exception. Note currently this method cannot be used for X-dominant MOI.\n        :param individual_list: list of Individuals to which we will add Variant objects\n        :type individual_list: List[Individual]\n        :param hemizygous: If True, this is an X-chromosomal gene and we assume hemizygous\n        :type hemizygous: bool\n        \"\"\"\n        if len(self._unmapped_alleles) &gt; 0:\n            raise ValueError(f\"Need to map all allele strings before using this method but \"\n                             f\"{len(self._unmapped_alleles)} were unmapped. Try variantManager.to_summary()\")\n        for i in individual_list:\n            citation = i.get_citation()\n            if citation is not None:\n                pmid = citation.pmid\n                individual_id = self._format_pmid_id(identifier=i.id, pmid=pmid)\n            else:\n                individual_id = self._format_pmid_id(identifier=i.id, pmid=None)\n            if individual_id not in self._individual_to_alleles_d:\n                raise ValueError(\n                    f\"Did not find {i.id} in our dictionary of individuals. Note that this function is intended to work with CaseTemplateEncoder\")\n            vlist = self._individual_to_alleles_d.get(individual_id)\n            if len(vlist) == 1:\n                # assume monoallelic\n                v = vlist[0]\n                if v not in self._var_d:\n                    raise ValueError(f\"Could not find {v} in variant dictionary\")\n                var = self._var_d.get(v)\n                if hemizygous:\n                    var.set_hemizygous()\n                else:\n                    var.set_heterozygous()\n                i.add_variant(var)\n            elif len(vlist) == 2:\n                if hemizygous:\n                    raise ValueError(\"hemizygous argument set to True in present of two alleles\")\n                # assume biallelic\n                v1 = vlist[0]\n                v2 = vlist[1]\n                if v1 not in self._var_d:\n                    raise ValueError(f\"Could not find {v1} in variant dictionary\")\n                if v2 not in self._var_d:\n                    raise ValueError(f\"Could not find {v2} in variant dictionary\")\n                if v1 == v2:\n                    var = self._var_d.get(v1)\n                    var.set_homozygous()\n                    i.add_variant(var)\n                else:\n                    var1 = self._var_d.get(v1)\n                    var1.set_heterozygous()\n                    i.add_variant(var1)\n                    var2 = self._var_d.get(v2)\n                    var2.set_heterozygous()\n                    i.add_variant(var2)\n\n    def get_var(self, v):\n        \"\"\"Get a Variant object that corresponds to v.\n\n        :param v: an HGVS string or free-text representation of a chromosomal variant\n        :type v: str\n        :returns: corresponding Variant\n        :rtype: Variant\n        \"\"\"\n        return self._var_d.get(v)\n\n    def get_variant_d(self):\n        \"\"\"\n        :returns:dictionary with key: original string for allele, value: Variant object\n        :rtype: Dict[str, Variant]\n        \"\"\"\n        return self._var_d\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.add_variants_to_individuals","title":"<code>add_variants_to_individuals(individual_list, hemizygous=False)</code>","text":"<p>Add Variant objects to individuals. Here, we use the map self._individual_to_alleles_d that relates the individual IDs to the allele strings in the original data, together with the map self._var_d, which relates the allele strings to Variant objects. If anything is missing, then we raise an Exception. Note currently this method cannot be used for X-dominant MOI.</p> <p>Parameters:</p> Name Type Description Default <code>individual_list</code> <code>List[Individual]</code> <p>list of Individuals to which we will add Variant objects</p> required <code>hemizygous</code> <code>bool</code> <p>If True, this is an X-chromosomal gene and we assume hemizygous</p> <code>False</code> Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def add_variants_to_individuals(self, individual_list: List[Individual], hemizygous: bool = False):\n    \"\"\"\n    Add Variant objects to individuals. Here, we use the map self._individual_to_alleles_d that\n    relates the individual IDs to the allele strings in the original data, together with the\n    map self._var_d, which relates the allele strings to Variant objects. If anything is missing, then\n    we raise an Exception. Note currently this method cannot be used for X-dominant MOI.\n    :param individual_list: list of Individuals to which we will add Variant objects\n    :type individual_list: List[Individual]\n    :param hemizygous: If True, this is an X-chromosomal gene and we assume hemizygous\n    :type hemizygous: bool\n    \"\"\"\n    if len(self._unmapped_alleles) &gt; 0:\n        raise ValueError(f\"Need to map all allele strings before using this method but \"\n                         f\"{len(self._unmapped_alleles)} were unmapped. Try variantManager.to_summary()\")\n    for i in individual_list:\n        citation = i.get_citation()\n        if citation is not None:\n            pmid = citation.pmid\n            individual_id = self._format_pmid_id(identifier=i.id, pmid=pmid)\n        else:\n            individual_id = self._format_pmid_id(identifier=i.id, pmid=None)\n        if individual_id not in self._individual_to_alleles_d:\n            raise ValueError(\n                f\"Did not find {i.id} in our dictionary of individuals. Note that this function is intended to work with CaseTemplateEncoder\")\n        vlist = self._individual_to_alleles_d.get(individual_id)\n        if len(vlist) == 1:\n            # assume monoallelic\n            v = vlist[0]\n            if v not in self._var_d:\n                raise ValueError(f\"Could not find {v} in variant dictionary\")\n            var = self._var_d.get(v)\n            if hemizygous:\n                var.set_hemizygous()\n            else:\n                var.set_heterozygous()\n            i.add_variant(var)\n        elif len(vlist) == 2:\n            if hemizygous:\n                raise ValueError(\"hemizygous argument set to True in present of two alleles\")\n            # assume biallelic\n            v1 = vlist[0]\n            v2 = vlist[1]\n            if v1 not in self._var_d:\n                raise ValueError(f\"Could not find {v1} in variant dictionary\")\n            if v2 not in self._var_d:\n                raise ValueError(f\"Could not find {v2} in variant dictionary\")\n            if v1 == v2:\n                var = self._var_d.get(v1)\n                var.set_homozygous()\n                i.add_variant(var)\n            else:\n                var1 = self._var_d.get(v1)\n                var1.set_heterozygous()\n                i.add_variant(var1)\n                var2 = self._var_d.get(v2)\n                var2.set_heterozygous()\n                i.add_variant(var2)\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.code_as_chromosomal_deletion","title":"<code>code_as_chromosomal_deletion(allele_set)</code>","text":"<p>Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal deletion)</p> <p>Parameters:</p> Name Type Description Default <code>allele_set</code> <p>Set of alleles (strings) for coding as Structural variants (chromosomal deletion)</p> required Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def code_as_chromosomal_deletion(self, allele_set) -&gt; None:\n    \"\"\"\n    Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal deletion)\n    :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal deletion)\n    \"\"\"\n    # first check that all of the alleles are in self._unmapped_alleles\n    if not allele_set.issubset(self._unmapped_alleles):\n        for a in allele_set:\n            if not a in self._unmapped_alleles:\n                print(f\"Could not find allele \\\"{a}\\\"\")\n        raise ValueError(\n            \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n    if self._gene_id is None or self._gene_symbol is None:\n        raise ValueError(\n            \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n    for allele in allele_set:\n        var = StructuralVariant.chromosomal_deletion(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                     gene_id=self._gene_id)\n        self._unmapped_alleles.remove(allele)\n        self._var_d[allele] = var\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.code_as_chromosomal_duplication","title":"<code>code_as_chromosomal_duplication(allele_set)</code>","text":"<p>Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal duplication)</p> <p>Parameters:</p> Name Type Description Default <code>allele_set</code> <p>Set of alleles (strings) for coding as Structural variants (chromosomal duplication)</p> required Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def code_as_chromosomal_duplication(self, allele_set) -&gt; None:\n    \"\"\"\n    Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal duplication)\n    :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal duplication)\n    \"\"\"\n    # first check that all of the alleles are in self._unmapped_alleles\n    if not allele_set.issubset(self._unmapped_alleles):\n        raise ValueError(\n            \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n    if self._gene_id is None or self._gene_symbol is None:\n        raise ValueError(\n            \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n    for allele in allele_set:\n        var = StructuralVariant.chromosomal_duplication(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                        gene_id=self._gene_id)\n        self._unmapped_alleles.remove(allele)\n        self._var_d[allele] = var\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.code_as_chromosomal_inversion","title":"<code>code_as_chromosomal_inversion(allele_set)</code>","text":"<p>Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal inversion)</p> <p>Parameters:</p> Name Type Description Default <code>allele_set</code> <p>Set of alleles (strings) for coding as Structural variants (chromosomal inversion)</p> required Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def code_as_chromosomal_inversion(self, allele_set) -&gt; None:\n    \"\"\"\n    Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal inversion)\n    :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal inversion)\n    \"\"\"\n    # first check that all of the alleles are in self._unmapped_alleles\n    if not allele_set.issubset(self._unmapped_alleles):\n        raise ValueError(\n            \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n    if self._gene_id is None or self._gene_symbol is None:\n        raise ValueError(\n            \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n    for allele in allele_set:\n        var = StructuralVariant.chromosomal_inversion(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                      gene_id=self._gene_id)\n        self._unmapped_alleles.remove(allele)\n        self._var_d[allele] = var\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.code_as_chromosomal_translocation","title":"<code>code_as_chromosomal_translocation(allele_set)</code>","text":"<p>Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal translocation)</p> <p>Parameters:</p> Name Type Description Default <code>allele_set</code> <p>Set of alleles (strings) for coding as Structural variants (chromosomal translocation)</p> required Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def code_as_chromosomal_translocation(self, allele_set) -&gt; None:\n    \"\"\"\n    Code variants with the identifiers in \"allele_set\" as Structural variants (chromosomal translocation)\n    :param allele_set: Set of alleles (strings) for coding as Structural variants (chromosomal translocation)\n    \"\"\"\n    # first check that all of the alleles are in self._unmapped_alleles\n    if not allele_set.issubset(self._unmapped_alleles):\n        raise ValueError(\n            \"[ERROR] We can only map alleles that were passed to the constructor - are you trying to map \\\"new\\\" alleles?\")\n    if self._gene_id is None or self._gene_symbol is None:\n        raise ValueError(\n            \"[ERROR] We cannot use this method unless the gene ID (HGNC) and symbol were passed to the constructor\")\n    for allele in allele_set:\n        var = StructuralVariant.chromosomal_translocation(cell_contents=allele, gene_symbol=self._gene_symbol,\n                                                          gene_id=self._gene_id)\n        self._unmapped_alleles.remove(allele)\n        self._var_d[allele] = var\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.get_var","title":"<code>get_var(v)</code>","text":"<p>Get a Variant object that corresponds to v.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <code>str</code> <p>an HGVS string or free-text representation of a chromosomal variant</p> required <p>Returns:</p> Type Description <code>Variant</code> <p>corresponding Variant</p> Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def get_var(self, v):\n    \"\"\"Get a Variant object that corresponds to v.\n\n    :param v: an HGVS string or free-text representation of a chromosomal variant\n    :type v: str\n    :returns: corresponding Variant\n    :rtype: Variant\n    \"\"\"\n    return self._var_d.get(v)\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.get_variant_d","title":"<code>get_variant_d()</code>","text":"<p>Returns:</p> Type Description <code>Dict[str, Variant]</code> <p>dictionary with key: original string for allele, value: Variant object</p> Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def get_variant_d(self):\n    \"\"\"\n    :returns:dictionary with key: original string for allele, value: Variant object\n    :rtype: Dict[str, Variant]\n    \"\"\"\n    return self._var_d\n</code></pre>"},{"location":"api/creation/variant_manager/#pyphetools.creation.VariantManager.to_summary","title":"<code>to_summary()</code>","text":"<p>Create and return a DataFrame with current status of mapping efforts. The resulting dataframe can be used to check mapping and to retrieve the allele strings that could not be mapped (and therefore probably need to be mapped with one of the chromosomal methods)</p> Source code in <code>pyphetools/creation/variant_manager.py</code> <pre><code>def to_summary(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Create and return a DataFrame with current status of mapping efforts. The resulting dataframe can be used to\n    check mapping and to retrieve the allele strings that could not be mapped (and therefore probably need to\n    be mapped with one of the chromosomal methods)\n    \"\"\"\n    dlist = []\n    n_mapped = len(self._var_d)\n    mapped_alleles = \", \".join(self._var_d.keys())\n    d = {\"status\": \"mapped\", \"count\": n_mapped, \"alleles\": mapped_alleles}\n    dlist.append(d)\n    n_unmapped = len(self._unmapped_alleles)\n    unmapped_alleles = \", \".join(self._unmapped_alleles)\n    for allele in self._unmapped_alleles:\n        if allele != allele.strip():\n            unmapped_alleles = f\"{unmapped_alleles}; warning \\\"{allele}\\\" has extra white space - check format\"\n    d = {\"status\": \"unmapped\", \"count\": n_unmapped, \"alleles\": unmapped_alleles}\n    dlist.append(d)\n    return pd.DataFrame(dlist)\n</code></pre>"},{"location":"api/creation/variant_validator/","title":"VariantValidator","text":"<p>Check and Encode HGVS string</p> <p>The default mRNA transcript for the HGVS strings should be added in the constructor byt can be overridden in the encode_hgvs method.</p> <p>Parameters:</p> Name Type Description Default <code>genome_build</code> <code>str</code> <p>The genome assembly, one of \"GRCh37\", \"GRCh38\", \"hg19\", \"hg38\"</p> required <code>transcript</code> <code>str</code> <p>An mRNA transcript that is the reference for the HGVS string, opt</p> <code>None</code> Source code in <code>pyphetools/creation/variant_validator.py</code> <pre><code>class VariantValidator:\n    \"\"\"\n    Check and Encode HGVS string\n\n    The default mRNA transcript for the HGVS strings should be added in the constructor byt can be overridden in the\n    encode_hgvs method.\n\n    :param genome_build: The genome assembly, one of \"GRCh37\", \"GRCh38\", \"hg19\", \"hg38\"\n    :type genome_build: str\n    :param transcript: An mRNA transcript that is the reference for the HGVS string, opt\n    :type transcript: str\n    \"\"\"\n\n    def __init__(self, genome_build, transcript=None):\n        \"\"\"\n        Constructor\n        \"\"\"\n        if genome_build not in ACCEPTABLE_GENOMES:\n            raise ValueError(f\"genome_build \\\"{genome_build}\\\" not recognized\")\n        self._genome_assembly = genome_build\n        self._transcript = transcript\n\n    def encode_hgvs(self, hgvs, custom_transcript=None):\n        \"\"\"\n        Encode an HGVS string as a pyphetools Variant object\n\n        :param hgvs: Human Genome Variation Society (HGVS) representation of a variant, e.g., c.36613706dup\n        :type hgvs: str\n        :param custom_transcript: a transcript (e.g., NM_001848.2), if different from the default transcript, optional\n        :type custom_transcript: str\n        :returns: pyphetools Variant object\n        :rtype: HgvsVariant\n        \"\"\"\n        if custom_transcript is not None:\n            transcript = custom_transcript\n        elif self._transcript is not None:\n            transcript = self._transcript\n        else:\n            raise ValueError(\"Cannot run variant validator without transcript\")\n        api_url = URL_SCHEME % (self._genome_assembly, transcript, hgvs, transcript)\n        #f\"https://rest.variantvalidator.org/VariantValidator/variantvalidator/{self._genome_assembly}/{transcript}%3A{hgvs}/{transcript}\"\n        #\n        print(api_url)\n        response = requests.get(api_url)\n        # We expect to get a dictionary with three keys. The first is the name of the variant, e.g., ACC:HGVS, then we\n        # get flag and metadata\n        vv_dict = response.json()\n        if 'flag' in vv_dict:\n            if vv_dict['flag'] != 'gene_variant':\n                flag = vv_dict['flag']\n                raise ValueError(f\"Expecting to get a gene_variant from Variant Validator but got {flag}\")\n        # This is the easiest way to get the variant key, which may contain difficult characters\n        variant_key = [k for k in vv_dict.keys() if k not in {'flag', 'metadata'}][0]\n        var = vv_dict[variant_key]\n        hgnc = None\n        if 'gene_ids' in var and 'hgnc_id' in var['gene_ids']:\n            hgnc = var['gene_ids']['hgnc_id']\n        symbol = None\n        if 'gene_symbol' in var:\n            symbol = var['gene_symbol']\n        assemblies = var['primary_assembly_loci']\n        if not self._genome_assembly in assemblies:\n            raise ValueError(f\"Could not identified {self._genome_assembly} in Variant Validator response\")\n        assembly = assemblies[self._genome_assembly]\n        hgvs_transcript_var = var.get('hgvs_transcript_variant', None)\n        genomic_hgvs = assembly.get('hgvs_genomic_description', None)\n        reference_sequence_records = var.get('reference_sequence_records', None)\n        if reference_sequence_records is not None:\n            transcript = reference_sequence_records['transcript']\n            if transcript.startswith('https://www.ncbi.nlm.nih.gov/nuccore/'):\n                transcript = transcript[37:]\n        else:\n            transcript = None\n        # 'vcf': {'alt': 'C', 'chr': '16', 'pos': '1756403', 'ref': 'CG'}},\n        if not 'vcf' in assembly:\n            raise ValueError(f\"Could not identify vcf element in Variant Validator genome assembly response\")\n        return HgvsVariant(assembly=self._genome_assembly, vcf_d=assembly['vcf'], symbol=symbol,\n                        hgnc=hgnc, transcript=transcript, hgvs=hgvs_transcript_var, g_hgvs=genomic_hgvs)\n</code></pre>"},{"location":"api/creation/variant_validator/#pyphetools.creation.VariantValidator.__init__","title":"<code>__init__(genome_build, transcript=None)</code>","text":"<p>Constructor</p> Source code in <code>pyphetools/creation/variant_validator.py</code> <pre><code>def __init__(self, genome_build, transcript=None):\n    \"\"\"\n    Constructor\n    \"\"\"\n    if genome_build not in ACCEPTABLE_GENOMES:\n        raise ValueError(f\"genome_build \\\"{genome_build}\\\" not recognized\")\n    self._genome_assembly = genome_build\n    self._transcript = transcript\n</code></pre>"},{"location":"api/creation/variant_validator/#pyphetools.creation.VariantValidator.encode_hgvs","title":"<code>encode_hgvs(hgvs, custom_transcript=None)</code>","text":"<p>Encode an HGVS string as a pyphetools Variant object</p> <p>Parameters:</p> Name Type Description Default <code>hgvs</code> <code>str</code> <p>Human Genome Variation Society (HGVS) representation of a variant, e.g., c.36613706dup</p> required <code>custom_transcript</code> <code>str</code> <p>a transcript (e.g., NM_001848.2), if different from the default transcript, optional</p> <code>None</code> <p>Returns:</p> Type Description <code>HgvsVariant</code> <p>pyphetools Variant object</p> Source code in <code>pyphetools/creation/variant_validator.py</code> <pre><code>def encode_hgvs(self, hgvs, custom_transcript=None):\n    \"\"\"\n    Encode an HGVS string as a pyphetools Variant object\n\n    :param hgvs: Human Genome Variation Society (HGVS) representation of a variant, e.g., c.36613706dup\n    :type hgvs: str\n    :param custom_transcript: a transcript (e.g., NM_001848.2), if different from the default transcript, optional\n    :type custom_transcript: str\n    :returns: pyphetools Variant object\n    :rtype: HgvsVariant\n    \"\"\"\n    if custom_transcript is not None:\n        transcript = custom_transcript\n    elif self._transcript is not None:\n        transcript = self._transcript\n    else:\n        raise ValueError(\"Cannot run variant validator without transcript\")\n    api_url = URL_SCHEME % (self._genome_assembly, transcript, hgvs, transcript)\n    #f\"https://rest.variantvalidator.org/VariantValidator/variantvalidator/{self._genome_assembly}/{transcript}%3A{hgvs}/{transcript}\"\n    #\n    print(api_url)\n    response = requests.get(api_url)\n    # We expect to get a dictionary with three keys. The first is the name of the variant, e.g., ACC:HGVS, then we\n    # get flag and metadata\n    vv_dict = response.json()\n    if 'flag' in vv_dict:\n        if vv_dict['flag'] != 'gene_variant':\n            flag = vv_dict['flag']\n            raise ValueError(f\"Expecting to get a gene_variant from Variant Validator but got {flag}\")\n    # This is the easiest way to get the variant key, which may contain difficult characters\n    variant_key = [k for k in vv_dict.keys() if k not in {'flag', 'metadata'}][0]\n    var = vv_dict[variant_key]\n    hgnc = None\n    if 'gene_ids' in var and 'hgnc_id' in var['gene_ids']:\n        hgnc = var['gene_ids']['hgnc_id']\n    symbol = None\n    if 'gene_symbol' in var:\n        symbol = var['gene_symbol']\n    assemblies = var['primary_assembly_loci']\n    if not self._genome_assembly in assemblies:\n        raise ValueError(f\"Could not identified {self._genome_assembly} in Variant Validator response\")\n    assembly = assemblies[self._genome_assembly]\n    hgvs_transcript_var = var.get('hgvs_transcript_variant', None)\n    genomic_hgvs = assembly.get('hgvs_genomic_description', None)\n    reference_sequence_records = var.get('reference_sequence_records', None)\n    if reference_sequence_records is not None:\n        transcript = reference_sequence_records['transcript']\n        if transcript.startswith('https://www.ncbi.nlm.nih.gov/nuccore/'):\n            transcript = transcript[37:]\n    else:\n        transcript = None\n    # 'vcf': {'alt': 'C', 'chr': '16', 'pos': '1756403', 'ref': 'CG'}},\n    if not 'vcf' in assembly:\n        raise ValueError(f\"Could not identify vcf element in Variant Validator genome assembly response\")\n    return HgvsVariant(assembly=self._genome_assembly, vcf_d=assembly['vcf'], symbol=symbol,\n                    hgnc=hgnc, transcript=transcript, hgvs=hgvs_transcript_var, g_hgvs=genomic_hgvs)\n</code></pre>"},{"location":"api/validation/cohort_validator/","title":"CohortValidator","text":"Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>class CohortValidator:\n\n    def __init__(self, cohort:List[Individual], ontology:hpotk.MinimalOntology, min_hpo:int,  allelic_requirement:AllelicRequirement=None) -&gt; None:\n        self._cohort = cohort\n        self._ontology = ontology\n        self._validated_individual_list = []\n        for indi in cohort:\n            vindi = ValidatedIndividual(individual=indi)\n            vindi.validate(ontology=ontology, min_hpo=min_hpo, allelic_requirement=allelic_requirement)\n            self._validated_individual_list.append(vindi)\n        if len(cohort) != len(self._validated_individual_list):\n            # should never happen\n            raise ValueError(f\"Invalid validation: size of cohort ={len(cohort)} but size of validated individual = {len(self._validated_individual_list)}\")\n        self._error_free_individuals = [vi.get_individual_with_clean_terms() for vi in self._validated_individual_list if not vi.has_unfixed_error()]\n        self._v_individuals_with_unfixable_errors = [vi for vi in self._validated_individual_list if vi.has_unfixed_error()]\n\n    def get_validated_individual_list(self):\n        \"\"\"\n        :returns: list of all individuals with QC Validation results\n        :rtype: List[ValidatedIndividual]\n        \"\"\"\n        return self._validated_individual_list\n\n\n    def get_error_free_individual_list(self) -&gt; List[Individual]:\n        \"\"\"\n        Returns a list of individuals from which the erroneous and redundant termas have been removed and from which individuals with errors (e.g., not enough HPO terms) have been removed.\n        :returns: List of individuals with no errors\n        :rtype: List[Individual]\n        \"\"\"\n        return self._error_free_individuals\n\n    def get_validated_individuals_with_unfixable_errors(self):\n        \"\"\"\n        Returns a list of individuals with errors that cannot be automatically fixed.\n        :returns: List of individuals with unfixable errors\n        :rtype: List[ValidatedIndivudal]\n        \"\"\"\n        return self._v_individuals_with_unfixable_errors\n\n\n    def n_removed_individuals(self):\n        return len(self._validated_individual_list) - len(self._error_free_individuals)\n\n    def n_individuals(self):\n        return len(self._validated_individual_list)\n\n    def n_error_free_individuals(self):\n        return len(self._error_free_individuals)\n\n    def get_ontology(self):\n        return self._ontology\n</code></pre>"},{"location":"api/validation/cohort_validator/#pyphetools.validation.CohortValidator.get_error_free_individual_list","title":"<code>get_error_free_individual_list()</code>","text":"<p>Returns a list of individuals from which the erroneous and redundant termas have been removed and from which individuals with errors (e.g., not enough HPO terms) have been removed.</p> <p>Returns:</p> Type Description <code>List[Individual]</code> <p>List of individuals with no errors</p> Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>def get_error_free_individual_list(self) -&gt; List[Individual]:\n    \"\"\"\n    Returns a list of individuals from which the erroneous and redundant termas have been removed and from which individuals with errors (e.g., not enough HPO terms) have been removed.\n    :returns: List of individuals with no errors\n    :rtype: List[Individual]\n    \"\"\"\n    return self._error_free_individuals\n</code></pre>"},{"location":"api/validation/cohort_validator/#pyphetools.validation.CohortValidator.get_validated_individual_list","title":"<code>get_validated_individual_list()</code>","text":"<p>Returns:</p> Type Description <code>List[ValidatedIndividual]</code> <p>list of all individuals with QC Validation results</p> Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>def get_validated_individual_list(self):\n    \"\"\"\n    :returns: list of all individuals with QC Validation results\n    :rtype: List[ValidatedIndividual]\n    \"\"\"\n    return self._validated_individual_list\n</code></pre>"},{"location":"api/validation/cohort_validator/#pyphetools.validation.CohortValidator.get_validated_individuals_with_unfixable_errors","title":"<code>get_validated_individuals_with_unfixable_errors()</code>","text":"<p>Returns a list of individuals with errors that cannot be automatically fixed.</p> <p>Returns:</p> Type Description <code>List[ValidatedIndivudal]</code> <p>List of individuals with unfixable errors</p> Source code in <code>pyphetools/validation/cohort_validator.py</code> <pre><code>def get_validated_individuals_with_unfixable_errors(self):\n    \"\"\"\n    Returns a list of individuals with errors that cannot be automatically fixed.\n    :returns: List of individuals with unfixable errors\n    :rtype: List[ValidatedIndivudal]\n    \"\"\"\n    return self._v_individuals_with_unfixable_errors\n</code></pre>"},{"location":"api/validation/content_validator/","title":"ContentValidator","text":"<p>               Bases: <code>PhenopacketValidator</code></p> <p>Validate a list of phenopackets as to whether they have a minunum number of phenotypic features and alleles</p> <p>The following example shows how to use this class to assess whether each phenopacket in the directory called \"phenopackets\" contains at least one variant and at least three HPO terms.</p> <pre><code>from pyphetools.visualization import PhenopacketIngestor\nfrom pyphetools.validation import ContentValidator\ningestor = PhenopacketIngestor(indir=\"phenopackets\")\nppkt_d = ingestor.get_phenopacket_dictionary()\nppkt_list = list(ppkt_d.values())\nvalidator = ContentValidator(min_var=1, min_hpo=3)\nerrors = validator.validate_phenopacket_list(ppkt_list)\nprint(f\"{len(errors)} errors were identified\")\n</code></pre> <p>Note that this class does not test for all errors. Use phenopacket-tools to check for redundant or conflicting annotations.</p> <p>Parameters:</p> Name Type Description Default <code>min_hpo</code> <code>int</code> <p>minimum number of phenotypic features (HP terms) for this phenopacket to be considered valid</p> required <code>allelic_requirement</code> <code>AllelicRequirement</code> <p>used to check number of alleles and variants</p> <code>None</code> Source code in <code>pyphetools/validation/content_validator.py</code> <pre><code>class ContentValidator(PhenopacketValidator):\n    \"\"\"\n    Validate a list of phenopackets as to whether they have a minunum number of phenotypic features and alleles\n\n    The following example shows how to use this class to assess whether each phenopacket in the directory called \"phenopackets\" contains at least one variant and at least three HPO terms.\n\n        from pyphetools.visualization import PhenopacketIngestor\n        from pyphetools.validation import ContentValidator\n        ingestor = PhenopacketIngestor(indir=\"phenopackets\")\n        ppkt_d = ingestor.get_phenopacket_dictionary()\n        ppkt_list = list(ppkt_d.values())\n        validator = ContentValidator(min_var=1, min_hpo=3)\n        errors = validator.validate_phenopacket_list(ppkt_list)\n        print(f\"{len(errors)} errors were identified\")\n\n    Note that this class does not test for all errors. Use phenopacket-tools to check for redundant or conflicting\n    annotations.\n\n    :param min_hpo: minimum number of phenotypic features (HP terms) for this phenopacket to be considered valid\n    :type min_hpo: int\n    :param allelic_requirement: used to check number of alleles and variants\n    :type allelic_requirement: AllelicRequirement\n    \"\"\"\n    def __init__(self, min_hpo: int, allelic_requirement: AllelicRequirement = None, minimum_disease_count:int=1) -&gt; None:\n        super().__init__()\n        self._min_hpo = min_hpo\n        self._allelic_requirement = allelic_requirement\n        self._minimum_disease_count = minimum_disease_count\n\n\n    def validate_individual(self, individual:Individual) -&gt; List[ValidationResult]:\n        \"\"\"\n        check a single Individual as to whether there are sufficient HPO terms and alleles/variants\n        :returns: a potential empty list of validations\n        :rtype: List[ValidationResult]\n        \"\"\"\n        n_pf = len(individual.hpo_terms)\n        n_var = 0\n        n_alleles = 0\n        pp_id = individual.get_phenopacket_id()\n        for variant_interpretation in individual.interpretation_list:\n            n_var += 1\n            if variant_interpretation.variation_descriptor is not None:\n                vdesc =  variant_interpretation.variation_descriptor\n                if vdesc.allelic_state is not None:\n                    gtype = vdesc.allelic_state\n                    if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                        n_alleles += 1\n                    elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                        n_alleles += 2\n                    elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                        n_alleles += 1\n        disease_count =  individual.disease_count()\n        return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n\n\n\n    def validate_phenopacket(self, phenopacket) -&gt; List[ValidationResult]:\n        \"\"\"\n        check a single phenopacket as to whether there are sufficient HPO terms and alleles/variants\n        :returns: a potential empty list of validations\n        :rtype: List[ValidationResult]\n        \"\"\"\n        if isinstance(phenopacket, str):\n            # the user passed a file\n            if not os.path.isfile(phenopacket):\n                raise FileNotFoundError(f\"Could not find phenopacket file at '{phenopacket}'\")\n            with open(phenopacket) as f:\n                data = f.read()\n                jsondata = json.loads(data)\n                phpacket = Parse(json.dumps(jsondata), phenopackets.Phenopacket())\n        elif isinstance(phenopacket, phenopackets.Phenopacket):\n            phpacket = phenopacket\n        else:\n            raise ValueError(f\"phenopacket argument must be file path or GA4GH Phenopacket \\\n                object but was {type(phenopacket)}\")\n        pp_id = phpacket.id\n        n_pf = len(phpacket.phenotypic_features)\n        if phpacket.interpretations is None:\n            n_var = 0\n            n_alleles = 0\n        else:\n            n_var = 0\n            n_alleles = 0\n            for interpretation in phpacket.interpretations:\n                if interpretation.diagnosis is not None:\n                    dx = interpretation.diagnosis\n                    for genomic_interpretation in dx.genomic_interpretations:\n                        n_var += 1\n                        vint = genomic_interpretation.variant_interpretation\n                        if vint.variation_descriptor is not None:\n                            vdesc =   vint.variation_descriptor\n                            if vdesc.allelic_state is not None:\n                                gtype = vdesc.allelic_state\n                                if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                                    n_alleles += 1\n                                elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                                    n_alleles += 2\n                                elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                                    n_alleles += 1\n        disease_count = len(phenopacket.diseases)\n        return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n\n\n\n    def _validate(self, pp_id:str, n_hpo:int, disease_count:int, n_var:int=None, n_alleles:int=None):\n        \"\"\"\n        private method called by validate_individual or validate_phenopacket.\n        :param pp_id: phenopacket identifier\n        :type pp_id: str\n        :param n_hpo: Number of HPO terms\n        :type n_hpo: int\n        :param n_var: Number of variants found\n        :type n_var: Optional[int]\n        :param n_alleles: Number of alleles found\n        :type n_alleles: Optional[int]\n        \"\"\"\n        validation_results = []\n        if n_hpo &lt; self._min_hpo:\n            validation_results.append(ValidationResultBuilder(phenopacket_id=pp_id).insufficient_hpos(min_hpo=self._min_hpo, n_hpo=n_hpo).build())\n        if disease_count &lt; self._minimum_disease_count:\n            val_result = ValidationResultBuilder(phenopacket_id=pp_id).insufficient_disease_count(disease_count, self._minimum_disease_count).build()\n            validation_results.append(val_result)\n        if self._allelic_requirement is None:\n            return validation_results\n        if self._allelic_requirement == AllelicRequirement.MONO_ALLELIC:\n            if n_var != 1:\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_variant_count(self._allelic_requirement, n_var).build()\n                validation_results.append(val_result)\n            if n_alleles != 1:\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_allele_count(self._allelic_requirement, n_alleles).build()\n                validation_results.append(val_result)\n        elif self._allelic_requirement == AllelicRequirement.BI_ALLELIC:\n            if n_var &lt; 1 or n_var &gt; 2:\n                msg = f\"Expected one or two variant for biallelic but got {n_var} variants\"\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_variant_count(self._allelic_requirement, n_var).build()\n                validation_results.append(val_result)\n            if n_alleles != 2:\n                val_result = ValidationResultBuilder(phenopacket_id=pp_id).incorrect_allele_count(self._allelic_requirement, n_alleles).build()\n                validation_results.append(val_result)\n        return validation_results\n</code></pre>"},{"location":"api/validation/content_validator/#pyphetools.validation.ContentValidator.validate_individual","title":"<code>validate_individual(individual)</code>","text":"<p>check a single Individual as to whether there are sufficient HPO terms and alleles/variants</p> <p>Returns:</p> Type Description <code>List[ValidationResult]</code> <p>a potential empty list of validations</p> Source code in <code>pyphetools/validation/content_validator.py</code> <pre><code>def validate_individual(self, individual:Individual) -&gt; List[ValidationResult]:\n    \"\"\"\n    check a single Individual as to whether there are sufficient HPO terms and alleles/variants\n    :returns: a potential empty list of validations\n    :rtype: List[ValidationResult]\n    \"\"\"\n    n_pf = len(individual.hpo_terms)\n    n_var = 0\n    n_alleles = 0\n    pp_id = individual.get_phenopacket_id()\n    for variant_interpretation in individual.interpretation_list:\n        n_var += 1\n        if variant_interpretation.variation_descriptor is not None:\n            vdesc =  variant_interpretation.variation_descriptor\n            if vdesc.allelic_state is not None:\n                gtype = vdesc.allelic_state\n                if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                    n_alleles += 1\n                elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                    n_alleles += 2\n                elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                    n_alleles += 1\n    disease_count =  individual.disease_count()\n    return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n</code></pre>"},{"location":"api/validation/content_validator/#pyphetools.validation.ContentValidator.validate_phenopacket","title":"<code>validate_phenopacket(phenopacket)</code>","text":"<p>check a single phenopacket as to whether there are sufficient HPO terms and alleles/variants</p> <p>Returns:</p> Type Description <code>List[ValidationResult]</code> <p>a potential empty list of validations</p> Source code in <code>pyphetools/validation/content_validator.py</code> <pre><code>def validate_phenopacket(self, phenopacket) -&gt; List[ValidationResult]:\n    \"\"\"\n    check a single phenopacket as to whether there are sufficient HPO terms and alleles/variants\n    :returns: a potential empty list of validations\n    :rtype: List[ValidationResult]\n    \"\"\"\n    if isinstance(phenopacket, str):\n        # the user passed a file\n        if not os.path.isfile(phenopacket):\n            raise FileNotFoundError(f\"Could not find phenopacket file at '{phenopacket}'\")\n        with open(phenopacket) as f:\n            data = f.read()\n            jsondata = json.loads(data)\n            phpacket = Parse(json.dumps(jsondata), phenopackets.Phenopacket())\n    elif isinstance(phenopacket, phenopackets.Phenopacket):\n        phpacket = phenopacket\n    else:\n        raise ValueError(f\"phenopacket argument must be file path or GA4GH Phenopacket \\\n            object but was {type(phenopacket)}\")\n    pp_id = phpacket.id\n    n_pf = len(phpacket.phenotypic_features)\n    if phpacket.interpretations is None:\n        n_var = 0\n        n_alleles = 0\n    else:\n        n_var = 0\n        n_alleles = 0\n        for interpretation in phpacket.interpretations:\n            if interpretation.diagnosis is not None:\n                dx = interpretation.diagnosis\n                for genomic_interpretation in dx.genomic_interpretations:\n                    n_var += 1\n                    vint = genomic_interpretation.variant_interpretation\n                    if vint.variation_descriptor is not None:\n                        vdesc =   vint.variation_descriptor\n                        if vdesc.allelic_state is not None:\n                            gtype = vdesc.allelic_state\n                            if gtype.label == \"heterozygous\": # \"GENO:0000135\"\n                                n_alleles += 1\n                            elif gtype.label == \"homozygous\": # \"GENO:0000136\"\n                                n_alleles += 2\n                            elif gtype.label == \"hemizygous\": # \"GENO:0000134\"\n                                n_alleles += 1\n    disease_count = len(phenopacket.diseases)\n    return self._validate(pp_id=pp_id, n_hpo=n_pf, disease_count=disease_count, n_var=n_var, n_alleles=n_alleles)\n</code></pre>"},{"location":"api/validation/ontology_qc/","title":"OntologyQC","text":"<p>This class performs three kind of checks/cleansing of ontology data 1. negated superclass and observed subclass (this is an error in the original data) 2. observed superclass and observed subclass (this is a redundancy but arguably not an error) 3. Same term is excluded and observed (this is an unfixable error in the original data)</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>class OntologyQC:\n    \"\"\"\n    This class performs three kind of checks/cleansing of ontology data\n    1. negated superclass and observed subclass (this is an error in the original data)\n    2. observed superclass and observed subclass (this is a redundancy but arguably not an error)\n    3. Same term is excluded and observed (this is an unfixable error in the original data)\n\n    \"\"\"\n\n    def __init__(self,\n                 ontology:hpotk.MinimalOntology,\n                 individual:Individual,\n                 fix_conflicts=True,\n                 fix_redundancies=True):\n        self._ontology = ontology\n        self._individual = individual\n        self._phenopacket_id = individual.get_phenopacket_id()\n        self._fix_conflict_flag = fix_conflicts\n        self._fix_redundancy_flag = fix_redundancies\n        self._errors = []\n        self._clean_hpo_terms = self._clean_terms()\n\n\n    def _fix_conflicts(self,\n                       observed_hpo_terms:List[HpTerm],\n                       excluded_hpo_terms) -&gt; List[HpTerm]:\n        \"\"\"\n        This class detects excluded superclasses that have observed subclasses -- a conflict.\n\n        For instance, if an individual is annotated to the terms (1) excluded: Seizure [HP:0001250] and (2)\n        observed - Clonic Seizure [HP:0020221], this is a conflict, because a person with clonic seizure also\n        can be said to have seizure. Here, we assume that the excluded annotation is an error that we\n        want to remove automatically and issue a warning. Thus, in this example, we would remove the\n        annotation excluded: Seizure [HP:0001250], and in general the excluded superclass is removed\n        if this kind of conflict is detected\n\n        :param observed_hpo_terms: list of HPO terms (observed), can be empty\n        :type observed_hpo_terms: List[HpTerm]\n        :param excluded_hpo_terms: list of HPO terms (excluded), can be empty\n        :type excluded_hpo_terms: List[HpTerm]\n        :returns: the potentially cleansed list of excluded terms (the observed terms are never changed by this method\n        :rtype: List[HpTerm]\n        \"\"\"\n        if len(excluded_hpo_terms) == 0:\n            # i.e., there can be no conflict\n            return excluded_hpo_terms\n        all_excluded_term_ids = {term.id for term in excluded_hpo_terms}\n        conflicting_term_id_set = set()\n        for term in observed_hpo_terms:\n            for tid in all_excluded_term_ids:\n                if term.id == tid:\n                    # same term observed and excluded\n                    # we cannot automatically fix this error\n                    # this will be reported and the user will need to check the input data\n                    error = ValidationResultBuilder(phenopacket_id=self._phenopacket_id).observed_and_excluded_term(term=term).build()\n                    self._errors.append(error)\n                elif self._ontology.graph.is_ancestor_of(tid, term.id):\n                    conflicting_term_id_set.add(tid)\n                    conflicting_term = self._ontology.get_term(term_id=tid)\n                    cterm = HpTerm.from_hpo_tk_term(conflicting_term)\n                    error = ValidationResultBuilder(phenopacket_id=self._phenopacket_id).conflict(term=term, conflicting_term=cterm).build()\n                    self._errors.append(error)\n        if len(conflicting_term_id_set) &gt; 0:\n            excluded_hpo_terms = [term for term in excluded_hpo_terms if term.id not in conflicting_term_id_set]\n        return excluded_hpo_terms\n\n\n\n\n    def _fix_redundancies(self,\n                          hpo_terms:List[HpTerm]) -&gt; List[HpTerm]:\n        \"\"\"\n        Remove redundant terms from a list of HPO terms.\n\n        As a side effect, add a ValidationResult for each removed redundant term\n        :param hpo_terms: original term list that might contain redundancies\n        :type hpo_terms: List[HpTerm]\n        :returns: list of HPO terms without redundancies\n        :rtype hpo_terms: List[HpTerm]\n        \"\"\"\n        all_terms = set(hpo_terms)\n        # check for duplicates\n        if len(all_terms) != len(hpo_terms):\n            duplicates = [item for item, count in Counter(hpo_terms).items() if count &gt; 1]\n            for dup in duplicates:\n                error = ValidationResultBuilder(self._phenopacket_id).duplicate_term(redundant_term=dup).build()\n                self._errors.append(error)\n            # The following removes duplicates under the assumption that all components of the HpTerm are equal\n            hpo_terms = set(hpo_terms)\n        # The following code checks for other kinds of redundancies\n        redundant_term_d = {}\n        for term in all_terms:\n            for term2 in all_terms:\n                # The ancestor, e.g. Seizure comes first, the other term, e.g. Clonic seizure, second\n                # in the following function call\n                if self._ontology.graph.is_ancestor_of(term2.id, term.id):\n                    redundant_term_d[term2] = term\n        # When we get here, we have scanned all terms for redundant ancestors\n        non_redundant_terms = [ term for term in hpo_terms if term not in redundant_term_d]\n        if len(redundant_term_d) &gt; 0:\n            for term, descendant in redundant_term_d.items():\n                error = ValidationResultBuilder(self._phenopacket_id).redundant_term(ancestor_term=term, descendent_term=descendant).build()\n                self._errors.append(error)\n        return non_redundant_terms\n\n\n    def _check_term_ids_and_labels(self,\n                                   hpo_terms:List[HpTerm]) -&gt; None:\n        \"\"\"\n        Check whether the term identifiers (e.g., HP:0001234) are present in the ontology as primary ids and whether\n        the label matches the current priumary label; if not, flag the errors in self._errors\n        \"\"\"\n        for term in hpo_terms:\n            hpo_id = term.id\n            if not hpo_id in self._ontology:\n                error = ValidationResultBuilder(self._phenopacket_id).malformed_hpo_id(malformed_term=term).build()\n                self._errors.append(error)\n            else:\n                hpo_term = self._ontology.get_term(term_id=hpo_id)\n                if hpo_term.name != term.label:\n                    valid_term = HpTerm.from_hpo_tk_term(hpo_term)\n                    error = ValidationResultBuilder(self._phenopacket_id).malformed_hpo_label(malformed_label=term.label,\n                                                                                              valid_term=hpo_term).build()\n                    self._errors.append(error)\n\n    def _clean_terms(self) -&gt; List[HpTerm]:\n        \"\"\"\n        :returns: list of HPO terms without redundancies/conflicts\n        :rtype hpo_terms: List[HpTerm]\n        \"\"\"\n        by_age_dictionary = defaultdict(list)\n        # collect all terms without a defined age of onset\n        # We will assume these terms exist at all specific ages of onset, thus we need this to calculate redundancy\n        observed_terms_without_onset = list()\n        excluded_terms_without_onset = list()\n        for term in self._individual.hpo_terms:\n            if not term.measured:\n                self._errors.append(ValidationResultBuilder(self._phenopacket_id).not_measured(term=term).build())\n            else:\n                if term.onset is not None:\n                    by_age_dictionary[term.onset].append(term)\n                else:\n                    if term.observed:\n                        observed_terms_without_onset.append(term)\n                    else:\n                        excluded_terms_without_onset.append(term)\n        self._check_term_ids_and_labels(self._individual.hpo_terms)\n        clean_terms = []\n\n        for onset, term_list in by_age_dictionary.items():\n            observed_hpo_terms = [term for term in term_list if term.observed]\n            excluded_hpo_terms = [term for term in term_list if not term.observed]\n            if self._fix_redundancy_flag:\n                observed_hpo_terms = self._fix_redundancies(observed_hpo_terms)\n                excluded_hpo_terms = self._fix_redundancies(excluded_hpo_terms)\n            if self._fix_conflict_flag:\n                # this method checks and may fix the excluded terms (only)\n                excluded_hpo_terms = self._fix_conflicts(observed_hpo_terms, excluded_hpo_terms)\n            clean_terms.extend(observed_hpo_terms)\n            clean_terms.extend(excluded_hpo_terms)\n        # When we get here, clean terms contains terms with specific onsets and conflicting/redundant terms\n        # have been removed. There may be terms with no specific onset. We only add such terms if they are neither\n        # ancestors or descendants of the specific terms\n        observed_terms_without_onset = self._fix_redundancies(observed_terms_without_onset)\n        excluded_terms_without_onset = self._fix_redundancies(excluded_terms_without_onset)\n        all_term_set = set(clean_terms)\n        for t in observed_terms_without_onset:\n            addT = True\n            for s in all_term_set:\n                # keep the term with the age of onset regardless of whether it is more or less specific\n                if s.id == t.id:\n                    error = ValidationResultBuilder(self._phenopacket_id).duplicate_term(s).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n                if self._ontology.graph.is_ancestor_of(t.id, s.id):\n                    error = ValidationResultBuilder(self._phenopacket_id).redundant_term(t, s).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n                if self._ontology.graph.is_ancestor_of(s.id, t.id):\n                    error = ValidationResultBuilder(self._phenopacket_id).redundant_term(s, t).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n            if addT:\n                clean_terms.append(t)\n                all_term_set.add(t)\n        # now check for problems with excluded terms\n        for t in excluded_terms_without_onset:\n            addT = True\n            for s in all_term_set:\n                # if an excluded term is equal to or ancestor of an observed term this is an error\n                if s.id == t.id:\n                    error = ValidationResultBuilder(self._phenopacket_id).observed_and_excluded_term(term=s).build()\n                    self._errors.append(error)\n                    addT = False\n                elif self._ontology.graph.is_ancestor_of(t.id, s.id):\n                    error = ValidationResultBuilder(self._phenopacket_id).conflict(term=s, conflicting_term=t).build()\n                    self._errors.append(error)\n                    addT = False\n                    break\n            if addT:\n                clean_terms.append(t)\n                all_term_set.add(t)\n\n        return clean_terms\n\n    def has_error(self) -&gt; bool:\n        \"\"\"\n        :returns: True iff errors were encountered\n        :rtype: boolean\n        \"\"\"\n        return len(self._errors) &gt; 0\n\n    def get_error_list(self) -&gt; List[ValidationResult]:\n        \"\"\"\n        :returns: a potential empty list of errors\n        :rtype: List[str]\n        \"\"\"\n        return self._errors\n\n    def get_clean_terms(self) -&gt; List[HpTerm]:\n        return self._clean_hpo_terms\n\n\n    def get_error_string(self) -&gt; Optional[str]:\n        \"\"\"\n        create and return a string that summarizes the redundancies and conflicts that were corrected\n\n        :returns: a string summarizing errors or None if there were none\n        :rtype: Optional[str]\n        \"\"\"\n        if not self.has_error():\n            return None\n        redundancies = [e for e in self._errors if e.is_redundant()]\n        conflicts = [e for e in self._errors if e.is_conflict()]\n        e_string = \"\"\n        if len(redundancies) &gt; 0:\n            red_terms = [e.hpo_term_and_id for e in redundancies]\n            e_string = \"The following redundant terms were removed: \" + \", \".join(red_terms) + \". \"\n        if len(conflicts) &gt; 0:\n            conf_terms = [e.hpo_term_and_id for e in conflicts]\n            e_string = e_string + \"The following conflicting excluded terms were removed: \" + \", \".join(conf_terms) + \". \"\n        return e_string\n\n\n    @staticmethod\n    def qc_cohort(individual_list:List[Individual]) -&gt; List[Individual] :\n\n\n        return individual_list\n</code></pre>"},{"location":"api/validation/ontology_qc/#pyphetools.validation.OntologyQC.get_error_list","title":"<code>get_error_list()</code>","text":"<p>Returns:</p> Type Description <code>List[str]</code> <p>a potential empty list of errors</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>def get_error_list(self) -&gt; List[ValidationResult]:\n    \"\"\"\n    :returns: a potential empty list of errors\n    :rtype: List[str]\n    \"\"\"\n    return self._errors\n</code></pre>"},{"location":"api/validation/ontology_qc/#pyphetools.validation.OntologyQC.get_error_string","title":"<code>get_error_string()</code>","text":"<p>create and return a string that summarizes the redundancies and conflicts that were corrected</p> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>a string summarizing errors or None if there were none</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>def get_error_string(self) -&gt; Optional[str]:\n    \"\"\"\n    create and return a string that summarizes the redundancies and conflicts that were corrected\n\n    :returns: a string summarizing errors or None if there were none\n    :rtype: Optional[str]\n    \"\"\"\n    if not self.has_error():\n        return None\n    redundancies = [e for e in self._errors if e.is_redundant()]\n    conflicts = [e for e in self._errors if e.is_conflict()]\n    e_string = \"\"\n    if len(redundancies) &gt; 0:\n        red_terms = [e.hpo_term_and_id for e in redundancies]\n        e_string = \"The following redundant terms were removed: \" + \", \".join(red_terms) + \". \"\n    if len(conflicts) &gt; 0:\n        conf_terms = [e.hpo_term_and_id for e in conflicts]\n        e_string = e_string + \"The following conflicting excluded terms were removed: \" + \", \".join(conf_terms) + \". \"\n    return e_string\n</code></pre>"},{"location":"api/validation/ontology_qc/#pyphetools.validation.OntologyQC.has_error","title":"<code>has_error()</code>","text":"<p>Returns:</p> Type Description <code>boolean</code> <p>True iff errors were encountered</p> Source code in <code>pyphetools/validation/ontology_qc.py</code> <pre><code>def has_error(self) -&gt; bool:\n    \"\"\"\n    :returns: True iff errors were encountered\n    :rtype: boolean\n    \"\"\"\n    return len(self._errors) &gt; 0\n</code></pre>"},{"location":"api/validation/validation_result/","title":"ValidationResult","text":"<p>A helper class to store the results of validation</p> <p>Parameters:</p> Name Type Description Default <code>phenopacket_id</code> <code>str</code> <p>Identifier of the phenopacket being validated</p> required <code>message</code> <code>str</code> <p>description of the error/warning</p> required <code>errorlevel</code> <code>ErrorLevel</code> <p>whether this result is an error or a warning</p> required <code>category</code> <code>Category</code> <p>type of QcError</p> required <code>term</code> <code>HpTerm</code> <p>HpTerm that caused the error</p> <code>None</code> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>class ValidationResult:\n    \"\"\"\n    A helper class to store the results of validation\n    :param phenopacket_id: Identifier of the phenopacket being validated\n    :type phenopacket_id: str\n    :param message: description of the error/warning\n    :type message: str\n    :param errorlevel: whether this result is an error or a warning\n    :type errorlevel: ErrorLevel\n    :param category: type of QcError\n    :type category: Category\n    :param term: HpTerm that caused the error\n    :type term: HpTerm\n\n    \"\"\"\n    def __init__(self, phenopacket_id:str, message:str, errorlevel:ErrorLevel, category:Category, term:HpTerm=None):\n        self._phenopacket_id = phenopacket_id\n        self._message = message\n        self._error_level = errorlevel\n        self._category = category\n        self._term = term\n\n    @property\n    def id(self):\n        return self._phenopacket_id\n\n    @property\n    def message(self) -&gt; str:\n        \"\"\"\n        :returns: description of the cause of ValidationResult\n        :rtype: str\n        \"\"\"\n        return self._message\n\n    @property\n    def error_level(self)-&gt; str:\n        \"\"\"\n        :returns: the name of the ErrorLevel this ValidationResult is about\n        :rtype: str\n        \"\"\"\n        return self._error_level.name\n\n    @property\n    def term(self) -&gt; Optional[HpTerm]:\n        \"\"\"\n        :returns: A string representation of the HPO term this ValidationResult is about, if applicable, or empty string\n        :rtype: Optional[str]\n        \"\"\"\n        return self._term\n\n    @property\n    def category(self) -&gt; str:\n        \"\"\"\n        :returns: the name of the Category this ValidationResult is about\n        :rtype: str\n        \"\"\"\n        return self._category.name\n\n    def is_error(self) -&gt; bool:\n        return self._error_level == ErrorLevel.ERROR\n\n    def is_warning(self) -&gt; bool:\n        return self._error_level == ErrorLevel.WARNING\n\n    def is_unfixable_error(self) -&gt; bool:\n        \"\"\"Some errors cannot be fixed automatically and require manual attention.\n\n        :returns: True iff this ValidationResult cannot be fixed automatically.\n        :rtype: bool\n        \"\"\"\n        return self._category in {Category.INSUFFICIENT_HPOS,\n                                Category.INCORRECT_ALLELE_COUNT,\n                                Category.INCORRECT_VARIANT_COUNT,\n                                Category.MALFORMED_ID,\n                                Category.MALFORMED_LABEL,\n                                Category.OBSERVED_AND_EXCLUDED\n                                }\n\n    def get_items_as_array(self) -&gt; List[str]:\n        \"\"\"\n        :returns: A list of items (strings) intended for display\n        :rtype: List[str]\n        \"\"\"\n        if self._term is None:\n            term = \"\"\n        elif isinstance(self._term, HpTerm):\n            term = self._term.hpo_term_and_id\n        else:\n            term = f\"{self._term.name} ({self._term.identifier.value})\"\n        return [self.id, self.error_level, self.category, self.message, term]\n\n    def __repr__(self):\n        return f\"{self._error_level}: {self._message}\"\n\n\n    @staticmethod\n    def get_header_fields():\n        return [\"ID\", \"Level\", \"Category\", \"Message\", \"HPO Term\"]\n</code></pre>"},{"location":"api/validation/validation_result/#pyphetools.validation.ValidationResult.category","title":"<code>category</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>the name of the Category this ValidationResult is about</p>"},{"location":"api/validation/validation_result/#pyphetools.validation.ValidationResult.error_level","title":"<code>error_level</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>the name of the ErrorLevel this ValidationResult is about</p>"},{"location":"api/validation/validation_result/#pyphetools.validation.ValidationResult.message","title":"<code>message</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>str</code> <p>description of the cause of ValidationResult</p>"},{"location":"api/validation/validation_result/#pyphetools.validation.ValidationResult.term","title":"<code>term</code>  <code>property</code>","text":"<p>Returns:</p> Type Description <code>Optional[str]</code> <p>A string representation of the HPO term this ValidationResult is about, if applicable, or empty string</p>"},{"location":"api/validation/validation_result/#pyphetools.validation.ValidationResult.get_items_as_array","title":"<code>get_items_as_array()</code>","text":"<p>Returns:</p> Type Description <code>List[str]</code> <p>A list of items (strings) intended for display</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def get_items_as_array(self) -&gt; List[str]:\n    \"\"\"\n    :returns: A list of items (strings) intended for display\n    :rtype: List[str]\n    \"\"\"\n    if self._term is None:\n        term = \"\"\n    elif isinstance(self._term, HpTerm):\n        term = self._term.hpo_term_and_id\n    else:\n        term = f\"{self._term.name} ({self._term.identifier.value})\"\n    return [self.id, self.error_level, self.category, self.message, term]\n</code></pre>"},{"location":"api/validation/validation_result/#pyphetools.validation.ValidationResult.is_unfixable_error","title":"<code>is_unfixable_error()</code>","text":"<p>Some errors cannot be fixed automatically and require manual attention.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True iff this ValidationResult cannot be fixed automatically.</p> Source code in <code>pyphetools/validation/validation_result.py</code> <pre><code>def is_unfixable_error(self) -&gt; bool:\n    \"\"\"Some errors cannot be fixed automatically and require manual attention.\n\n    :returns: True iff this ValidationResult cannot be fixed automatically.\n    :rtype: bool\n    \"\"\"\n    return self._category in {Category.INSUFFICIENT_HPOS,\n                            Category.INCORRECT_ALLELE_COUNT,\n                            Category.INCORRECT_VARIANT_COUNT,\n                            Category.MALFORMED_ID,\n                            Category.MALFORMED_LABEL,\n                            Category.OBSERVED_AND_EXCLUDED\n                            }\n</code></pre>"},{"location":"api/visualization/detailed_suppl_table/","title":"DetailedSupplTable","text":"<p>This class intends to facilitate the creation of a detailed supplemental tabular file with the phenotypic findings for an entire cohort. Each attribute (id, sex, age, HPO terms) are shown on rows, and the individuals who make up the cohort are shown as columns.</p> Source code in <code>pyphetools/visualization/detailed_suppl_table.py</code> <pre><code>class DetailedSupplTable:\n    \"\"\"\n    This class intends to facilitate the creation of a detailed supplemental tabular file with the phenotypic findings for\n    an entire cohort. Each attribute (id, sex, age, HPO terms) are shown on rows, and the individuals who make up the cohort\n    are shown as columns.\n    \"\"\"\n\n    def __init__(self, \n                 patient_list: typing.List[PPKt.Phenopacket], \n                 hp_json:str=None) -&gt; None:\n        \"\"\"\n        :param patient_d: dictionary of patients to display\n        :type patient_d: map with key string and value SimplePatient\n        \"\"\"\n        parser = HpoParser(hpo_json_file=hp_json)\n        hp_ontology = parser.get_ontology()\n        if not isinstance(patient_list, list):\n            raise ValueError(f\"patient_list argument must be dictionary but was {type(patient_list)}\")\n        self._simple_patient_list = list()\n        for v in patient_list:\n            if str(type(v)) == \"&lt;class 'phenopackets.schema.v2.phenopackets_pb2.Phenopacket'&gt;\":\n                self._simple_patient_list.append(SimplePatient(ga4gh_phenopacket=v))\n            else:\n                raise ValueError(f\"patient_d values must be GA4GH Phenopackets but was {type(v)}\")\n        self._hp_ontology = hp_ontology\n        self._total_counts = defaultdict(int)\n        self._total_counts_propagated = defaultdict(int)\n        sex_d = defaultdict(int)\n        var_d = defaultdict(int)\n        for pat in self._simple_patient_list:\n            sex_d[pat.get_sex()] += 1\n            hpo_terms = pat.get_observed_hpo_d()\n            anc_set = set() # graph with ancestors induced by all terms of the patient\n            for hp_id in hpo_terms.keys():\n                # key is a string such as HP:0001234, value is an HpTerm object\n                # we need to convert it to an object from hpo-toolkit because get_ancestors returns HpTerm objects\n                hp_termid = TermId.from_curie(hp_id)\n                if not self._hp_ontology.graph.is_descendant_of(hp_termid, PHENOTYPIC_ABNORMALITY_ROOT):\n                    continue # do not count terms that are not phenotypes\n                ancs = self._hp_ontology.graph.get_ancestors(hp_termid)\n                anc_set.add(hp_termid)\n                anc_set.update(ancs)\n                self._total_counts[hp_id] += 1\n            for hp_id in anc_set:\n                if hp_id == ALL_ROOT or hp_id == PHENOTYPIC_ABNORMALITY_ROOT:\n                    continue\n                else:\n                    self._total_counts_propagated[hp_id.value] += 1\n            variants = pat.get_variant_list()\n            for var in variants:\n                var_d[var] += 1\n        self._hpo_category_set = HpoCategorySet(ontology=hp_ontology)\n\n    def _calculate_table(self, patient_list: typing.List[PPKt.Phenopacket], ) -&gt; typing.List[typing.List[str]]:\n        for pat in self._simple_patient_list:\n            hpo_terms = pat.get_observed_hpo_d()\n            anc_set = set() # graph with ancestors induced by all terms of the patient\n\n\n\n    def _get_table(self, counts_d):\n        \"\"\"\n        Get counts of terms without annotation propagation or thresholding\n        \"\"\"\n        rows = []\n        N = len(self._patient_d)\n        for hpid, total_count in counts_d.items():\n            total_per = 100*total_count/N\n            total_s = f\"{total_count}/{N} ({total_per:.1f}%)\"\n            hpterm = self._ontology.get_term(hpid)\n            cat = self.get_category(termid=hpid)\n            focus_count = self._focus_counts.get(hpid, 0)\n            other_count = self._non_focus_counts.get(hpid, 0)\n            d = {'category': cat, 'term': hpterm.name, 'HP:id': hpid, 'focus' : focus_count, 'other': other_count, 'total': total_s, 'total_count': total_count}\n            rows.append(d)\n        df = pd.DataFrame(rows)\n        df.set_index('category', inplace=True)\n        return df.sort_values(['category', 'total_count'], ascending=[True, False])\n\n\n\n    def get_table_direct_annotations(self):\n        \"\"\"\n        Get counts of terms without annotation propagation or thresholding\n        \"\"\"\n        return self._get_table(self._total_counts)\n\n\n    def get_table_with_propagated_counts(self):\n        \"\"\"\n        Get counts of terms without annotation propagation or thresholding\n        \"\"\"\n        return self._get_table(self._total_counts_propagated)\n\n    @staticmethod\n    def _get_counts(hpo_term_id:str, counts_d:dict):\n        M = len(counts_d)\n        N = 0\n        for _, v in counts_d.items():\n            if v.contains_observed_term_id(hpo_term_id):\n                N += 1\n        return N, M\n\n    @staticmethod\n    def _get_counts_dict(pat_list):\n        counts_d = defaultdict(int)\n        for pat in pat_list:\n            observed_hpo = pat.get_observed_hpo_d()\n            for hpo_term_id in observed_hpo.keys():\n                counts_d[hpo_term_id] += 1\n        return counts_d   \n\n\n    def get_html_table_by_pmid(self, min_count=0):\n        \"\"\"\n        :param min_count: minimum count to be displayed ion the table (by default, all terms are displayed)\n        :type min_count: int\n        \"\"\"\n        by_pmid_d = defaultdict(list)\n        all_observed_hpo = defaultdict(int) # HPO ids observed in our cohort\n        hpo_id_to_display_d = defaultdict()\n        for pat in self._simple_patient_list:\n            observed_hpo_d = pat.get_observed_hpo_d()\n            for hpo_term in observed_hpo_d.values():\n                hpo_term_id = hpo_term.id\n                all_observed_hpo[hpo_term_id] += 1\n                hpo_id_to_display_d[hpo_term_id] = hpo_term\n            if pat.has_pmid():\n                by_pmid_d[pat.get_pmid()].append(pat) \n            else:\n                by_pmid_d[\"n/a\"].append(pat) \n        sorted_pmids = sorted(by_pmid_d.items(), key=lambda x:len(x[1]), reverse=True) # sort by values\n        sorted_pmids = [ x[0] for x  in sorted_pmids]\n        sorted_hpos = sorted(all_observed_hpo.items(), key=lambda x:x[1], reverse=True)\n        sorted_hpos = [ x[0] for x  in sorted_hpos if x[1] &gt; min_count]\n        table_items = []\n        table_items.append('&lt;table style=\"border: 2px solid black;\"&gt;\\n')\n        middle = []\n        for pmid in sorted_pmids:\n            middle.append(f\"&lt;th&gt;{pmid}&lt;/th&gt;\")\n        middle_txt = \"\".join(middle)\n        header = f\"&lt;tr&gt;&lt;th&gt;HPO term&lt;/th&gt;{middle_txt}&lt;/tr&gt;\"\n        table_items.append(header)\n        for hpo_term_id in sorted_hpos:\n            hpo_term = hpo_id_to_display_d.get(hpo_term_id)\n            line_items = []\n            line_items.append(f\"&lt;tr&gt;&lt;td&gt;{hpo_term}&lt;/td&gt;\")\n            for pmid in sorted_pmids:\n                simple_pat_list = by_pmid_d.get(pmid)\n                counts_d = DetailedSupplTable._get_counts_dict(simple_pat_list)\n                M = len(simple_pat_list)\n                N = counts_d.get(hpo_term_id, 0)\n                cell_contents = f\"{N}/{M} ({100*N/M:.1f}%)\"\n                line_items.append(f\"&lt;td&gt;{cell_contents}&lt;/td&gt;\")\n            line_items.append(\"&lt;/tr&gt;\\n\")\n            table_items.append(\"\".join(line_items))\n        table_items.append('&lt;/table&gt;\\n') # close table content\n        return \"\\n\".join(table_items)\n</code></pre>"},{"location":"api/visualization/detailed_suppl_table/#pyphetools.visualization.DetailedSupplTable.__init__","title":"<code>__init__(patient_list, hp_json=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>patient_d</code> <code>map with key string and value SimplePatient</code> <p>dictionary of patients to display</p> required Source code in <code>pyphetools/visualization/detailed_suppl_table.py</code> <pre><code>def __init__(self, \n             patient_list: typing.List[PPKt.Phenopacket], \n             hp_json:str=None) -&gt; None:\n    \"\"\"\n    :param patient_d: dictionary of patients to display\n    :type patient_d: map with key string and value SimplePatient\n    \"\"\"\n    parser = HpoParser(hpo_json_file=hp_json)\n    hp_ontology = parser.get_ontology()\n    if not isinstance(patient_list, list):\n        raise ValueError(f\"patient_list argument must be dictionary but was {type(patient_list)}\")\n    self._simple_patient_list = list()\n    for v in patient_list:\n        if str(type(v)) == \"&lt;class 'phenopackets.schema.v2.phenopackets_pb2.Phenopacket'&gt;\":\n            self._simple_patient_list.append(SimplePatient(ga4gh_phenopacket=v))\n        else:\n            raise ValueError(f\"patient_d values must be GA4GH Phenopackets but was {type(v)}\")\n    self._hp_ontology = hp_ontology\n    self._total_counts = defaultdict(int)\n    self._total_counts_propagated = defaultdict(int)\n    sex_d = defaultdict(int)\n    var_d = defaultdict(int)\n    for pat in self._simple_patient_list:\n        sex_d[pat.get_sex()] += 1\n        hpo_terms = pat.get_observed_hpo_d()\n        anc_set = set() # graph with ancestors induced by all terms of the patient\n        for hp_id in hpo_terms.keys():\n            # key is a string such as HP:0001234, value is an HpTerm object\n            # we need to convert it to an object from hpo-toolkit because get_ancestors returns HpTerm objects\n            hp_termid = TermId.from_curie(hp_id)\n            if not self._hp_ontology.graph.is_descendant_of(hp_termid, PHENOTYPIC_ABNORMALITY_ROOT):\n                continue # do not count terms that are not phenotypes\n            ancs = self._hp_ontology.graph.get_ancestors(hp_termid)\n            anc_set.add(hp_termid)\n            anc_set.update(ancs)\n            self._total_counts[hp_id] += 1\n        for hp_id in anc_set:\n            if hp_id == ALL_ROOT or hp_id == PHENOTYPIC_ABNORMALITY_ROOT:\n                continue\n            else:\n                self._total_counts_propagated[hp_id.value] += 1\n        variants = pat.get_variant_list()\n        for var in variants:\n            var_d[var] += 1\n    self._hpo_category_set = HpoCategorySet(ontology=hp_ontology)\n</code></pre>"},{"location":"api/visualization/detailed_suppl_table/#pyphetools.visualization.DetailedSupplTable.get_html_table_by_pmid","title":"<code>get_html_table_by_pmid(min_count=0)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>min_count</code> <code>int</code> <p>minimum count to be displayed ion the table (by default, all terms are displayed)</p> <code>0</code> Source code in <code>pyphetools/visualization/detailed_suppl_table.py</code> <pre><code>def get_html_table_by_pmid(self, min_count=0):\n    \"\"\"\n    :param min_count: minimum count to be displayed ion the table (by default, all terms are displayed)\n    :type min_count: int\n    \"\"\"\n    by_pmid_d = defaultdict(list)\n    all_observed_hpo = defaultdict(int) # HPO ids observed in our cohort\n    hpo_id_to_display_d = defaultdict()\n    for pat in self._simple_patient_list:\n        observed_hpo_d = pat.get_observed_hpo_d()\n        for hpo_term in observed_hpo_d.values():\n            hpo_term_id = hpo_term.id\n            all_observed_hpo[hpo_term_id] += 1\n            hpo_id_to_display_d[hpo_term_id] = hpo_term\n        if pat.has_pmid():\n            by_pmid_d[pat.get_pmid()].append(pat) \n        else:\n            by_pmid_d[\"n/a\"].append(pat) \n    sorted_pmids = sorted(by_pmid_d.items(), key=lambda x:len(x[1]), reverse=True) # sort by values\n    sorted_pmids = [ x[0] for x  in sorted_pmids]\n    sorted_hpos = sorted(all_observed_hpo.items(), key=lambda x:x[1], reverse=True)\n    sorted_hpos = [ x[0] for x  in sorted_hpos if x[1] &gt; min_count]\n    table_items = []\n    table_items.append('&lt;table style=\"border: 2px solid black;\"&gt;\\n')\n    middle = []\n    for pmid in sorted_pmids:\n        middle.append(f\"&lt;th&gt;{pmid}&lt;/th&gt;\")\n    middle_txt = \"\".join(middle)\n    header = f\"&lt;tr&gt;&lt;th&gt;HPO term&lt;/th&gt;{middle_txt}&lt;/tr&gt;\"\n    table_items.append(header)\n    for hpo_term_id in sorted_hpos:\n        hpo_term = hpo_id_to_display_d.get(hpo_term_id)\n        line_items = []\n        line_items.append(f\"&lt;tr&gt;&lt;td&gt;{hpo_term}&lt;/td&gt;\")\n        for pmid in sorted_pmids:\n            simple_pat_list = by_pmid_d.get(pmid)\n            counts_d = DetailedSupplTable._get_counts_dict(simple_pat_list)\n            M = len(simple_pat_list)\n            N = counts_d.get(hpo_term_id, 0)\n            cell_contents = f\"{N}/{M} ({100*N/M:.1f}%)\"\n            line_items.append(f\"&lt;td&gt;{cell_contents}&lt;/td&gt;\")\n        line_items.append(\"&lt;/tr&gt;\\n\")\n        table_items.append(\"\".join(line_items))\n    table_items.append('&lt;/table&gt;\\n') # close table content\n    return \"\\n\".join(table_items)\n</code></pre>"},{"location":"api/visualization/detailed_suppl_table/#pyphetools.visualization.DetailedSupplTable.get_table_direct_annotations","title":"<code>get_table_direct_annotations()</code>","text":"<p>Get counts of terms without annotation propagation or thresholding</p> Source code in <code>pyphetools/visualization/detailed_suppl_table.py</code> <pre><code>def get_table_direct_annotations(self):\n    \"\"\"\n    Get counts of terms without annotation propagation or thresholding\n    \"\"\"\n    return self._get_table(self._total_counts)\n</code></pre>"},{"location":"api/visualization/detailed_suppl_table/#pyphetools.visualization.DetailedSupplTable.get_table_with_propagated_counts","title":"<code>get_table_with_propagated_counts()</code>","text":"<p>Get counts of terms without annotation propagation or thresholding</p> Source code in <code>pyphetools/visualization/detailed_suppl_table.py</code> <pre><code>def get_table_with_propagated_counts(self):\n    \"\"\"\n    Get counts of terms without annotation propagation or thresholding\n    \"\"\"\n    return self._get_table(self._total_counts_propagated)\n</code></pre>"},{"location":"api/visualization/hpoa_table_creator/","title":"HpoaTableCreator","text":"<p>Create an HPO \"small file\" with the following fourteen columns     1. #diseaseID     2. diseaseName     3. phenotypeID     4. phenotypeName     5. onsetID     6. onsetName     7. frequency     8. sex     9. negation     10. modifier     11. description     12. publication     13. evidence     14. biocuration These should be tab separated fields.</p> Source code in <code>pyphetools/visualization/hpoa_table_creator.py</code> <pre><code>class HpoaTableCreator:\n    \"\"\"\n    Create an HPO \"small file\" with the following fourteen columns\n        1. #diseaseID\n        2. diseaseName\n        3. phenotypeID\n        4. phenotypeName\n        5. onsetID\n        6. onsetName\n        7. frequency\n        8. sex\n        9. negation\n        10. modifier\n        11. description\n        12. publication\n        13. evidence\n        14. biocuration\n    These should be tab separated fields.\n    \"\"\"\n    def __init__(\n            self,\n            phenopacket_list,\n            onset_term_d,\n            moi_d,\n            created_by: str,\n    ) -&gt; None:\n        \"\"\"Constructor\n\n        :param phenopacket_list: List of GA4GH phenopackets\n        :type phenopacket_list: List[PPKt.Phenopacket]\n        :param onset_term_d: Dictionary with key PMID string and value: OnsetTerm object\n        :type: Dict[str, OnsetTerm]\n        :param moi_d: Dictionary with key PMID and value Mode of inheritance\n        \"\"\"\n        todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n        self._created_by = created_by\n        self._todays_date = f\"[{todays_date}]\"\n        self._phenopackets = phenopacket_list\n        self._all_hpo_d = self._get_all_hpos()\n        self._disease = self._get_disease() # only allow one disease, therefore this is a scalar value (string)\n        self._hpo_counter_d = self._count_hpos()\n        self._biocurator_d = self._get_biocurator_d()\n        self._onset_rows = self._add_age_of_onset_terms(onset_term_d)\n        self._moi_rows = self._add_moi_rows(moi_d)\n\n    def _get_all_hpos(self) -&gt; Dict[str,HpTerm]:\n        \"\"\"Get a dictionary of HpTerms, with key being HPO id and the value the corresponding HpTerm\n\n        We use this to retrieve the label\n        :returns: a dictionary, with key=HPO id, value: HpTerm\n        :rtype: Dict[str, HpTerm]\n        \"\"\"\n        all_hpo_d = {}\n        for ppkt in self._phenopackets:\n            for pf in ppkt.phenotypic_features:\n                hpterm = HpTerm(hpo_id=pf.type.id, label=pf.type.label)\n                all_hpo_d[hpterm.id] = hpterm\n        print(f\"We found a total of {len(all_hpo_d)} unique HPO terms\")\n        return all_hpo_d\n\n\n    @staticmethod\n    def get_pmid(ppkt):\n        mdata = ppkt.meta_data\n        if mdata.external_references is None:\n            raise ValueError(\"MetaData must have external_references element for HPOA conversion\")\n        eref_list = mdata.external_references\n        if len(eref_list) != 1:\n            raise ValueError(f\"MetaData must have exactly one external_references element for HPOA conversion but had {len(eref_list)}\")\n        eref = eref_list[0]\n        pmid = eref.id\n        if not pmid.startswith(\"PMID:\"):\n            raise ValueError(f\"Malformed PMID: \\\"{pmid}\\\"\")\n        return pmid\n\n\n    def _get_disease(self):\n        disease_set = set()\n        for ppkt in self._phenopackets:\n            interpretations = ppkt.interpretations\n            if len(interpretations) != 1:\n                raise ValueError(f\"Error: must have only a single disease for HPOA conversion but we found {len(interpretations)}\")\n            interpretation = interpretations[0]\n            if interpretation.diagnosis is None:\n                raise ValueError(f\"Could not get diagnosis object from interpretation with id {interpretation.id}\")\n            diagnosis = interpretation.diagnosis\n            disease = Disease(disease_id=diagnosis.disease.id, disease_label=diagnosis.disease.label)\n            disease_set.add(disease)\n        if len(disease_set) == 0:\n            raise ValueError(\"Could not retrieve Disease for cohort\")\n        elif len(disease_set) &gt; 1:\n            disease_lst = '; '.join([disease.id for disease in disease_set])\n            raise ValueError(f\"Error: must have only a single Disease for HPOA conversion but we found {len(disease_set)}: {disease_lst}\")\n        [disease] = disease_set\n        print(f\"Extracted disease: {disease}\")\n        return disease\n\n    def _get_biocurator_d(self):\n        \"\"\"The unspoken assumption of this function is that there is just one biocurator per PMID.\n        This will be true for phenopackets created by pyphetools.\n\n        :returns: dictionary with key=PMID, value=biocurator\n        :rtype: Dict[str,str]\n        \"\"\"\n        biocurator_d = {}\n        for ppkt in self._phenopackets:\n            pmid = HpoaTableCreator.get_pmid(ppkt=ppkt)\n            mdata = ppkt.meta_data\n            created_by = mdata.created_by\n            if mdata.HasField(\"created\"):\n                created = mdata.created  # created is a TimeStamp object\n                created_dt = created.ToDatetime()\n                ymd = created_dt.strftime('%Y-%m-%d')\n                created_by = f\"{created_by}[{ymd}]\"\n            else:\n                created_by = f\"{created_by}{self._todays_date}\"\n            biocurator_d[pmid] = created_by\n        return biocurator_d\n\n    def _count_hpos(self):\n        hpo_counter_d = defaultdict(HpoaPmidCounter)\n        for ppkt in self._phenopackets:\n            pmid = HpoaTableCreator.get_pmid(ppkt=ppkt)\n            hpo_counter = hpo_counter_d.get(pmid)\n            # if not yet present,  initialize with zero counts\n            if  hpo_counter is None:\n                hpo_counter = HpoaPmidCounter()\n                hpo_counter_d[pmid] = hpo_counter\n            for pf in ppkt.phenotypic_features:\n                hpterm = HpTerm(hpo_id=pf.type.id, label=pf.type.label)\n                hpo_counter.increment_measured(hpterm.id)\n                if pf.excluded is not None and not pf.excluded:\n                    hpo_counter.increment_observed(hpterm.id)\n        return hpo_counter_d\n\n    def _add_age_of_onset_terms(self, onset_term_d) -&gt; List[HpoaTableRow]:\n        \"\"\"\n        :param onset_term_d: Dictionary with key=pmid, value: list of CountedHpoTerm objects\n        :type onset_term_d: Dict[str, List[CountedHpoTerm]]\n        \"\"\"\n        onset_rows  = list() # reset\n        for pmid, oterm_list in onset_term_d.items():\n            biocurator = self._biocurator_d.get(pmid)\n            for oterm in oterm_list:\n                hpo_onset_term = HpTerm(hpo_id=oterm.id, label=oterm.label)\n                row = HpoaTableRow(disease=self._disease, hpo_term=hpo_onset_term, publication=pmid, biocurator=biocurator, freq_num=oterm.numerator, freq_denom=oterm.denominator)\n                onset_rows.append(row)\n        return onset_rows\n\n    def _add_moi_rows(self, moi_d) -&gt; List[HpoaTableRow]:\n        \"\"\"Add mode of inheritance information\n        :param moi_d: dictionary with key: PMID, and value: List of MOI terms\n        :type moi_d:Dict[str,List[str]]\n        :returns: list of HPOA table rows\n        :rtype: List[HpoaTableRow]\n        \"\"\"\n        moi_rows = list()\n        for pmid, hpterm_list in moi_d.items():\n            biocurator = self._biocurator_d.get(pmid)\n            # If we add an MOI outside of the template, then it will not have a PMID\n            # the template builder requires a created_by field which is designed for this.\n            if biocurator is None:\n                biocurator = f'{self._created_by}{self._todays_date}'\n            for hpterm in hpterm_list:\n                row = HpoaTableRow(disease=self._disease, hpo_term=hpterm, publication=pmid, biocurator=biocurator)\n                moi_rows.append(row)\n        return moi_rows\n\n\n    def get_dataframe(self):\n        rows = []\n        column_names = [\"#diseaseID\", \"diseaseName\", \"phenotypeID\", \"phenotypeName\",\n                        \"onsetID\", \"onsetName\", \"frequency\", \"sex\", \"negation\",  \"modifier\",\n                        \"description\", \"publication\",\"evidence\", \"biocuration\"]\n        for pmid, counter in self._hpo_counter_d.items():\n            biocurator = self._biocurator_d.get(pmid)\n            measured_d = counter.get_measured_d()\n            observed_d = counter.get_observed_d()\n            # by construction, there can be no term in observed_d that is not in measured_d\n            for hpo_id in measured_d:\n                n = observed_d.get(hpo_id, 0)\n                m = measured_d.get(hpo_id)\n                hpo_term = self._all_hpo_d.get(hpo_id)\n                row = HpoaTableRow(disease=self._disease, hpo_term=hpo_term, publication=pmid, biocurator=biocurator, freq_num=n, freq_denom=m)\n                rows.append(row.get_dict())\n        for onset_row in self._onset_rows:\n            rows.append(onset_row.get_dict())\n        for moi_row in self._moi_rows:\n            rows.append(moi_row.get_dict())\n        df = pd.DataFrame.from_records(data=rows, columns=column_names)\n        return df\n\n    def write_data_frame(self):\n        df = self.get_dataframe()\n        dlist = df[\"#diseaseID\"].unique()\n        if len(dlist) != 1:\n            raise ValueError(\"Error - expected to get one disease but got {len(dlist)}\")\n        disease = dlist[0].replace(\":\", \"-\")\n        fname = f\"{disease}.tab\"\n        df.to_csv(fname, sep=\"\\t\", index=False)\n        print(f\"Wrote HPOA disease file to {fname}\")\n</code></pre>"},{"location":"api/visualization/hpoa_table_creator/#pyphetools.visualization.HpoaTableCreator.__init__","title":"<code>__init__(phenopacket_list, onset_term_d, moi_d, created_by)</code>","text":"<p>Constructor</p> <p>Parameters:</p> Name Type Description Default <code>phenopacket_list</code> <code>List[PPKt.Phenopacket]</code> <p>List of GA4GH phenopackets</p> required <code>onset_term_d</code> <p>Dictionary with key PMID string and value: OnsetTerm object</p> required <code>moi_d</code> <p>Dictionary with key PMID and value Mode of inheritance</p> required Source code in <code>pyphetools/visualization/hpoa_table_creator.py</code> <pre><code>def __init__(\n        self,\n        phenopacket_list,\n        onset_term_d,\n        moi_d,\n        created_by: str,\n) -&gt; None:\n    \"\"\"Constructor\n\n    :param phenopacket_list: List of GA4GH phenopackets\n    :type phenopacket_list: List[PPKt.Phenopacket]\n    :param onset_term_d: Dictionary with key PMID string and value: OnsetTerm object\n    :type: Dict[str, OnsetTerm]\n    :param moi_d: Dictionary with key PMID and value Mode of inheritance\n    \"\"\"\n    todays_date = datetime.now().strftime(\"%Y-%m-%d\")\n    self._created_by = created_by\n    self._todays_date = f\"[{todays_date}]\"\n    self._phenopackets = phenopacket_list\n    self._all_hpo_d = self._get_all_hpos()\n    self._disease = self._get_disease() # only allow one disease, therefore this is a scalar value (string)\n    self._hpo_counter_d = self._count_hpos()\n    self._biocurator_d = self._get_biocurator_d()\n    self._onset_rows = self._add_age_of_onset_terms(onset_term_d)\n    self._moi_rows = self._add_moi_rows(moi_d)\n</code></pre>"},{"location":"api/visualization/onset_calculator/","title":"OnsetCalculator","text":"<p>This class calculates the age of onset anntoations for the HPOA file</p> Source code in <code>pyphetools/visualization/onset_calculator.py</code> <pre><code>class OnsetCalculator:\n    \"\"\"\n    This class calculates the age of onset anntoations for the HPOA file\n    \"\"\"\n    def __init__(self, phenopacket_list):\n        if not isinstance(phenopacket_list, list):\n            raise ValueError(f\"Malformed individual_list argument -- needs to be list but was {type(phenopacket_list)} \")\n        self._pmid_to_onsetlist_d = defaultdict(list)\n        for ppack in phenopacket_list:\n            mdata = ppack.meta_data\n            pmid = None\n            if len(mdata.external_references) == 1:\n                eref = mdata.external_references[0]\n                pmid = eref.id\n            else:\n                print(\"Warning: Could not identify pmid\")\n            if len(ppack.diseases) == 0:\n                print(\"Warning: Could not identify disease element\")\n            elif len(ppack.diseases) &gt; 1:\n                print(\"Warning: Identified multiple disease element\")\n            disease = ppack.diseases[0]\n            if disease.HasField(\"onset\"):\n                # onset is a GA4GH TimeElement\n                # In pyphetools, it can be an OntologyClass, an Age, or a GestationalAge\n                onset = disease.onset\n                if onset.HasField(\"ontology_class\"):\n                        onset_term = onset.ontology_class\n                        hpo_onset_term = HpTerm(hpo_id=onset_term.id, label=onset_term.label)\n                        self._pmid_to_onsetlist_d[pmid].append(hpo_onset_term)\n                elif onset.HasField(\"age\"):\n                    hpo_onset_term = self._get_hpo_onset_term_from_iso8601(onset.age.iso8601duration)\n                    self._pmid_to_onsetlist_d[pmid].append(hpo_onset_term)\n                elif onset.HasField(\"gestational_age\"):\n                    hpo_onset_term = self._get_hpo_onset_term_from_gestational_age(onset.age.iso8601duration)\n                    self._pmid_to_onsetlist_d[pmid].append(hpo_onset_term)\n                else:\n                    raise ValueError(f\"onset was present but could not be decoded: {onset}\")\n\n\n    def _get_hpo_onset_term_from_iso8601(self, isostring):\n        # the following regex gets years, months, days - optionally (when we get to this point in pyphetools, we cannot have weeks)\n        ISO8601_REGEX = r\"^P(\\d+Y)?(\\d+M)?(\\d+D)?\"\n        match = re.search(ISO8601_REGEX, isostring)\n        if match:\n            y = match.group(1) or \"0Y\"\n            m = match.group(2) or \"0M\"\n            d = match.group(3) or \"0D\"\n            y = int(y[0:-1]) # all but last character\n            m = int(m[0:-1])\n            d = int(d[0:-1])\n            label = None\n            if y &gt;= 60:\n                label = \"Late onset\"\n            elif y &gt;= 40:\n                label = \"Middle age onset\"\n            elif y &gt;= 16:\n                label = \"Young adult onset\"\n            elif y &gt;= 5:\n                label = \"Juvenile onset\"\n            elif y &gt;= 1:\n                label = \"Childhood onset\"\n            elif m &gt;= 1:\n                label = \"Infantile onset\"\n            elif d  &gt;= 1:\n                label = \"Neonatal onset\"\n            elif d == 0:\n                label = \"Congenital onset\"\n            else:\n                raise ValueError(f\"[ERROR] Could not parse iso8601 \\\"{isostring}\\\"\")\n            if label not in HPO_ONSET_TERMS:\n                # should never happen ...\n                raise ValueError(f\"Could not identify onset label {label}\")\n            hpo_id = HPO_ONSET_TERMS.get(label)\n            return HpTerm(hpo_id=hpo_id, label=label)\n\n    def _get_hpo_onset_term_from_gestational_age(self, gestational_age):\n        weeks = gestational_age.weeks\n        # days not relevant to identifying the HPO Onset term\n        label = None\n        if weeks &gt;= 28:\n            # prior to birth during the third trimester, which is defined as 28 weeks and zero days (28+0) of gestation and beyond.\n            label = \"Third trimester onset\" # HP:0034197\n        elif weeks &gt;= 14:\n            # prior to birth during the second trimester, which comprises the range of gestational ages from 14 0/7 weeks to 27 6/7 (inclusive).\n            label = \"Second trimester onset\" # HP:0034198\n        elif weeks &gt;= 11:\n            # 11 0/7 to 13 6/7 weeks of gestation (inclusive).\n            label = \"Late first trimester onset\"  #  HP:0034199\n        else:\n            label = \"Embryonal onset\"\n        if label not in HPO_ONSET_TERMS:\n                # should never happen ...\n                raise ValueError(f\"Could not identify onset label {label}\")\n        hpo_id = HPO_ONSET_TERMS.get(label)\n        return HpTerm(hpo_id=hpo_id, label=label)\n\n\n    def get_pmid_to_onset_d(self)-&gt; Dict[str, List[HpTerm]]:\n        return self._pmid_to_onsetlist_d\n</code></pre>"},{"location":"api/visualization/phenopacket_ingestor/","title":"PhenopacketIngestor","text":"<p>Ingest a collection of GA4GH Phenopacket objects from a directory</p> <p>Parameters:</p> Name Type Description Default <code>indir</code> <code>str</code> <p>input directory</p> <code>'phenopackets'</code> <code>recursive</code> <code>bool</code> <p>Iff True, search subdirectorys for phenopackets</p> <code>False</code> <code>disease_id</code> <code>str</code> <p>If provided, limit ingest to phenopackets with this disease ID</p> <code>None</code> Source code in <code>pyphetools/visualization/phenopacket_ingestor.py</code> <pre><code>class PhenopacketIngestor:\n    \"\"\"\n    Ingest a collection of GA4GH Phenopacket objects from a directory\n\n    :param indir: input directory\n    :type indir: str\n    :param recursive: Iff True, search subdirectorys for phenopackets\n    :type recursive: bool, default False\n    :param disease_id: If provided, limit ingest to phenopackets with this disease ID\n    :type disease_id: str\n    \"\"\"\n\n    def __init__(self, indir=\"phenopackets\", recursive:bool=False, disease_id:str=None) -&gt; None:\n        if not os.path.isdir(indir):\n            raise ValueError(f\"indir argument {indir} must be directory!\")\n        self._indir = indir\n        self._phenopackets = []\n        for file in os.listdir(indir):\n            fname = os.path.join(indir, file)\n            if fname.endswith(\".json\") and os.path.isfile(fname):\n                with open(fname) as f:\n                    data = f.read()\n                    jsondata = json.loads(data)\n                    ppack = Parse(json.dumps(jsondata), PPKt.Phenopacket())\n                    if disease_id is not None:\n                        if not PhenopacketIngestor.has_disease_id(ppkt=ppack, disease_id=disease_id):\n                            continue\n                    self._phenopackets.append(ppack)\n        print(f\"[pyphetools] Ingested {len(self._phenopackets)} GA4GH phenopackets.\")\n\n    @staticmethod\n    def has_disease_id(ppkt:PPKt.Phenopacket, disease_id:str) -&gt; bool:\n        if len(ppkt.diseases) == 0:\n            return False\n        for disease in ppkt.diseases:\n            if disease.HasField(\"term\"):\n                if disease_id == disease.term.id:\n                    return True\n        return False\n\n\n    def get_simple_patient_dictionary(self) -&gt; typing.Dict:\n        patient_d = defaultdict(SimplePatient)\n        for ppack in self._phenopackets:\n            patient = SimplePatient(ga4gh_phenopacket=ppack)\n            patient_d[patient.get_subject_id()] = patient\n        return patient_d\n\n    def get_simple_patient_list(self) -&gt; typing.List[SimplePatient]:\n        sp_d = self.get_simple_patient_dictionary()\n        return list(sp_d.values())\n\n\n    def get_phenopacket_dictionary(self) -&gt; typing.Dict:\n        patient_d = defaultdict(SimplePatient)\n        for ppack in self._phenopackets:\n            patient_d[ppack.id] = ppack\n        return patient_d\n\n    def get_phenopacket_list(self) -&gt; typing.List:\n        ppktd = self.get_phenopacket_dictionary()\n        return list(ppktd.values())\n\n\n    def _ingest(self, indir=\"phenopackets\", recursive:bool=False, disease_id:str=None):\n        for file in os.listdir(indir):\n            fname = os.path.join(indir, file)\n            if fname.endswith(\".json\") and os.path.isfile(fname):\n                with open(fname) as f:\n                    data = f.read()\n                    jsondata = json.loads(data)\n                    ppack = Parse(json.dumps(jsondata), PPKt.Phenopacket())\n                    if disease_id is not None:\n                        if not PhenopacketIngestor.has_disease_id(ppkt=ppack, disease_id=disease_id):\n                            continue\n                    self._phenopackets.append(ppack)\n\n\n    def ingest_from_directory(self, indir:str):\n        return self._ingest(indir=indir)\n\n    def ingest_from_file(self, json_file:str) -&gt; PPKt.Phenopacket:\n         with open(json_file) as f:\n            data = f.read()\n            jsondata = json.loads(data)\n            ppack = Parse(json.dumps(jsondata), PPKt.Phenopacket())\n            return ppack\n\n\n    @staticmethod \n    def from_directory(indir: str, disease_id:str=None) -&gt; typing.List[PPKt.Phenopacket]:\n        if not os.path.isdir(indir):\n            raise FileNotFoundError(f\"argument indir={indir} is not a directory\")\n        ingestor = PhenopacketIngestor(indir=indir, disease_id=disease_id)\n        return ingestor.get_phenopacket_list()\n\n    @staticmethod\n    def filter_phenopackets(ppkt_list: typing.List[PPKt.Phenopacket], disease_id:str) -&gt; typing.List[PPKt.Phenopacket]:\n        ppkt_target_disease = list()\n        skipped_count = 0\n        for ppkt in ppkt_list:\n            if PhenopacketIngestor.has_disease_id(ppkt=ppkt, disease_id=disease_id):\n                ppkt_target_disease.append(ppkt)\n            else:\n                skipped_count += 1\n        print(f\"Returning {len(ppkt_target_disease)} phenopackets for disease {disease_id}, ommiting {skipped_count} phenopackets.\")\n        return ppkt_target_disease\n</code></pre>"},{"location":"api/visualization/phenopacket_table/","title":"PhenopacketTable","text":"<p>This class creates a table with a summary of all phenopackets in a cohort of individuals Create Individual objects and transform them into phenopackets, or import GA4GH phenopackets and display them.</p> <pre><code>from IPython.display import HTML, display\nphenopackets = [i.to_ga4gh_phenopacket(metadata=metadata) for i in individuals]\ntable = PhenopacketTable.from_phenopackets(phenopacket_list=phenopackets)\ndisplay(HTML(table.to_html()))\n</code></pre> <p>Alternatively,</p> <pre><code>table = PhenopacketTable.from_individuals(individual_list=individuals, metadata=metadata)\ndisplay(HTML(table.to_html()))\n</code></pre> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>class PhenopacketTable:\n    \"\"\"\n    This class creates a table with a summary of all phenopackets in a cohort of individuals\n    Create Individual objects and transform them into phenopackets, or import GA4GH phenopackets and display them.\n\n        from IPython.display import HTML, display\n        phenopackets = [i.to_ga4gh_phenopacket(metadata=metadata) for i in individuals]\n        table = PhenopacketTable.from_phenopackets(phenopacket_list=phenopackets)\n        display(HTML(table.to_html()))\n\n    Alternatively,\n\n        table = PhenopacketTable.from_individuals(individual_list=individuals, metadata=metadata)\n        display(HTML(table.to_html()))\n    \"\"\"\n    def __init__(self, phenopacket_list:List[PPKt.Phenopacket]=None,\n                        individual_list:List[Individual]=None,\n                        metadata:MetaData=None) -&gt; None:\n        \"\"\"\n        :param phenopacket_list: List of GA4GH phenopackets to be displayed\n        :type phenopacket_list: List[PPKt.Phenopacket]\n        :param individual_list: List of Indidivual objects to be displayed\n        :type individual_list: List[Individual]\n        :param metadata: metadata about the individuals\n        :type metadata: MetaData\n        \"\"\"\n        if phenopacket_list is None and individual_list is not None and metadata is not None:\n            self._phenopacket_list =  [i.to_ga4gh_phenopacket(metadata=metadata.to_ga4gh()) for i in individual_list]\n        elif phenopacket_list is not None and individual_list is None:\n            if metadata is not None:\n                raise ValueError(\"metadata argument not needed for phenopacket list\")\n            self._phenopacket_list = phenopacket_list\n\n    @staticmethod\n    def from_phenopackets(phenopacket_list:List[PPKt.Phenopacket]):\n        \"\"\"Initialize PhenopacketTable from list of GA4GH Phenopackets\n\n        :param phenopacket_list: list of GA4GH Phenopackets\n        :type phenopacket_list: List[PPKt.Phenopacket]\n\n        :returns: PhenopacketTable for displaying information about a cohort\n        :rtype: PhenopacketTable\n        \"\"\"\n        if not isinstance(phenopacket_list, list):\n            raise ValueError(f\"Expecting a list but got {type(phenopacket_list)}\")\n        if len(phenopacket_list) == 0:\n            raise ValueError(\"phenopacket_list was empty\")\n        ppkt = phenopacket_list[0]\n        if not isinstance(ppkt, PPKt.Phenopacket):\n            raise ValueError(f\"phenopacket_list argument must be list of Phenopacket objects but was {type(ppkt)}\")\n        return PhenopacketTable(phenopacket_list=phenopacket_list)\n\n    @staticmethod\n    def from_individuals(individual_list:List[Individual], metadata:MetaData):\n        \"\"\"Initialize PhenopacketTable from list of GA4GH Phenopackets\n\n        :param phenopacket_list: list of GA4GH Phenopackets\n        :type phenopacket_list: List[PPKt.Phenopacket]\n\n        :returns: PhenopacketTable for displaying information about a cohort\n        :rtype: PhenopacketTable\n        \"\"\"\n        if not isinstance(individual_list, list):\n            raise ValueError(f\"Expecting a list but got {type(individual_list)}\")\n        if len(individual_list) == 0:\n            raise ValueError(\"individual_list was empty\")\n        indi = individual_list[0]\n        if not isinstance(indi, Individual):\n            raise ValueError(f\"individual_list argument must be list of Individual objects but was {type(indi)}\")\n        if not isinstance(metadata, MetaData):\n            raise ValueError(f\"metadata argument must be pyphetools MetaData object but was {type(metadata)}\")\n        return PhenopacketTable(individual_list=individual_list, metadata=MetaData)\n\n    def _simple_patient_to_table_row(self, spat:SimplePatient) -&gt; List[str]:\n        \"\"\"\n        private method intended to create one table row that represents one individual\n        :param spat: An object that represents one individual\n        :type spat: SimplePatient\n        \"\"\"\n        row_items = []\n        # Patient information\n        pat_info = spat.get_subject_id() + \" (\" + spat.get_sex() + \"; \" + spat.get_age() + \")\"\n        row_items.append( pat_info)\n        row_items.append( spat.get_disease())\n        # Variant information\n        var_list = spat.get_variant_list()\n        if len(var_list) == 0:\n            row_items.append(\"n/a\" )\n        elif len(var_list) == 1:\n            var = var_list[0]\n            row_items.append( var.get_display() )\n        else:\n            cell_items = []\n            cell_items.append(\"&lt;ul&gt;\")\n            for var in var_list:\n                cell_items.append(\"&lt;li&gt;\" + var.get_display() + \"&lt;/li&gt;\")\n            cell_items.append(\"&lt;/ul&gt;\")\n            row_items.append( \" \".join(cell_items) )\n        # HPO information\n        hpo_html = self.get_hpo_cell(spat.get_term_by_age_dict())\n        row_items.append( hpo_html )\n        return row_items\n\n\n    def get_hpo_cell(self, term_by_age_dict:Dict[str,HpTerm]) -&gt; str:\n        \"\"\"\n        :param term_by_age_dict: A dictionary with key - ISO8601 string, value - list of HpTerm objects\n        :type term_by_age_dict: Dict[str,HpTerm]\n        :returns: HTML code for the HTML cell\n        :rtype: str\n        \"\"\"\n        lines = []\n        age2day_list = PhenopacketTable.get_sorted_age2data_list(term_by_age_dict.keys())\n        sorted_age = sorted(age2day_list, key=lambda x: x.days)\n        for onset in sorted_age:\n            hpo_list = term_by_age_dict.get(onset.key)\n            hpos = \"; \".join([hpo.__str__() for hpo in hpo_list])\n            if onset.key == Constants.NOT_PROVIDED:\n                lines.append(hpos)\n            else:\n                lines.append(f\"&lt;b&gt;{onset.key}&lt;/b&gt;: {hpos}\")\n        return \"&lt;br/&gt;\".join(lines)\n\n    def to_html(self):\n        \"\"\"create an HTML table with patient ID, age, sex, genotypes, and PhenotypicFeatures\n        \"\"\"\n        ppack_list = self._phenopacket_list\n        spat_list = []\n        pmid_count_d = defaultdict(int)\n        no_pmid_found = 0\n        pmid_found = 0\n        for pp in ppack_list:\n            spat = SimplePatient(ga4gh_phenopacket=pp)\n            if spat.has_pmid():\n                pmid_count_d[spat.get_pmid()] += 1\n                pmid_found += 1\n            else:\n                no_pmid_found += 1\n            spat_list.append(spat)\n        # Create caption\n        if pmid_found == 0:\n            capt = f\"{len(ppack_list)} phenopackets - no PMIDs (consider adding this information to the MetaData)\"\n        else:\n            pmid_strings = []\n            for k, v in pmid_count_d.items():\n                pmid_strings.append(f\"{k} (n={v})\")\n            pmid_str = \"; \".join(pmid_strings)\n            n_phenopackets = len(ppack_list)\n            if n_phenopackets == 1:\n                capt = f\"{n_phenopackets} phenopacket - {pmid_str}\"\n            else:\n                capt = f\"{n_phenopackets} phenopackets - {pmid_str}\"\n        header_items = [\"Individual\", \"Disease\", \"Genotype\", \"Phenotypic features\"]\n        rows = []\n        for spat in spat_list:\n            rows.append(self._simple_patient_to_table_row(spat))\n        generator = HtmlTableGenerator(caption=capt, header_items=header_items, rows=rows)\n        return generator.get_html()\n\n    @staticmethod\n    def iso_to_days(iso_age:str) -&gt; int:\n        \"\"\"\n        Transform the ISO8601 age strings (e.g., P3Y2M) into the corresponding number of days to facilitate sorting.\n\n        Note that if age is not provided we want to sort it to the end of the list so we transform to a very high number of days.\n\n        :param iso_age: ISO8601 age string (e.g., P3Y2M)\n        :type iso_age: str\n        :returns: number of days\n        :rtype: int\n        \"\"\"\n        if iso_age == Constants.NOT_PROVIDED:\n            days = sys.maxsize\n        elif not iso_age.startswith(\"P\"):\n            raise ValueError(f\"Invlaid age string: {age}\")\n        else:\n            days = 0\n            age = iso_age[1:]\n            N = len(age)\n            y = age.find(\"Y\")\n            if y != -1:\n                days = days + int(365.25*int(age[:y]))\n                if age.endswith(\"Y\"):\n                    return days\n                age = age[y+1:]\n            m = age.find(\"M\")\n            if m is not None and m != -1:\n                days = days + int(30.436875*int(age[:m]))\n                if age.endswith(\"M\"):\n                    return days\n                age = age[m+1:]\n            d = age.find(\"D\")\n            if d != -1:\n                days = days + int(age[:d])\n        return days\n\n    @staticmethod\n    def get_sorted_age2data_list(ages:Set[str]) -&gt; List[Age2Day]:\n        \"\"\"\n        Create a sorted list of Age2Day objects that we use to display the age in the HTML output.\n\n        :param ages: A set of ISO 8601 age strings\n        :type ages: Set[str]\n        :returns: A list of sorted Age2Day objects\n        :rtype:  List[Age2Day]\n        \"\"\"\n        age2day_list = list(Age2Day(age, PhenopacketTable.iso_to_days(age)) for age in ages)\n        sorted_list = sorted(age2day_list, key=lambda x: x.days)\n        return sorted_list\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.__init__","title":"<code>__init__(phenopacket_list=None, individual_list=None, metadata=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>phenopacket_list</code> <code>List[Phenopacket]</code> <p>List of GA4GH phenopackets to be displayed</p> <code>None</code> <code>individual_list</code> <code>List[Individual]</code> <p>List of Indidivual objects to be displayed</p> <code>None</code> <code>metadata</code> <code>MetaData</code> <p>metadata about the individuals</p> <code>None</code> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>def __init__(self, phenopacket_list:List[PPKt.Phenopacket]=None,\n                    individual_list:List[Individual]=None,\n                    metadata:MetaData=None) -&gt; None:\n    \"\"\"\n    :param phenopacket_list: List of GA4GH phenopackets to be displayed\n    :type phenopacket_list: List[PPKt.Phenopacket]\n    :param individual_list: List of Indidivual objects to be displayed\n    :type individual_list: List[Individual]\n    :param metadata: metadata about the individuals\n    :type metadata: MetaData\n    \"\"\"\n    if phenopacket_list is None and individual_list is not None and metadata is not None:\n        self._phenopacket_list =  [i.to_ga4gh_phenopacket(metadata=metadata.to_ga4gh()) for i in individual_list]\n    elif phenopacket_list is not None and individual_list is None:\n        if metadata is not None:\n            raise ValueError(\"metadata argument not needed for phenopacket list\")\n        self._phenopacket_list = phenopacket_list\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.from_individuals","title":"<code>from_individuals(individual_list, metadata)</code>  <code>staticmethod</code>","text":"<p>Initialize PhenopacketTable from list of GA4GH Phenopackets</p> <p>Parameters:</p> Name Type Description Default <code>phenopacket_list</code> <code>List[PPKt.Phenopacket]</code> <p>list of GA4GH Phenopackets</p> required <p>Returns:</p> Type Description <code>PhenopacketTable</code> <p>PhenopacketTable for displaying information about a cohort</p> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>@staticmethod\ndef from_individuals(individual_list:List[Individual], metadata:MetaData):\n    \"\"\"Initialize PhenopacketTable from list of GA4GH Phenopackets\n\n    :param phenopacket_list: list of GA4GH Phenopackets\n    :type phenopacket_list: List[PPKt.Phenopacket]\n\n    :returns: PhenopacketTable for displaying information about a cohort\n    :rtype: PhenopacketTable\n    \"\"\"\n    if not isinstance(individual_list, list):\n        raise ValueError(f\"Expecting a list but got {type(individual_list)}\")\n    if len(individual_list) == 0:\n        raise ValueError(\"individual_list was empty\")\n    indi = individual_list[0]\n    if not isinstance(indi, Individual):\n        raise ValueError(f\"individual_list argument must be list of Individual objects but was {type(indi)}\")\n    if not isinstance(metadata, MetaData):\n        raise ValueError(f\"metadata argument must be pyphetools MetaData object but was {type(metadata)}\")\n    return PhenopacketTable(individual_list=individual_list, metadata=MetaData)\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.from_phenopackets","title":"<code>from_phenopackets(phenopacket_list)</code>  <code>staticmethod</code>","text":"<p>Initialize PhenopacketTable from list of GA4GH Phenopackets</p> <p>Parameters:</p> Name Type Description Default <code>phenopacket_list</code> <code>List[Phenopacket]</code> <p>list of GA4GH Phenopackets</p> required <p>Returns:</p> Type Description <code>PhenopacketTable</code> <p>PhenopacketTable for displaying information about a cohort</p> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>@staticmethod\ndef from_phenopackets(phenopacket_list:List[PPKt.Phenopacket]):\n    \"\"\"Initialize PhenopacketTable from list of GA4GH Phenopackets\n\n    :param phenopacket_list: list of GA4GH Phenopackets\n    :type phenopacket_list: List[PPKt.Phenopacket]\n\n    :returns: PhenopacketTable for displaying information about a cohort\n    :rtype: PhenopacketTable\n    \"\"\"\n    if not isinstance(phenopacket_list, list):\n        raise ValueError(f\"Expecting a list but got {type(phenopacket_list)}\")\n    if len(phenopacket_list) == 0:\n        raise ValueError(\"phenopacket_list was empty\")\n    ppkt = phenopacket_list[0]\n    if not isinstance(ppkt, PPKt.Phenopacket):\n        raise ValueError(f\"phenopacket_list argument must be list of Phenopacket objects but was {type(ppkt)}\")\n    return PhenopacketTable(phenopacket_list=phenopacket_list)\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.get_hpo_cell","title":"<code>get_hpo_cell(term_by_age_dict)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>term_by_age_dict</code> <code>Dict[str, HpTerm]</code> <p>A dictionary with key - ISO8601 string, value - list of HpTerm objects</p> required <p>Returns:</p> Type Description <code>str</code> <p>HTML code for the HTML cell</p> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>def get_hpo_cell(self, term_by_age_dict:Dict[str,HpTerm]) -&gt; str:\n    \"\"\"\n    :param term_by_age_dict: A dictionary with key - ISO8601 string, value - list of HpTerm objects\n    :type term_by_age_dict: Dict[str,HpTerm]\n    :returns: HTML code for the HTML cell\n    :rtype: str\n    \"\"\"\n    lines = []\n    age2day_list = PhenopacketTable.get_sorted_age2data_list(term_by_age_dict.keys())\n    sorted_age = sorted(age2day_list, key=lambda x: x.days)\n    for onset in sorted_age:\n        hpo_list = term_by_age_dict.get(onset.key)\n        hpos = \"; \".join([hpo.__str__() for hpo in hpo_list])\n        if onset.key == Constants.NOT_PROVIDED:\n            lines.append(hpos)\n        else:\n            lines.append(f\"&lt;b&gt;{onset.key}&lt;/b&gt;: {hpos}\")\n    return \"&lt;br/&gt;\".join(lines)\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.get_sorted_age2data_list","title":"<code>get_sorted_age2data_list(ages)</code>  <code>staticmethod</code>","text":"<p>Create a sorted list of Age2Day objects that we use to display the age in the HTML output.</p> <p>Parameters:</p> Name Type Description Default <code>ages</code> <code>Set[str]</code> <p>A set of ISO 8601 age strings</p> required <p>Returns:</p> Type Description <code>List[Age2Day]</code> <p>A list of sorted Age2Day objects</p> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>@staticmethod\ndef get_sorted_age2data_list(ages:Set[str]) -&gt; List[Age2Day]:\n    \"\"\"\n    Create a sorted list of Age2Day objects that we use to display the age in the HTML output.\n\n    :param ages: A set of ISO 8601 age strings\n    :type ages: Set[str]\n    :returns: A list of sorted Age2Day objects\n    :rtype:  List[Age2Day]\n    \"\"\"\n    age2day_list = list(Age2Day(age, PhenopacketTable.iso_to_days(age)) for age in ages)\n    sorted_list = sorted(age2day_list, key=lambda x: x.days)\n    return sorted_list\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.iso_to_days","title":"<code>iso_to_days(iso_age)</code>  <code>staticmethod</code>","text":"<p>Transform the ISO8601 age strings (e.g., P3Y2M) into the corresponding number of days to facilitate sorting.</p> <p>Note that if age is not provided we want to sort it to the end of the list so we transform to a very high number of days.</p> <p>Parameters:</p> Name Type Description Default <code>iso_age</code> <code>str</code> <p>ISO8601 age string (e.g., P3Y2M)</p> required <p>Returns:</p> Type Description <code>int</code> <p>number of days</p> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>@staticmethod\ndef iso_to_days(iso_age:str) -&gt; int:\n    \"\"\"\n    Transform the ISO8601 age strings (e.g., P3Y2M) into the corresponding number of days to facilitate sorting.\n\n    Note that if age is not provided we want to sort it to the end of the list so we transform to a very high number of days.\n\n    :param iso_age: ISO8601 age string (e.g., P3Y2M)\n    :type iso_age: str\n    :returns: number of days\n    :rtype: int\n    \"\"\"\n    if iso_age == Constants.NOT_PROVIDED:\n        days = sys.maxsize\n    elif not iso_age.startswith(\"P\"):\n        raise ValueError(f\"Invlaid age string: {age}\")\n    else:\n        days = 0\n        age = iso_age[1:]\n        N = len(age)\n        y = age.find(\"Y\")\n        if y != -1:\n            days = days + int(365.25*int(age[:y]))\n            if age.endswith(\"Y\"):\n                return days\n            age = age[y+1:]\n        m = age.find(\"M\")\n        if m is not None and m != -1:\n            days = days + int(30.436875*int(age[:m]))\n            if age.endswith(\"M\"):\n                return days\n            age = age[m+1:]\n        d = age.find(\"D\")\n        if d != -1:\n            days = days + int(age[:d])\n    return days\n</code></pre>"},{"location":"api/visualization/phenopacket_table/#pyphetools.visualization.PhenopacketTable.to_html","title":"<code>to_html()</code>","text":"<p>create an HTML table with patient ID, age, sex, genotypes, and PhenotypicFeatures</p> Source code in <code>pyphetools/visualization/phenopacket_table.py</code> <pre><code>def to_html(self):\n    \"\"\"create an HTML table with patient ID, age, sex, genotypes, and PhenotypicFeatures\n    \"\"\"\n    ppack_list = self._phenopacket_list\n    spat_list = []\n    pmid_count_d = defaultdict(int)\n    no_pmid_found = 0\n    pmid_found = 0\n    for pp in ppack_list:\n        spat = SimplePatient(ga4gh_phenopacket=pp)\n        if spat.has_pmid():\n            pmid_count_d[spat.get_pmid()] += 1\n            pmid_found += 1\n        else:\n            no_pmid_found += 1\n        spat_list.append(spat)\n    # Create caption\n    if pmid_found == 0:\n        capt = f\"{len(ppack_list)} phenopackets - no PMIDs (consider adding this information to the MetaData)\"\n    else:\n        pmid_strings = []\n        for k, v in pmid_count_d.items():\n            pmid_strings.append(f\"{k} (n={v})\")\n        pmid_str = \"; \".join(pmid_strings)\n        n_phenopackets = len(ppack_list)\n        if n_phenopackets == 1:\n            capt = f\"{n_phenopackets} phenopacket - {pmid_str}\"\n        else:\n            capt = f\"{n_phenopackets} phenopackets - {pmid_str}\"\n    header_items = [\"Individual\", \"Disease\", \"Genotype\", \"Phenotypic features\"]\n    rows = []\n    for spat in spat_list:\n        rows.append(self._simple_patient_to_table_row(spat))\n    generator = HtmlTableGenerator(caption=capt, header_items=header_items, rows=rows)\n    return generator.get_html()\n</code></pre>"},{"location":"api/visualization/qc_visualizer/","title":"QcVisualizer","text":"<p>Class degigned to create HTML summaries of the validation/QC of a cohort</p> <p>Parameters:</p> Name Type Description Default <code>ontology</code> <code>hpotk.MinimalOntology</code> <p>HPO ontology</p> required <code>cohort_validator</code> <code>CohortValidator</code> <p>Validator object that checks all individuals in a cohort</p> required Source code in <code>pyphetools/visualization/qc_visualizer.py</code> <pre><code>class QcVisualizer:\n    \"\"\"Class degigned to create HTML summaries of the validation/QC of a cohort\n    :param ontology: HPO ontology\n    :type ontology: hpotk.MinimalOntology\n    :param cohort_validator: Validator object that checks all individuals in a cohort\n    :type cohort_validator: CohortValidator\n    \"\"\"\n    def __init__(self, cohort_validator:CohortValidator) -&gt; None:\n        self._ontology = cohort_validator.get_ontology()\n        if not isinstance(cohort_validator, CohortValidator):\n            raise ValueError(f\"cohort_validator argument must be CohortValidator object but was {type(cohort_validator)}\")\n        self._cohort_validator = cohort_validator\n\n\n    def to_html(self) -&gt; str:\n        validated_individual_list = self._cohort_validator.get_validated_individual_list()\n        html_lines = []\n        n_individuals = len(validated_individual_list)\n        n_individuals_with_errors = sum([1 for i in validated_individual_list if i.has_error()])\n        html_lines.append(\"&lt;h2&gt;Cohort validation&lt;/h2&gt;\")\n        if n_individuals_with_errors == 0:\n            html_lines.append(f\"&lt;p&gt;No errors found for the cohort with {n_individuals} individuals&lt;/p&gt;\")\n        else:\n            para = f\"&lt;p&gt;Errors found with {n_individuals_with_errors} of {n_individuals} phenopackets.&lt;/p&gt;\"\n            html_lines.append(para)\n            errors = []\n            for vi in validated_individual_list:\n                if vi.has_error():\n                    errors.extend(vi.get_validation_errors())\n            errors = sorted(errors, key=lambda x : (x._error_level, x._category, x._message))\n            header_fields = ValidationResult.get_header_fields()\n            rows = [row.get_items_as_array() for row in errors]\n            generator = HtmlTableGenerator(header_items=header_fields, rows=rows, caption=\"Error analysis\")\n            html_lines.append(generator.get_html())\n        return \"\\n\".join(html_lines)\n\n    def to_summary_html(self) -&gt; str:\n        validated_individual_list = self._get_validated_individuals()\n        qc_element_list = QcElement.get_qc_element_list()\n        error_count = defaultdict(int)\n        total_validation_issues = 0\n        distinct_item_d = defaultdict(set)\n        for vi in validated_individual_list:\n            verrors = vi.get_validation_errors()\n            total_validation_issues += vi.n_errors()\n            for ve in verrors:\n                error_count[ve.category] += 1\n                distinct_item_d[ve.category].add(ve.message)\n        html_lines = []\n        n_individuals = len(validated_individual_list)\n        n_individuals_with_errors = sum([1 for i in validated_individual_list if i.has_error()])\n        html_lines.append(\"&lt;h2&gt;Cohort validation&lt;/h2&gt;\")\n        if n_individuals_with_errors == 0:\n            html_lines.append(f\"&lt;p&gt;No errors found for the cohort with {n_individuals} individuals&lt;/p&gt;\")\n        else:\n            para = f\"&lt;p&gt;Errors found with {n_individuals_with_errors} of {n_individuals} phenopackets.&lt;/p&gt;\"\n            html_lines.append(para)\n\n            header_fields = [\"Level\", \"Error category\", \"Count\"]\n            rows = []\n            for elem in qc_element_list:\n                if elem.category in error_count:\n                    count = error_count.get(elem.category)\n                    row = [elem.level, elem.category, str(count)]\n                    rows.append(row)\n            generator = HtmlTableGenerator(header_items=header_fields, rows=rows, caption=\"Error counts\")\n            html_lines.append(generator.get_html())\n            n_removed = self._cohort_validator.n_removed_individuals()\n            n_error_free_i = self._cohort_validator.n_error_free_individuals()\n            if n_removed == 0:\n                para = f\"&lt;p&gt;A total of {total_validation_issues} issues were fixed and no individual was removed from the cohort.&lt;/p&gt;\"\n                html_lines.append(para)\n            else:\n                para = f\"&lt;p&gt;A total of {total_validation_issues} issues were fixed and {n_removed} individuals were removed from the cohort because of irreparable errors. The cohort validator will return {n_error_free_i} individual objects without errors.&lt;/p&gt;\"\n                html_lines.append(para)\n                if \"MALFORMED_LABEL\" in distinct_item_d:\n                    malformed_label_set = distinct_item_d.get(\"MALFORMED_LABEL\")\n                    if len(malformed_label_set) &gt; 0:\n                        malformed = \"; \".join(malformed_label_set)\n                        para = f\"&lt;p&gt;The following malformed labels were found: {malformed}. These need to be corrected before continuing.&lt;/p&gt;\"\n                        html_lines.append(para)\n                if \"REDUNDANT\" in distinct_item_d:\n                    redundant_label_set = distinct_item_d.get(\"REDUNDANT\")\n                    redundant = \"; \".join(redundant_label_set)\n                    para = f\"&lt;p&gt;The following redundant terms were found: {redundant}. Redundant terms will be removed, keeping only one instance of the most specific term.&lt;/p&gt;\"\n                    html_lines.append(para)\n                if \"CONFLICT\" in distinct_item_d:\n                    conflict_label_set = distinct_item_d.get(\"CONFLICT\")\n                    conflict = \"; \".join(conflict_label_set)\n                    para = f\"&lt;p&gt;The following excluded terms were found to have a conflict with an observed descendent term: {conflict}. The ancestor terms will be removed.&lt;/p&gt;\"\n                    html_lines.append(para)\n                if \"OBSERVED_AND_EXCLUDED\" in distinct_item_d:\n                    o_and_e_set = distinct_item_d.get(\"OBSERVED_AND_EXCLUDED\")\n                    o_and_e = \"; \".join(o_and_e_set)\n                    para = f\"&lt;p&gt;The following terms were annotated as being both observed and excluded: {o_and_e}. This needs to be fixed manually.&lt;/p&gt;\"\n                    html_lines.append(para)\n                if \"DUPLICATE\" in distinct_item_d:\n                    dup_set = distinct_item_d.get(\"DUPLICATE\")\n                    dup = \"; \".join(dup_set)\n                    para = f\"&lt;p&gt;The following terms were annotated as duplicates: {dup}. This will be fixed automatically.&lt;/p&gt;\"\n                    html_lines.append(para)\n                html_lines.append(self._get_unfixable_error_table())\n        return \"\\n\".join(html_lines)\n\n\n    def _get_unfixable_error_table(self):\n        v_individuals_with_unfixable = self._cohort_validator.get_validated_individuals_with_unfixable_errors()\n        html_lines = []\n        html_lines.append(\"&lt;h2&gt;Individuals with unfixable errors&lt;/h2&gt;\")\n        errors = []\n        for vi in v_individuals_with_unfixable:\n            if vi.has_unfixed_error():\n                errors.extend(vi.get_unfixed_errors())\n        errors = sorted(errors, key=lambda x : (x._error_level, x._category, x._message))\n        header_fields = ValidationResult.get_header_fields()\n        rows = [row.get_items_as_array() for row in errors]\n        generator = HtmlTableGenerator(header_items=header_fields, rows=rows, caption=\"Error analysis\")\n        html_lines.append(generator.get_html())\n        return \"\\n\".join(html_lines)\n\n\n    def _get_validated_individuals(self):\n        validated_individual_list = self._cohort_validator.get_validated_individual_list()\n        if not isinstance(validated_individual_list, list):\n            raise ValueError(f\"validated_individual_list argument must be a list but was {type(validated_individual_list)}\")\n        if len(validated_individual_list) == 0:\n            raise ValueError(f\"validated_individual_list argument was empty\")\n        if not isinstance(validated_individual_list[0], ValidatedIndividual):\n            raise ValueError(f\"validated_individual_list argument must be a list of ValidatedIndividual objects but was {type(validated_individual_list[0])}\")\n        return validated_individual_list\n</code></pre>"},{"location":"developers/developers/","title":"For developers","text":""},{"location":"developers/developers/#local-installation","title":"Local Installation","text":"<p>We recommend creating a local environment:</p> <pre><code>python3 -m venv venv\nsource venv/bin/activate\n</code></pre> <p>and updating Python's <code>pip</code> tool:</p> <pre><code>python3 -m pip install --upgrade pip\n</code></pre> <p>You can then do a local/editable install:</p> <pre><code>python3 -m pip install --editable \".[test]\"\n</code></pre> <p>After installation you should be able to run the test suite:</p> <pre><code>pytest\n</code></pre>"},{"location":"developers/developers/#creating-phenopackets","title":"Creating Phenopackets","text":"<p>pyphetools provides two main ways of creating phenopackets.</p> <ul> <li> <p>Using an Excel template. This is the recommended approach for most users.</p> <ul> <li>Details are provided in the Phenopacket Store documentation, along with many examples.</li> </ul> </li> <li> <p>Creating custom Python scripts. This approach can be used by those who are comfortable with writing Python and using Jupyter notebooks. This approach is mainly intended to ingest tabular data from published articles with data from numerous individuals in tabular form (e.g., a typical Supplemental Table). The formats that one encounters in publications are so varied, that pyphetools provides a variety of approaches to capturing the data.</p> <ul> <li>See the section on Custom Python scripts to get started</li> <li>See the API documentation for details</li> </ul> </li> </ul>"},{"location":"developers/hpoa_editing/","title":"HPOA Editing","text":"<p>The HPO team creates one HPOA file for each annotated disease. We are in the process of converting our entire annotation pipeline to be based on phenopackets, and we would like to generate the HPOA files from collections of phenopackets (because essentially all existing HPO-based software uses the file phenotype.hpoa, which is generated from the individual HPOA files).</p> <p>This document explains how to create HPOA files. Several examples are available on the phenopacket-store website, including:</p> <ul> <li>ESAM</li> </ul>"},{"location":"developers/hpoa_editing/#input-data","title":"Input data","text":"<p>HPOA files can be generated from a collection of phenopackets. Each phenopacket should describe an individual with the same disease (identical OMIM, ORPHA, or MONDO identifier). If you are starting from a directory with a collection of phenopackets (JSON files), then ingest the files as follows.</p> Importing phenopackets from JSON files<pre><code>from pyphetools.visualization import *\ningestor = PhenopacketIngestor(indir=\"phenopackets\")\nppkt_d = ingestor.get_phenopacket_dictionary()\nppkt_list = list(ppkt_d.values())\n</code></pre> <p>If you are starting with pyphetools Individual objects, then create phenopackets as follows (note: you will need to have created a pyphetools MetaData object to create the individual list).</p> Importing phenopackets from pyphetools Individual objects<pre><code>ppkt_list = [i.to_ga4gh_phenopacket(metadata=metadata) for i in individuals]\n</code></pre> <p>We recommend that you use the quality control and visualization facilities offered by pyphetools before continuing. See validation.</p>"},{"location":"developers/hpoa_editing/#hpoa-table-builder","title":"HPOA Table Builder","text":"<p>The builder object can be used to create the HPOA annotations. There are two ways to initialized the builder.</p> <p>Initializing the builder from a phenopacket list<pre><code>builder = HpoaTableBuilder(phenopacket_list=ppkt_list)\n</code></pre> It is also possible to create a builder object by providing the path to the directory of phenopackets. Initializing the builder from from JSON files<pre><code>builder = HpoaTableBuilder(indir=\"phenopackets\")\n</code></pre></p>"},{"location":"developers/hpoa_editing/#mode-of-inheritance","title":"Mode of inheritance","text":"<p>In the HPOA annotation model, we regard the mode of inheritance as certain knoweldge that does not receive a frequency or does not need to be specified for each publication (exception: rare diseases with multiple modes of inheritance). In this case, the disease is listed as autosomal dominant in OMIM and in both publications. We curate this using one of the PMIDs (generally, the first to report the disease) as follows.</p> specifying mode of inheritance<pre><code>PMID = \"PMID:123\" # enter the PMID of an article that specificies the mode of inheritance.\nbuilder.autosomal_recessive(PMID)\n</code></pre>"},{"location":"developers/hpoa_editing/#visualizing-the-annotations","title":"Visualizing the annotations","text":"<p>We can bow build the table creator and retrieve the pandas dataframe with all of the annotations.</p> building the table creator<pre><code>hpoa_table_creator = builder.build()\ndf = hpoa_table_creator.get_dataframe()\ndf.head()\n</code></pre> <p>This produces a table like this:</p> <p></p> Validation Results."},{"location":"developers/hpoa_editing/#saving-to-file","title":"Saving to file","text":"<p>We save the HPOA files for each disease with file names such as <code>OMIM-620375.tab</code>. The can be done with the following command</p> writing the HPO file<pre><code>hpoa_table_creator.write_data_frame()\n</code></pre> <p>This file should then be merged with the HPOA repository (task for the HPO team).</p>"},{"location":"developers/hpoa_editing/#api","title":"API","text":"<p>See</p> <ul> <li>HpoaTableCreator</li> </ul>"},{"location":"developers/installation/","title":"Installation of pyphetools","text":"<p>pyphetools is available as a PyPI package.</p> <p>Most users should install the latest version (the following example creates a virtual environment). Note that depending on your system it will be necessary to update pip to be able to install pyphetools.</p> setting up a virtual environment<pre><code>python3 -m venv ppt_env\nsource ppt_env/bin/activate\npip install --upgrade pip\n</code></pre> <p>To work with the notebooks in this repository, it may be desirable to install the latest local version</p> installing pyphetools<pre><code>source ppt_env/bin/activate\npip install -e .\n</code></pre> <p>To use the kernel in notebooks, enter the following</p> installing jupyter and running pyphetools in a notebook<pre><code>pip install jupyter ipykernel\npython -m ipykernel install --user --name \"ppt_env\" --display-name \"ppt_env\"\njupyter-notebook\n</code></pre> <p>The last command will open a jupyter. Create or open a notebook and set the kernel to ppt_env.</p>"},{"location":"developers/internal/","title":"Internal","text":"<p>The following commands are used by the development team.</p>"},{"location":"developers/internal/#updating-package-in-pypi","title":"Updating package in PyPI","text":"<p>We have installed the package in the Python Package Index (pypi) at pyphetools. To update the version, first make sure the build and twine packages are installed (if necessary).</p> <pre><code>python3 -m pip install --upgrade build\npython3 -m pip install --upgrade twine\n</code></pre> <p>To update the version in PyPI, update the version number in the pyproject.toml file, and execute the following commands to build and install.</p> updating package in PyPI<pre><code>python3 -m build\npython3 -m twine upload dist/*\n</code></pre>"},{"location":"developers/internal/#unit-testing","title":"Unit testing","text":"<p>Unit tests were written for pytest, which can be installed with pip and run from the top-level directory as</p> <pre><code>pytest\n</code></pre>"},{"location":"developers/internal/#documentation","title":"Documentation","text":"<p>These pages are generated with mkdocs.</p> <p>To set things up, perform the following steps (substitute name of venv if needed).</p> <pre><code>python3 -m venv venvhpoo\nsource venvhpo/bin/activate\npip install --upgrade pip\npip install mkdocs\npip install mkdocs-material\npip install mkdocs-material[imaging]\npip install pillow cairosvg\npip install mkdocs-material-extensions\npip install mkdocstrings[python]\n</code></pre> <p>To start a local server, enter: <pre><code>mkdocs serve\n</code></pre></p>"},{"location":"user-guide/discombobulator/","title":"Discombobulator","text":"<p>Sometimes tables contain many different related items. For instance, the following box shows the contents of one cell in a table from PMID:30057029 in a column entitled \"dysmorpholoy\".</p> <p>Dysmorphology</p> <p>frontal bossing, curled hair, highly arched and sparse eyebrows, long eyelashes, downslanting palpebral fissures, depressed nasal ridge, tented upper lip</p> <p>While we could create annotations by hand and create one column for each entry in this cell (and all of the other entries in the column), it can be error-prone and time consuming. Therefore, pyphetools has a (currently experimental) feature called \"discombobulation\", then takes all of the entries in such a cell from each cell in a column, and creates corresponding columns and rows for the standard Excel template file. To do this, we create the following python code.</p> <pre><code>from pyphetools.creation import Discombobulator, HpoParser\nimport pandas as pd\nparser = HpoParser()\nhp_cr = parser.get_hpo_concept_recognizer()\ndisco = Discombobulator(hpo_cr=hp_cr)\n</code></pre> <p>This creates a Discombobulator object that can be used for all of the relevant columns of the original supplemental file. Assuming for this example that the original file is called \"temp.xslx\" and the column of interest is called \"face\", we would use the following python code.</p> <pre><code>df = pd.read_excel(\"temp.xlsx\")\ndf_face = disco.decode(df=df, column=\"face\", assumeExcluded=True)\ndf_face.head(3)\n</code></pre> <p>The assumeExcluded argument determines if we call a feature to be absent if it is not mentioned in a certain cell but is mentioned in another cell in the same column. This assumption seems justified for dysmorphology features if the authors state a full examination was conducted.</p> <p>For now, this function operates one column at a time. We can save the results in an excel file and manually add them to the template file.</p> <pre><code>df_face.to_excel(\"temp_face.xlsx\")\n</code></pre> <p>This functionality is currently in an experimental stage and we are exploring ways to make its use easier. We do not recommend using the Decombobualtor unless you are very comfortable with Python and Excel.</p> <p>There is no need to keep the temporary excel files or python code after creating the main template file.</p>"},{"location":"user-guide/excel/","title":"Excel Template","text":"<p>We have designed a format for Excel templates that can be used to quickly and efficiently generate collections of Phenopackets. This is currently the prefered way for clinicians and translational researchers to contribute to this project. The pyphetools  library provides other means for bioinformaticians (please ask us).</p> <p>The template file is generated for each disease as described in template.</p>"},{"location":"user-guide/excel/#a-format-for-cohort-descriptions-in-excel","title":"A format for cohort descriptions in excel","text":"<p>The schema of the template consists in two rows that specify the nature of the data. There is a fixed set of columns that capture basic demographic data together with the disease, the source publication, and the variants. The second half of the template should be used to record information about HPO terms curated from the publications.</p> <p>Note that the format specifier \"CURIE\" means \"Compact uniform resource identifier\", which means the entry should have a prefix (e.g., PMID, a colon, and the identifier, e.g., 3021034, altogether \"PMID:3021034\"). \"str\" refers to an arbitrary text (string). \"optional\" means the cell can be left empty.</p>"},{"location":"user-guide/excel/#fixed-columns","title":"Fixed columns","text":"<p>The first (leftmost) 11 or 12 columns specify basic demographic data together with the disease, the source publication, and the variants. The first two rows are used to specify the datatypes and should not be changed. The following tables show the first two rows together with one example row with data extracted from a publication (We show two tables for better legibility)</p> PMID title individual_id Comment disease_id disease_label CURIE str str optional CURIE str PMID:33087723 Early-onset autoimmunity associated with SOCS1 haploinsufficiency A1 OMIM:603597 Autoinflammatory syndrome, familial, with or without immunodeficiency <ol> <li>PMID (CURIE: The PubMed identifier of the publication being curated.</li> <li>title (str): The title of the publication being curated.</li> <li>individual_id (str): The identifier of the individual being described in the original publication. This field is required. Please add \u2018individual\u2019 if the original article does not provide an identifier (if needed, individual 1, individual 2,...).</li> <li>comment (str): This field is provided to record additional information that will not be used for creating phenopackets but may be helpful for future reference. It can be left empty.</li> <li>disease_id (CURIE). The disease identifer (e.g., <code>OMIM:154700</code> or  <code>MONDO:0007947</code>).</li> <li>disease_label (str). The name of the disease (e.g. <code>Marfan syndrome</code>).</li> </ol> HGNC_id gene_symbol transcript allele_1 allele_2 variant.comment CURIE str str str str str HGNC:19383 SOCS1 NM_003745.2 c.368C&gt;G na p.P123R <ol> <li>HGNC_id (CURIE): Identifier of the HUGO Gene Nomenclature Committee.</li> <li>gene_symbol (str):: Gene symbol, e.g., SOCS1.</li> <li>transcript (str): The identifier of the transcript. NCBI RefSeq or ENSEMBL identifiers are preferred.</li> <li>allele_1 (str): A string representing the first pathogenic allele (variant) according to HGVS nomenclature.</li> <li>allele_2 (str): This field should not be used for monoallelic diseases (e.g. autosomal dominant, XLR). The column can eigther be omitted or can be filled with \"na\" to denote \"not applicable\". It the column is present and is left empty, this will be flagged as an error. For biallelic diseases (autosomal recessive), specific the second allele (which will be the same as the first for homozygous genotypes).</li> <li>variant.comment (str): This field is provided to record additional information that will not be used for creating phenopackets but may be helpful for future reference.</li> </ol> age_of_onset age_at_last_encounter sex HPO age age M:F:O:U na Infantile onset P21Y F na <ol> <li>age_of_onset: The age of onset of disease, recorded using iso8601 convention or an HPO Onset term.</li> <li>sex (M:F:U:O): one of M (male), female (F), other(O), or unknown (U)</li> <li>HPO (str): The column marks the end of the data columns and should contain \"na\".</li> </ol>"},{"location":"user-guide/excel/#hpo-term-columns","title":"HPO Term Columns","text":"<p>All of the following columns denote HPO terms. The first row has the HPO term label. Be sure to use the same label as is shown on the HPO webpage and do not chance the capitalization. The second row has the corresponding HPO id. The following table shows several examples, whereby the individual_id column from above is shown for ease of exposition.</p> individual_id Hepatitis Pancreatitis Lymphadenopathy Splenomegaly HP:0012115 \u00a0 HP:0001733 HP:0002716 HP:0001744 \u00a0A \u00a0observed \u00a0excluded \u00a0P4Y2M \u00a0B P3Y na \u00a0observed \u00a0excluded <p>Each table cell can contain either 1. observed: The phenotypic abnormality denoted by the HPO term was present 2. excluded: The phenotypic abnormality denoted by the HPO term was investigated and ruled out. 3. An iso8601 string denoting the age of onset. 4. na or empty (blank): Information not available or phenotypic feature not measured.</p> <p>In this example, individual A was observed to have hepatitis (but age of onset is unknown or not available), pancreatitis was ruled out, no information is available about lymphadenopathy, and splenomegaly was first observed at age 4 years and 2 months.</p> <p>Individual B was found to have hepatitis first observed at age 3 years, no information was available about pancreatitis, lymphadenopathy was observed (but age of onset is unknown or not available), and splenomegaly  was ruled out.</p> <p>The file should contain at least the following information; see explanations below.</p> row_type id age sex allele Tall stature Abnormal sternum morphology Potassium header1 str ISO8601 str NM_000138.5 simple option threshold header2 HP:0000098 HP:0000767; HP:0000768 3.5-5.2 mEq/L: High-&gt;Hyperkalemia{HP:0002153); Low-&gt;Hypokalemia(HP:0002900) individual patient A P6Y male c.8326C&gt;T + Pectus carinatum n/a individual patient B P9Y female c.7988G&gt;C - Pectus excavatum 5.8"},{"location":"user-guide/excel/#row_type","title":"row_type","text":"<p>Each row must begin with one of the words \"header1\", \"header2\" or \"individual\". There should be one row for each individual in the cohort.</p>"},{"location":"user-guide/excel/#id","title":"id","text":"<p>This is an cohort-specific identifier that must be anonymized.</p>"},{"location":"user-guide/excel/#age","title":"age","text":"<p>This is the age of the individual at the time of the medical encounter at which the phenotypic features were recorded. The format of the column is recorded in the header1 line. Valid options are ISO8601 for strings such as \"P4Y\" (four years of age) and \"P71Y6M2D\" for 71 years, 6 months, and 2 days; Years for 5 (5 years of age) or 7.5 (7 years and 6 months).</p>"},{"location":"user-guide/excel/#sex","title":"sex","text":"<p>Use male, female, other, or unknown.</p>"},{"location":"user-guide/excel/#hpo-columns","title":"HPO columns","text":"<p>The remaining columns contain information about HPO terms observed in the individuals. There are three types of column.</p>"},{"location":"user-guide/excel/#simple","title":"Simple.","text":"<p>The top row contains the label of the term. The header1 row contains the word \"simple\". The header2 row contains the HPO id; in the example table, we see Tall stature; HP:0000098. If the feature is observed in an indivual, use \"+\"; if the feature was explicitly excluded, use \"-\". If the feature was not measured or no information is available, use \"n/a\".</p>"},{"location":"user-guide/excel/#option","title":"Option","text":"<p>This type of column is used for sets of related terms. The top row contains the label of the HPO superclass (herere Abnormal sternum morphology HP:0000766). The header1 row contains the word \"option\". The header2 row contains the HPO ids of the terms that can be recorded in the column. In this example, it is the terms Pectus carinatum; HP:0000768 and Pectus excavatum HP:0000767. In the individual rows, the corresponding label of the HPO term is written. Any number of terms can be put into one column in this way.</p>"},{"location":"user-guide/excel/#threshold","title":"Threshold","text":"<p>This type of column is used for numerical data with a normal range. Indicate the normal range and the HPO terms that are used for low or high values as shown.</p>"},{"location":"user-guide/excel/#text-mining","title":"Text mining","text":"<p>This type of column is not preferred but if necessary can be used. An example is not shown here, but but \"text mining\" in the header1 row and nothing in the header2 row. We will use text mining to attempt to extract HPO terms from the texts in the column.</p>"},{"location":"user-guide/python_notebook/","title":"Python (Jupyter) notebook for the Excel template","text":"<p>The following sections explain how to use Python code to create phenopackets from data stored using the Excel template.</p>"},{"location":"user-guide/python_notebook/#preparing-the-notebook","title":"Preparing the notebook.","text":"<p>We first import the TemplateImporter to import the data and create phenopackets, and several classes to visualize the data.</p> <pre><code>from pyphetools.creation import TemplateImporter, Moi\nfrom pyphetools.visualization import IndividualTable, QcVisualizer\nfrom IPython.display import display, HTML\nimport pyphetools\nprint(f\"Using pyphetools version {pyphetools.__version__}\")\n</code></pre>"},{"location":"user-guide/python_notebook/#set-paths-and-identifiers","title":"Set paths and identifiers","text":"<p>Update the ORCID identifier to your own ORCID  id.  Update the path to the template file.</p> <pre><code>template = \"input/BRD4_individuals.xlsx\"\ncreated_by = \"0000-0002-0736-9199\"\n</code></pre>"},{"location":"user-guide/python_notebook/#import-the-template-file","title":"Import the template file.","text":"<p>The code returns the pyphetools Individual objects, each of which contains all of the information needed to create a phenopacket and which here can be used if desired for debugging or further analysis. The cvalidator object is used to display quality assessment information. Note that optionally you can provide an argument to the location of the hp.json file using the <code>hp_json</code>argument. If no argument is provided, the hpo-toolkit library will download the latest version of hp.json to your user directory (.hpotk folder).</p> <pre><code>timporter = TemplateImporter(template=template,  created_by=created_by)\nindividual_list, cvalidator = timporter.import_phenopackets_from_template()\n</code></pre>"},{"location":"user-guide/python_notebook/#structural-variants","title":"Structural variants","text":"<p>pyphetools will automatically retrieve information about small variants coded as HGVS strings using the VariantValidator API. Until very recently, it was challenging to determine the exact positions of larger structural variants, and for this reason, publications often described them using phrases such as \"whole gene deletion\" or \"EX9-12DEL\". If such as string is found in the template file, pyphetool will emit an error such as the following.</p> <p></p> Validation Results.  <p>This can be fixed by passing an argument with a set of all strings that represent deletions (as in the following example), duplications, or inversions.</p> Specifying structural variants<pre><code>del_set = {\"EX9-12DEL\"}\ntimporter = TemplateImporter(template=template, created_by=created_by)\nindividual_list, cvalidator = timporter.import_phenopackets_from_template(deletions=del_set)\n</code></pre>"},{"location":"user-guide/python_notebook/#display-quality-assessment-data","title":"Display quality assessment data.","text":"<pre><code>qc = QcVisualizer(cohort_validator=cvalidator)\ndisplay(HTML(qc.to_summary_html()))\n</code></pre>"},{"location":"user-guide/python_notebook/#display-summaries-of-each-phenopacket","title":"Display summaries of each phenopacket.","text":"<p>The command <code>cvalidator.get_error_free_individual_list()</code>returns versions of the Individual objects in which errors such as redundancies have been removed; this is the data that gets transformed into phenopackets.</p> <pre><code>table = IndividualTable(cvalidator.get_error_free_individual_list())\ndisplay(HTML(table.to_html()))\n</code></pre>"},{"location":"user-guide/python_notebook/#hpoa-files","title":"HPOA files","text":"<p>If desired, we can transform the phenopacket data into an HPOA file. This is the format that the HPO team uses to create the phenotype.hpoa file that is distributed on the Human Phenotype Ontology website. We need to choose a PubMed identifier that documents the mode of inheritance (MOI) and then indicate the MOI. If multiple distinct diseases are stored in the phenopackets directory, then we need to choose one of them using the target argument.</p> <p>Check results of variant encoding. <pre><code>pmid = \"PMID:36333996\"\ndf = timporter.create_hpoa_from_phenopackets(pmid=pmid, mode_of_inheritance=Moi.AR)\n</code></pre> or</p> <pre><code>pmid = \"PMID:36333996\"\ndf = timporter.create_hpoa_from_phenopackets(pmid=pmid, mode_of_inheritance=Moi.AD, target=\"OMIM:620427\")\n</code></pre>"},{"location":"user-guide/summary/","title":"Summary","text":"<p>The pyphetools library provides code to create a summary of all of the phenopackets of a cohort. This can be useful to review work or understand the distribution of data. This page explains how to set up the notebook.</p>"},{"location":"user-guide/summary/#imports","title":"Imports","text":"<p>We first import several classes to visualize the data.</p> <pre><code>import pandas as pd\npd.set_option('display.max_colwidth', None) # show entire column contents, important!\nfrom IPython.display import HTML, display\nfrom pyphetools.visualization import *\nimport pyphetools\nprint(f\"Using pyphetools version {pyphetools.__version__}\")\n</code></pre>"},{"location":"user-guide/summary/#extract-phenopackets","title":"Extract phenopackets","text":"<p>We then extract a list of phenopackets from the target directory.</p> <p><pre><code>ingestor = PhenopacketIngestor(indir=\"phenopackets\")\nppkt_list = ingestor.get_phenopacket_list()\n</code></pre> By default, pyphetools will create a new directory called phenopackets into which it will write the new phenopackets. Therefore, the PhenopacketIngestor will use phenopackets as a default if we do not specify the \"indir\" argument. <pre><code>ingestor = PhenopacketIngestor()\nppkt_list = ingestor.get_phenopacket_list()\n</code></pre></p> <p>If the input directory contains phenopackets for more than one disease, an error message will appear. In this case, use the disease_id argument to specific the disease identifier.</p>"},{"location":"user-guide/summary/#detailed-table","title":"Detailed table","text":"<p>The following command will display a table with the counts of annotated HPO terms for each PubMed identifier (publication) used in the cohort.</p> <pre><code>detailed_table = DetailedSupplTable(patient_list=ppkt_list)\ndisplay(HTML(detailed_table.get_html_table_by_pmid(min_count=1)))\n</code></pre>"},{"location":"user-guide/summary/#pcharts","title":"pcharts","text":"<p>The PhenopacketCharts class uses matplotlib to display barcharts to show salient aspects of the data</p> <p>This will display a chart with the counts of each disease in the cohort.</p> <pre><code>pcharts = PhenopacketCharts(indir=\"phenopackets\")\npcharts.disease_barchart();\n</code></pre> <p>This will display a chart with the counts of individuals per publication (PMID) in the cohort.</p> <pre><code>pcharts.pmid_barchart();\n</code></pre> <p>And finally, this will display a chart with the most commonly annotated HPO terms in the cohort.</p> <pre><code>pcharts.most_common_hpo_terms(max_terms_to_show=10);\n</code></pre>"},{"location":"user-guide/template/","title":"Data-Entry Template","text":"<p>pyphetools offers two main ways to encode clinical data as phenopackets. The library provides various functions to encode data found in typical supplementary materials of publications about cohorts. This option, which is covered in more detail here is intended for those with skills in scripting with Python. Additionally, pyphetools can ingest data encoded in an Excel template that can be used without additional scripting. The template can be ingested using a standardized notebook. Alternatively, users are invited to work with the HPO team to enter the data into the HPO database.</p> <p>See here for many examples of how to use the template.</p>"},{"location":"user-guide/template/#template-creation","title":"Template Creation","text":"<p>Excel templates can be  created in a Jupyter notebook to prepopulate them with the HPO terms, gene and disease ids.</p> <p>We will show an example for creating a template for Simpson-Golabi-Behmel syndrome, type 2-OMIM:300209.</p> <pre><code>from pyphetools.creation import TemplateCreator\n</code></pre> <p>First initialize the creator object with the path to a <code>hp.json</code> file (adjust the path as needed on your system).</p> <pre><code>tcreator = TemplateCreator(hp_json=\"../hp.json\")\n</code></pre> <p>We will then use HPO text mining to retrieve as many terms as possible from a description of the phenotypic features that can be derived from the article you are curating or any relevant source. We took the following description from Tenorio J, et al., Simpson-Golabi-Behmel syndrome types I and II. Orphanet J Rare Dis. 2014</p> <pre><code>tcreator.add_seed_terms(\"\"\"\nIt is an infantile lethal variant of SGBS associated with hydrops fetalis.\nIn the first report, the authors reported 4 maternally-related male cousins\nwith a severe variant of SGBS [6]. One of these males was aborted therapeutically\nat 19 weeks of gestation following the detection of multicystic kidneys on ultrasound.\nThe three live born males were hydropic at birth. They also depicted craniofacial\nanomalies including macrocephaly; apparently low-set, posteriorly angulated ears; hypertelorism;\nshort, broad nose with anteverted nares; large mouth with thin upper vermilion border;\nprominent philtrum; high-arched and cleft palate. Other findings were short neck;\nredundant skin; hypoplastic nails; skeletal defects involving upper and lower limbs;\ngastrointestinal and genitourinary anomalies, hypotonia and neurologic impairment.\n\"\"\")```\n\nThe script added 14 HPO terms to the template. Now we specify the remaining information.\n\n```python\ndisease_id = \"OMIM:300209\"\ndisease_label = \"Simpson-Golabi-Behmel syndrome, type 2\"\nsymbol = \"OFD1\"\nhgnc_id = \"HGNC:2567\"\nofd1_transcript='NM_003611.3'\ntcreator.create_template(disease_id=disease_id,\n                         disease_label=disease_label,\n                         gene_symbol=symbol,\n                         HGNC_id=hgnc_id,\n                         transcript=ofd1_transcript)\n</code></pre> <p>The following snippet can be used as a \"starter\" by pasting it into the notebook.</p> <pre><code>tc.create_template(disease_id=\"\",\n                         disease_label=\"\",\n                         gene_symbol=\"\",\n                         HGNC_id=\"\",\n                         transcript=\"\")\n</code></pre> <p>The script creates a file that can be opened in Excel and used for curation. Add additional HPO terms as necessary and remove terms that are not needed.</p>"},{"location":"user-guide/tips_for_curation/","title":"Tips for accurate curation","text":"<p>This document explains the intended use of the fields of the template and provides guidance on common problems.</p>"},{"location":"user-guide/tips_for_curation/#pmid","title":"PMID:","text":"<p>Please use the form <code>PMID:38143450</code>. Please remove the space, if any, between the colon and the number.</p>"},{"location":"user-guide/tips_for_curation/#indentifier","title":"Indentifier:","text":"<p>Please use the identifier used in the original publication. If the original publication has a Table, it is usually obvious what identifier to use. In other cases, no explicit identifier is given. Try to extract a short identifier that will be obvious to others who might look at your curation later on. For instance, if the paper is a case report that states this:</p> <p>Example</p> <p>Here we present the case of a 28-year-old man with X-linked immunodeficiency with magnesium defect, Epstein\u2013Barr virus (EBV) infection and neoplasia (XMEN) disease.</p> <p>Then use \u201c28-year-old man\u201d as the identifier (see PMID:38143450).</p>"},{"location":"user-guide/tips_for_curation/#disease-id-and-name","title":"Disease id and name","text":"<p>Please use the OMIM identifier. This can be taken from the OMIM webpage for the disease. For instance, OMIM:300853 shows Phenotype MIM number 300853. Please enter this as <code>OMIM:300853</code>. The <code>Phenotype</code> (i.e., disease) is shown in the table as <code>Immunodeficiency, X-linked, with magnesium defect, Epstein-Barr virus infection and neoplasia</code>. Please use this label. This will make it much easier for software to correctly identify the disease that is being curated.</p>"},{"location":"user-guide/tips_for_curation/#comment","title":"Comment","text":"<p>Sometimes it is hard to curate information and it is a good idea to enter some additional information about the case to help others understand the curation. Please use the <code>comment</code> field for this. The following box shows an example of the kind of comment that might be useful.</p> <p>Example</p> <p>incl Table 1 with many neurological symptoms in these two patients + Table 2 with neurological symptoms in pther XMEN patients</p>"},{"location":"user-guide/tips_for_curation/#transcript","title":"Transcript","text":"<p>It can be difficult to choose the optimal transcript, and articles about one and the same disease may even use different transcripts. We try to use the transcript that is preferred by ClinVar. See Varint notation for explanations.</p> <p>We recommend using VariantValidator to check the variant identifiers used in original publications.</p> <p>Note that incorrect variant nomenclature is still common in the literature. For instance, <code>c.C414A</code> should be <code>c.414C&gt;A</code>.</p>"},{"location":"user-guide/tips_for_curation/#hpo-term-columns","title":"HPO Term columns","text":"<p>Please use only HPO terms for these columns. Do not use terms from other ontologies or terminologies such as OMIM, ORPHA, or other sources.</p> <p>Please use exactly the original HPO term label, e.g., do not use the words they used in the original publication, instead use the label found on the HPO website</p> <p>For instance, if the original publication states <code>recurrent bronchopulmonary infection</code>, go to the HPO website to determine the corresponding HPO term, which in this case is Recurrent bronchopulmonary infections. If <code>hypogammaglobulinemia</code> is used in the original publication, choose Decreased circulating antibody level.</p> <p>This will make the curation unambiguous and reduce potential errors.</p>"},{"location":"user-guide/tips_for_curation/#new-terms","title":"New terms","text":"<p>The HPO is still incomplete. If you find a phenotypic abnormality in a publication but cannot find a corresponding HPO term, enter the label for the term in the first row and <code>NTR</code> (new term request) in the second row. The HPO team will help to decide if there is an existing term for the abnormality or will create a new term. Following this, the Excel file can be updated.</p>"},{"location":"user-guide/tips_for_curation/#scope","title":"Scope","text":"<p>The HPO describes phenotypic abnormalities in a clinical context. It does not cover topics such as molecular mechanisms. Terms such as \u201closs-of function\u201d are not in scope.</p>"},{"location":"user-guide/variant_notation/","title":"Variant Notation","text":"<p>We recommend that users choose one transcript for all HGVS variant descriptions in a project. In general, the most clinically relevant transcript should be chosen.</p>"},{"location":"user-guide/variant_notation/#choosing-the-reference-transcript-for-a-project","title":"Choosing the reference transcript for a project","text":"<p>An easy way to identify the optimal transcript is to search with the gene symbol in ClinVar. For instance, searching on FBN2 reveals a page with variants such as this: NM_001999.4(FBN2):c.8729A&gt;G (p.Gln2910Arg) (Note that you may need to skip over more complex structural variants that include the FBN2 and other genes to get to this entry). The transcript NM_001999.4 is the one to use.</p> <p>In general, we recommend using the MANE Select (or if available MANE Select Clinical). This can be found using the Ensembl website for the gene in quenstion (here we see that the MANE Select transcript for FBN2 is ENST00000262464.9, which is equivalent to NM_001999.4). MANE refers to MANE (Matched Annotation from NCBI and EBI)</p> <p>Rarely, one transcript alone is not enough to report all clinically relevant variation. We reocmmend consulting the MANE Plus Clinical set, which includes additional transcripts for genes where MANE Select alone is not sufficient to report all \"Pathogenic (P)\" or \"Likely Pathogenic (LP)\" clinical variants available in public resources.</p>"},{"location":"user-guide/variant_notation/#checking-and-converting-variants","title":"Checking and converting variants","text":"<p>Older literature often uses out-of-date HGVS notation and may use transcripts other than MANE select or the transcript used in ClinVar.</p> <p>For example, Abbas MM, et al. 2016 describe a \"A missense mutation c.T2525C:p.L842P in ATP13A2 (Ensemble transcript ID ENST00000341676)\". There are two difficulties here. Firstly, the notation \"cT2525C\" is not correct HGVS Nomenclature and should be \"c.2525T&gt;C\". Secondly, the transcript used is not the desired one. By consulting the Ensembl webpage, we determined that ENST00000341676 is equivalent to NM_001141974.2.</p> <p>There are various ways to check and convert notation.</p> <ul> <li>Mutalyzer: Has tools to check notation and also to convert between transcript references</li> <li>VariantValidator: Has tools to check HGVS nomenclature and to compare differnet transcript references.</li> </ul> <p>In this case, using VariantValidator, we determined that the correct notation is NM_022089.4:c.2657T&gt;C. This can be difficult and please reach out to us in case of questions.</p> <p>We can additionally check the transcript by going to the VariantValidator website and testing the HGVS nucleotide variant (i.e., NM_001999.4(FBN2):c.8729A&gt;G) using the  Validator tool (paste the variant in the Variant Description: window). If we paste the resulting VCF-like notation GRCh38:5:128259465:T:C</p>"},{"location":"visualization/","title":"Visualization","text":"<p>pyphetools offers several options to visualize cohorts.</p>"},{"location":"visualization/kaplan_meier_visualizer/","title":"Kaplan Meier Visualization","text":"<p>A brief introduction to Kaplan-Meier analysis is available here. The following texts were extracted from that article.</p> <p>Time-to-event is a clinical course duration variable for each subject having a beginning and an end anywhere along the time line of the complete study. For example, it may begin when the subject is enrolled into a study or when treatment begins, and ends when the end-point (event of interest) is reached or the subject is censored from the study.  In preparing Kaplan-Meier survival analysis, each subject is characterized by three variables: 1) their serial time, 2) their status at the end of their serial time (event occurrence or censored), and 3) the study group they are in.  For the construction of survival time probabilities and curves, the serial times for individual subjects are arranged from the shortest to the longest, without regard to when they entered the study. By this maneuver, all subjects within the group begin the analysis at the same point and all are surviving until something happens to one of them. The two things that can happen are: 1) a subject can have the event of interest or 2) they are censored.</p> SUBJECT SERIAL TIME (years) STATUS AT SERIAL TIME (1=event; 0=censored) Group (1 or 2) B 1 1 1 E 2 1 1 F 3 1 1 A 4 1 1 D 4.5 1 1 C 5 0 1 U 0.5 1 2 Z 0.75 1 2 W 1 1 2 <p>Censoring means the total survival time for that subject cannot be accurately determined. This can happen when something negative for the study occurs, such as the subject drops out, is lost to follow-up, or required data is not available or, conversely, something good happens, such as the study ends before the subject had the event of interest occur, i.e., they survived at least until the end of the study, but there is no knowledge of what happened thereafter. Thus censoring can occur within the study or terminally at the end.</p> <p>Currently, pyphetools shows a survival curve for the entire cohort. This is the corresponding Python code. There are two options. First, we plot the time up to the event represented by the age of onset of an HPO term.</p> <pre><code>from pyphetools.visualization import KaplanMeierVisualizer, PhenopacketIngestor, SimplePatient\nfrom lifelines import KaplanMeierFitter\nimport matplotlib.pyplot as plt # only needed to save file \nphenopackets_dir = \"../phenopackets/\" # directory containing phenopackets to plot\ningestor = PhenopacketIngestor(indir=phenopackets_dir)\nppkt_list = ingestor.get_phenopacket_list()\nsimple_pt_list = [SimplePatient(ppkt) for ppkt in ppkt_list]\nhpo_id = \"HP:0003774\" # TermId of HPO term for the KM plot\nkmv = KaplanMeierVisualizer(simple_patient_list=simple_pt_list, target_tid=stage5crd)\nT, E = kmv.get_time_and_event()\n# plot Kaplan Meier curve\nkmf = KaplanMeierFitter()\nkmf.fit(T, E, label=\"Age at stage 5 kidney disease\")\nplt.plot()\nax = kmf.plot_survival_function()\nax.set_xlabel(\"Years\");\nplt.savefig(\"kmf_plot.png\", format=\"png\"); ## optional\n</code></pre> <p></p> Kaplan Meier Survival Plot of a cohort of individuals with pathogenic variants in the UMOD gene with respect to age of onset of stage 5 kidney failure.  <pre><code>It is also possible to plot a curve for survival, which makes use of the VitalStatus message of the phenopackets. The code is exactly the same\nas the above, except that we do not pass the target_tid argument.\n```python\n# same as above\nkmv = KaplanMeierVisualizer(simple_patient_list=simple_pt_list)\n# same as above except that we change the title of the plot\nkmf.fit(T, E, label=\"Survival\")\n</code></pre> <p></p> <p></p> Kaplan Meier Survival Plot of a cohort of individuals with pathogenic variants in the UMOD gene."}]}